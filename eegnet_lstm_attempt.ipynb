{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2a563374",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "2a563374",
        "outputId": "9011deaa-65f5-4fe2-ffd4-a106eeea3568"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ffe57a4-c3a2-4707-840a-3702871d577d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ffe57a4-c3a2-4707-840a-3702871d577d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving modules.zip to modules.zip\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "if not os.path.exists('./modules') and not os.path.exists('modules.zip'):\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "if not os.path.exists('./modules') and os.path.exists('modules.zip'):\n",
        "    os.system('unzip modules.zip -d .')\n",
        "\n",
        "!pip3 install optuna\n",
        "import kagglehub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import optuna\n",
        "from modules import EEGDataset\n",
        "from modules.utils import split_and_get_loaders, evaluate_model, manual_write_study_params\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fb6b091d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb6b091d",
        "outputId": "e613bca5-ff09-4160-a0c4-6798ce53167d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/girgismicheal/steadystate-visual-evoked-potential-signals?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23.3M/23.3M [00:00<00:00, 153MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download datasetaset files: \n",
            " /root/.cache/kagglehub/datasets/girgismicheal/steadystate-visual-evoked-potential-signals/versions/1/SSVEP (BrainWheel)\n"
          ]
        }
      ],
      "source": [
        "#! need to modify those for the competition itself\n",
        "TRIAL_LENGTH = 640  # frequency of changing.. frequency\n",
        "# Download dataset\n",
        "path_1 = kagglehub.dataset_download(\"girgismicheal/steadystate-visual-evoked-potential-signals\")\n",
        "path_1 += \"/SSVEP (BrainWheel)\"\n",
        "print(\"Download datasetaset files:\", \"\\n\", path_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8b83a09b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b83a09b",
        "outputId": "5b6e2fb9-e5be-4bd0-c0d5-7cfcc8b70537"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0195,  0.3192, -0.1630,  0.1811],\n",
              "        [-0.0165,  0.3870, -0.1583,  0.0998],\n",
              "        [-0.0478,  0.3266, -0.1169,  0.0824],\n",
              "        [ 0.0051,  0.3093, -0.0847,  0.1376],\n",
              "        [-0.0976,  0.3636, -0.1377,  0.0726]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, h0=None, c0=None):\n",
        "        if h0 is None or c0 is None:\n",
        "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
        "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class DepthWiseConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, dim_mult=1, padding=0, bias=False):\n",
        "        super(DepthWiseConv2D, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels * dim_mult, padding=padding, kernel_size=kernel_size, groups=in_channels, bias=bias)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.depthwise(x)\n",
        "\n",
        "\n",
        "class SeperableConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=False):\n",
        "        super(SeperableConv2D, self).__init__()\n",
        "        self.depthwise = DepthWiseConv2D(in_channels, kernel_size, padding=padding)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        return out\n",
        "\n",
        "class SSVEPClassifier(nn.Module):\n",
        "    # EEG Net Based\n",
        "    # todo look at this https://paperswithcode.com/paper/a-transformer-based-deep-neural-network-model\n",
        "    def __init__(self, n_electrodes=16, n_samples=128, out_dim=4, dropout=0.25, kernLength=256, F1=96, D=1, F2=96, hidden_dim=100, layer_dim=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # B x C x T\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, F1, (1, kernLength), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(F1),\n",
        "            #\n",
        "            DepthWiseConv2D(F1, (n_electrodes, 1), dim_mult=D, bias=False),\n",
        "            nn.BatchNorm2d(F1*D),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d((1, 2)), # todo try making this max pool\n",
        "            nn.Dropout(dropout),\n",
        "            #\n",
        "            SeperableConv2D(F1 * D, F2, kernel_size=(1, 16), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(F2),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d((1, 4)),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.lstm_head = LSTMModel(F2, hidden_dim, layer_dim, out_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"expected input shape: BxCxT\"\"\"\n",
        "        x = x.unsqueeze(1)\n",
        "        y = self.block_1(x) # B x F1 x 1 x time_sub\n",
        "\n",
        "        y = y.squeeze(2) # B x F1 x time_sub\n",
        "        y = y.permute(0, 2, 1) # B x time_sub x F1\n",
        "        y = self.lstm_head(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "dummy_x = torch.randn(5, 14, 320)\n",
        "model = SSVEPClassifier(n_electrodes=dummy_x.shape[1], n_samples=dummy_x.shape[2])\n",
        "model(dummy_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "42089fb8",
      "metadata": {
        "id": "42089fb8"
      },
      "outputs": [],
      "source": [
        "window_length = 320\n",
        "stride = window_length // 2\n",
        "batch_size = 32\n",
        "\n",
        "dataset = EEGDataset(path_1, TRIAL_LENGTH, window_length, stride=stride)\n",
        "train_loader, val_loader, test_loader = split_and_get_loaders(dataset, batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SSVEPClassifier(n_electrodes=dummy_x.shape[1], n_samples=dummy_x.shape[2]).to(device)"
      ],
      "metadata": {
        "id": "5aw8bHOjIgqv"
      },
      "id": "5aw8bHOjIgqv",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "12b164b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "12b164b5",
        "outputId": "0c937650-d21e-4b8d-99f6-b15739e90fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, avg_loss: 1.3928805647826776, val_evaluation: 0.26875\n",
            "epoch: 1, avg_loss: 1.368941687956089, val_evaluation: 0.30625\n",
            "epoch: 2, avg_loss: 1.342956211508774, val_evaluation: 0.3625\n",
            "epoch: 3, avg_loss: 1.329485009356243, val_evaluation: 0.34375\n",
            "epoch: 4, avg_loss: 1.3120341417266101, val_evaluation: 0.3375\n",
            "epoch: 5, avg_loss: 1.304872230785649, val_evaluation: 0.334375\n",
            "epoch: 6, avg_loss: 1.2907797447065028, val_evaluation: 0.3625\n",
            "epoch: 7, avg_loss: 1.2516086421361783, val_evaluation: 0.359375\n",
            "epoch: 8, avg_loss: 1.2355819271831978, val_evaluation: 0.365625\n",
            "epoch: 9, avg_loss: 1.218538926868904, val_evaluation: 0.38125\n",
            "epoch: 10, avg_loss: 1.193409652244754, val_evaluation: 0.396875\n",
            "epoch: 11, avg_loss: 1.1423812232366422, val_evaluation: 0.38125\n",
            "epoch: 12, avg_loss: 1.1423980695445364, val_evaluation: 0.35625\n",
            "epoch: 13, avg_loss: 1.136247142059047, val_evaluation: 0.375\n",
            "epoch: 14, avg_loss: 1.0839109929596507, val_evaluation: 0.4\n",
            "epoch: 15, avg_loss: 1.0308051778049003, val_evaluation: 0.384375\n",
            "epoch: 16, avg_loss: 1.0366550233305953, val_evaluation: 0.384375\n",
            "epoch: 17, avg_loss: 1.0065754186816331, val_evaluation: 0.3875\n",
            "epoch: 18, avg_loss: 0.9910286112529475, val_evaluation: 0.378125\n",
            "epoch: 19, avg_loss: 0.956220533789658, val_evaluation: 0.4125\n",
            "epoch: 20, avg_loss: 0.908793577333776, val_evaluation: 0.440625\n",
            "epoch: 21, avg_loss: 0.8820665740385288, val_evaluation: 0.425\n",
            "epoch: 22, avg_loss: 0.8500028208988469, val_evaluation: 0.409375\n",
            "epoch: 23, avg_loss: 0.832261604506795, val_evaluation: 0.4375\n",
            "epoch: 24, avg_loss: 0.8161822295770412, val_evaluation: 0.43125\n",
            "epoch: 25, avg_loss: 0.7924132608785862, val_evaluation: 0.428125\n",
            "epoch: 26, avg_loss: 0.7358978318005074, val_evaluation: 0.43125\n",
            "epoch: 27, avg_loss: 0.6998896373481285, val_evaluation: 0.4375\n",
            "epoch: 28, avg_loss: 0.6996123587212911, val_evaluation: 0.45625\n",
            "epoch: 29, avg_loss: 0.6940538490690836, val_evaluation: 0.453125\n",
            "epoch: 30, avg_loss: 0.6485465212566096, val_evaluation: 0.4875\n",
            "epoch: 31, avg_loss: 0.5995608691762133, val_evaluation: 0.44375\n",
            "epoch: 32, avg_loss: 0.6037876151683854, val_evaluation: 0.45625\n",
            "epoch: 33, avg_loss: 0.5697141893026305, val_evaluation: 0.50625\n",
            "epoch: 34, avg_loss: 0.5538727917322298, val_evaluation: 0.459375\n",
            "epoch: 35, avg_loss: 0.5651933398188614, val_evaluation: 0.478125\n",
            "epoch: 36, avg_loss: 0.5424708382385534, val_evaluation: 0.5125\n",
            "epoch: 37, avg_loss: 0.501421347987361, val_evaluation: 0.475\n",
            "epoch: 38, avg_loss: 0.5014020647944474, val_evaluation: 0.465625\n",
            "epoch: 39, avg_loss: 0.4628325831599352, val_evaluation: 0.49375\n",
            "epoch: 40, avg_loss: 0.48199795222863917, val_evaluation: 0.45\n",
            "epoch: 41, avg_loss: 0.46997900488899974, val_evaluation: 0.503125\n",
            "epoch: 42, avg_loss: 0.4564440294009883, val_evaluation: 0.490625\n",
            "epoch: 43, avg_loss: 0.40863098876505366, val_evaluation: 0.53125\n",
            "epoch: 44, avg_loss: 0.38313201505963396, val_evaluation: 0.5125\n",
            "epoch: 45, avg_loss: 0.4292269745251028, val_evaluation: 0.515625\n",
            "epoch: 46, avg_loss: 0.4330942630767822, val_evaluation: 0.5\n",
            "epoch: 47, avg_loss: 0.3982538508205879, val_evaluation: 0.503125\n",
            "epoch: 48, avg_loss: 0.3409975832555352, val_evaluation: 0.515625\n",
            "epoch: 49, avg_loss: 0.3339958888728444, val_evaluation: 0.4875\n",
            "epoch: 50, avg_loss: 0.35203754502098733, val_evaluation: 0.509375\n",
            "epoch: 51, avg_loss: 0.33929236160545817, val_evaluation: 0.51875\n",
            "epoch: 52, avg_loss: 0.31646783813470747, val_evaluation: 0.503125\n",
            "epoch: 53, avg_loss: 0.2908720101525144, val_evaluation: 0.546875\n",
            "epoch: 54, avg_loss: 0.2581212983989134, val_evaluation: 0.53125\n",
            "epoch: 55, avg_loss: 0.25229268557414775, val_evaluation: 0.546875\n",
            "epoch: 56, avg_loss: 0.2738629096164936, val_evaluation: 0.528125\n",
            "epoch: 57, avg_loss: 0.2422170720812751, val_evaluation: 0.528125\n",
            "epoch: 58, avg_loss: 0.2515089215665329, val_evaluation: 0.51875\n",
            "epoch: 59, avg_loss: 0.2715916299238438, val_evaluation: 0.55\n",
            "epoch: 60, avg_loss: 0.22001686292450603, val_evaluation: 0.53125\n",
            "epoch: 61, avg_loss: 0.2565004889194558, val_evaluation: 0.534375\n",
            "epoch: 62, avg_loss: 0.26790009457163694, val_evaluation: 0.5\n",
            "epoch: 63, avg_loss: 0.25848656383956353, val_evaluation: 0.521875\n",
            "epoch: 64, avg_loss: 0.20908423140645027, val_evaluation: 0.503125\n",
            "epoch: 65, avg_loss: 0.2024809680879116, val_evaluation: 0.5125\n",
            "epoch: 66, avg_loss: 0.20727490506521085, val_evaluation: 0.5125\n",
            "epoch: 67, avg_loss: 0.23204168259370617, val_evaluation: 0.484375\n",
            "epoch: 68, avg_loss: 0.20778168865093372, val_evaluation: 0.525\n",
            "epoch: 69, avg_loss: 0.18424649145908473, val_evaluation: 0.5125\n",
            "epoch: 70, avg_loss: 0.20465462909239093, val_evaluation: 0.496875\n",
            "epoch: 71, avg_loss: 0.20605553295917628, val_evaluation: 0.5125\n",
            "epoch: 72, avg_loss: 0.19921130841461623, val_evaluation: 0.525\n",
            "epoch: 73, avg_loss: 0.1712203785413649, val_evaluation: 0.53125\n",
            "epoch: 74, avg_loss: 0.24564589796269812, val_evaluation: 0.509375\n",
            "epoch: 75, avg_loss: 0.2014515951457547, val_evaluation: 0.525\n",
            "epoch: 76, avg_loss: 0.2071953278216647, val_evaluation: 0.515625\n",
            "epoch: 77, avg_loss: 0.18614425137639046, val_evaluation: 0.521875\n",
            "epoch: 78, avg_loss: 0.15012161142942382, val_evaluation: 0.534375\n",
            "epoch: 79, avg_loss: 0.13899146511060437, val_evaluation: 0.50625\n",
            "epoch: 80, avg_loss: 0.14159727723496715, val_evaluation: 0.534375\n",
            "epoch: 81, avg_loss: 0.13413883250479292, val_evaluation: 0.503125\n",
            "epoch: 82, avg_loss: 0.1496516323489387, val_evaluation: 0.534375\n",
            "epoch: 83, avg_loss: 0.16734548576357888, val_evaluation: 0.553125\n",
            "epoch: 84, avg_loss: 0.18413618988380198, val_evaluation: 0.50625\n",
            "epoch: 85, avg_loss: 0.16317051594577184, val_evaluation: 0.54375\n",
            "epoch: 86, avg_loss: 0.15261426531687017, val_evaluation: 0.559375\n",
            "epoch: 87, avg_loss: 0.11443161133040743, val_evaluation: 0.515625\n",
            "epoch: 88, avg_loss: 0.11707783435902945, val_evaluation: 0.51875\n",
            "epoch: 89, avg_loss: 0.09662854966775673, val_evaluation: 0.509375\n",
            "epoch: 90, avg_loss: 0.09494791163994772, val_evaluation: 0.53125\n",
            "epoch: 91, avg_loss: 0.11373903447898423, val_evaluation: 0.5125\n",
            "epoch: 92, avg_loss: 0.1238007383739076, val_evaluation: 0.509375\n",
            "epoch: 93, avg_loss: 0.13290879307541906, val_evaluation: 0.50625\n",
            "epoch: 94, avg_loss: 0.1562005649434357, val_evaluation: 0.528125\n",
            "epoch: 95, avg_loss: 0.13008656861578546, val_evaluation: 0.5125\n",
            "epoch: 96, avg_loss: 0.11137064891617472, val_evaluation: 0.521875\n",
            "epoch: 97, avg_loss: 0.09713070816928293, val_evaluation: 0.54375\n",
            "epoch: 98, avg_loss: 0.0873654071332478, val_evaluation: 0.521875\n",
            "epoch: 99, avg_loss: 0.16819873570305546, val_evaluation: 0.53125\n",
            "epoch: 100, avg_loss: 0.16245131244564928, val_evaluation: 0.528125\n",
            "epoch: 101, avg_loss: 0.10632012598216534, val_evaluation: 0.525\n",
            "epoch: 102, avg_loss: 0.1260276532209501, val_evaluation: 0.5375\n",
            "epoch: 103, avg_loss: 0.13718161695614095, val_evaluation: 0.50625\n",
            "epoch: 104, avg_loss: 0.09896538249875714, val_evaluation: 0.528125\n",
            "epoch: 105, avg_loss: 0.1556543200390368, val_evaluation: 0.51875\n",
            "epoch: 106, avg_loss: 0.13000009931260492, val_evaluation: 0.525\n",
            "epoch: 107, avg_loss: 0.09198349432610883, val_evaluation: 0.521875\n",
            "epoch: 108, avg_loss: 0.11655456506897037, val_evaluation: 0.53125\n",
            "epoch: 109, avg_loss: 0.10909559863914804, val_evaluation: 0.54375\n",
            "epoch: 110, avg_loss: 0.1054086116392438, val_evaluation: 0.53125\n",
            "epoch: 111, avg_loss: 0.11926048576104932, val_evaluation: 0.559375\n",
            "epoch: 112, avg_loss: 0.12341846958393367, val_evaluation: 0.5125\n",
            "epoch: 113, avg_loss: 0.08693319404634034, val_evaluation: 0.5375\n",
            "epoch: 114, avg_loss: 0.08157829620034956, val_evaluation: 0.534375\n",
            "epoch: 115, avg_loss: 0.13852524757385254, val_evaluation: 0.53125\n",
            "epoch: 116, avg_loss: 0.11727297215200053, val_evaluation: 0.490625\n",
            "epoch: 117, avg_loss: 0.1007212788184605, val_evaluation: 0.5125\n",
            "epoch: 118, avg_loss: 0.08092198654918409, val_evaluation: 0.49375\n",
            "epoch: 119, avg_loss: 0.061857300901376616, val_evaluation: 0.496875\n",
            "epoch: 120, avg_loss: 0.05306514872737774, val_evaluation: 0.525\n",
            "epoch: 121, avg_loss: 0.06908147684412032, val_evaluation: 0.521875\n",
            "epoch: 122, avg_loss: 0.06755250357318579, val_evaluation: 0.496875\n",
            "epoch: 123, avg_loss: 0.07192182214930654, val_evaluation: 0.5375\n",
            "epoch: 124, avg_loss: 0.08243512321354413, val_evaluation: 0.521875\n",
            "epoch: 125, avg_loss: 0.05350208054183096, val_evaluation: 0.528125\n",
            "epoch: 126, avg_loss: 0.11494508029029864, val_evaluation: 0.525\n",
            "epoch: 127, avg_loss: 0.08437558761002814, val_evaluation: 0.521875\n",
            "epoch: 128, avg_loss: 0.08208190865542103, val_evaluation: 0.515625\n",
            "epoch: 129, avg_loss: 0.08674673833770723, val_evaluation: 0.53125\n",
            "epoch: 130, avg_loss: 0.0490253089200251, val_evaluation: 0.51875\n",
            "epoch: 131, avg_loss: 0.06362218961755677, val_evaluation: 0.509375\n",
            "epoch: 132, avg_loss: 0.07851254489136542, val_evaluation: 0.521875\n",
            "epoch: 133, avg_loss: 0.06657165829546569, val_evaluation: 0.496875\n",
            "epoch: 134, avg_loss: 0.10303040387154352, val_evaluation: 0.521875\n",
            "epoch: 135, avg_loss: 0.12075481977222896, val_evaluation: 0.509375\n",
            "epoch: 136, avg_loss: 0.082977993050363, val_evaluation: 0.51875\n",
            "epoch: 137, avg_loss: 0.052683390949557464, val_evaluation: 0.51875\n",
            "epoch: 138, avg_loss: 0.044956899622864116, val_evaluation: 0.525\n",
            "epoch: 139, avg_loss: 0.048245665833081416, val_evaluation: 0.51875\n",
            "epoch: 140, avg_loss: 0.046014192786703746, val_evaluation: 0.509375\n",
            "epoch: 141, avg_loss: 0.05095185701758033, val_evaluation: 0.540625\n",
            "epoch: 142, avg_loss: 0.0744215167672714, val_evaluation: 0.515625\n",
            "epoch: 143, avg_loss: 0.06245654248973218, val_evaluation: 0.503125\n",
            "epoch: 144, avg_loss: 0.08902856604218846, val_evaluation: 0.509375\n",
            "epoch: 145, avg_loss: 0.11257164839019136, val_evaluation: 0.490625\n",
            "epoch: 146, avg_loss: 0.07753451333222229, val_evaluation: 0.540625\n",
            "epoch: 147, avg_loss: 0.07126930041420387, val_evaluation: 0.503125\n",
            "epoch: 148, avg_loss: 0.07885344754677356, val_evaluation: 0.55\n",
            "epoch: 149, avg_loss: 0.07772133951416103, val_evaluation: 0.525\n",
            "epoch: 150, avg_loss: 0.06823286142132086, val_evaluation: 0.51875\n",
            "epoch: 151, avg_loss: 0.05911079763502973, val_evaluation: 0.515625\n",
            "epoch: 152, avg_loss: 0.1268348503494408, val_evaluation: 0.5125\n",
            "epoch: 153, avg_loss: 0.06584142650500303, val_evaluation: 0.521875\n",
            "epoch: 154, avg_loss: 0.07526855349040977, val_evaluation: 0.534375\n",
            "epoch: 155, avg_loss: 0.1286442172145698, val_evaluation: 0.521875\n",
            "epoch: 156, avg_loss: 0.07267560130666668, val_evaluation: 0.534375\n",
            "epoch: 157, avg_loss: 0.060390284875544105, val_evaluation: 0.553125\n",
            "epoch: 158, avg_loss: 0.05666059345324955, val_evaluation: 0.5125\n",
            "epoch: 159, avg_loss: 0.05560515085008086, val_evaluation: 0.540625\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4163966691>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mavg_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mval_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/modules/utils.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-32914771>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"expected input shape: BxCxT\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B x F1 x 1 x time_sub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B x F1 x time_sub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "avg_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    avg_loss = 0\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        y_pred = model(x).to(device)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "    avg_loss /= len(train_loader)\n",
        "    avg_losses.append(avg_loss)\n",
        "\n",
        "    evaluation = evaluate_model(model, val_loader, device)\n",
        "    val_accuracies.append(evaluation)\n",
        "    print(f'epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# maxpool\n",
        "plt.plot(range(len(avg_losses)), avg_losses, \"b-\", label=\"trainingg loss\")\n",
        "plt.plot(range(len(val_accuracies)), val_accuracies, \"r-\", label=\"validation accuracies\")\n",
        "plt.legend()\n",
        "print(f\"min avg_losses: {min(avg_losses)}\")\n",
        "print(f\"max val_accuracies: {max(val_accuracies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "OBfEejXsGwBy",
        "outputId": "91f81846-7357-407e-934f-637a9ee97ab1"
      },
      "id": "OBfEejXsGwBy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min avg_losses: 2.594960134468615e-05\n",
            "max val_accuracies: 0.490625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2dec2ee1",
      "metadata": {
        "id": "2dec2ee1"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.train_epochs = 1000\n",
        "        self.tune_epochs = 50\n",
        "        self.optuna_n_trials = 120\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = None\n",
        "        self.trial = None\n",
        "\n",
        "        self.train_loader = None\n",
        "        self.eval_loader = None\n",
        "        self.test_loader = None\n",
        "        self.dataset = None\n",
        "\n",
        "        self.storage = \"sqlite:///optuna_studies.db\"\n",
        "        self.study_name = \"ssvep_classifier_optimization\"\n",
        "\n",
        "        self.checkpoint_path = \"./checkpoints/ssvep\"\n",
        "        os.makedirs(os.path.join(self.checkpoint_path, \"models\"), exist_ok=True)\n",
        "        self.checkpoint_model_path = os.path.join(self.checkpoint_path, \"models\")\n",
        "\n",
        "    def _train_loop(self, n_epochs: int, should_save=False, should_print=False):\n",
        "        assert isinstance(self.optimizer, torch.optim.Optimizer), \"optimizer is not a valid optimizer\"\n",
        "        assert isinstance(self.train_loader, DataLoader), \"train_laoder is not valid Datloader\"\n",
        "        if self.trial is None:\n",
        "            print(\"Warning: self.trial is none, we are probably in acutal training phase\")\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            self.model.to(self.device)\n",
        "            self.model.train()\n",
        "\n",
        "            avg_loss = 0\n",
        "            for x, y in self.train_loader:\n",
        "                x = x.to(self.device)\n",
        "                y = y.to(self.device)\n",
        "\n",
        "                y_pred = self.model(x)  # B x out_size\n",
        "                loss = self.criterion(y_pred, y)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                avg_loss += loss.item()\n",
        "\n",
        "            avg_loss = avg_loss / len(self.train_loader)\n",
        "            evaluation = evaluate_model(self.model, self.val_loader, self.device)\n",
        "\n",
        "            if self.trial is not None:\n",
        "                self.trial.report(evaluation, epoch)\n",
        "                if self.trial.should_prune():\n",
        "                    optuna.exceptions.TrialPruned()\n",
        "\n",
        "            if should_print:\n",
        "                print(f\"epoch {epoch}, evaluation {evaluation}, avg_loss {avg_loss}\")\n",
        "\n",
        "            if should_save:\n",
        "                self.model.cpu()\n",
        "                torch.save(self.model.state_dict(), os.path.join(self.checkpoint_model_path, f\"ssvep.pth\"))\n",
        "                self.model.to(self.device)\n",
        "\n",
        "\n",
        "    def _prepare_training(self, is_trial):\n",
        "        if is_trial:\n",
        "            assert isinstance(self.trial, optuna.Trial), \"trial is none, cant' suggest params\"\n",
        "\n",
        "            # network params\n",
        "            n_electrodes = self.trial.suggest_categorical(\"n_electrodes\", [16, 32])\n",
        "            n_samples = self.trial.suggest_categorical(\"n_samples\", [128, 256])\n",
        "            dropout = self.trial.suggest_float(\"dropout\", 0, 0.5)\n",
        "            kernLength = self.trial.suggest_categorical(\"kernLength\", [128, 256, 512])\n",
        "            F1 = self.trial.suggest_categorical(\"F1\", [64, 96, 128])\n",
        "            D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
        "            F2 = self.trial.suggest_categorical(\"F2\", [64, 96, 128])\n",
        "            hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
        "            layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3, 4])\n",
        "\n",
        "            # dataset params\n",
        "            window_length = self.trial.suggest_categorical(\"window_length\", [160, 320])\n",
        "            stride_factor = self.trial.suggest_int(\"stride\", 1, 3)\n",
        "\n",
        "            # training params\n",
        "            lr = self.trial.suggest_float(\"lr\", 3e-4, 3e-2, log=True)\n",
        "            batch_size = self.trial.suggest_categorical(\"batch_size\", [32, 64])\n",
        "\n",
        "        else:\n",
        "            best_params = self._get_study().best_params\n",
        "\n",
        "            window_length = best_params['window_length']\n",
        "            stride_factor = best_params['stride']\n",
        "            dropout = best_params[\"dropout\"]\n",
        "            lr = best_params[\"lr\"]\n",
        "            batch_size = best_params[\"batch_size\"]\n",
        "\n",
        "        stride = int(window_length // stride_factor)\n",
        "        self.dataset = EEGDataset(path_1, TRIAL_LENGTH, window_length, stride=stride)\n",
        "        unique_freqs = torch.unique(self.dataset.labels)\n",
        "\n",
        "        n_samples = self.dataset.data[0].shape[1] # data[x] shape CxT\n",
        "        n_electrodes = self.dataset.data[0].shape[0]\n",
        "        out_size = len(unique_freqs)\n",
        "\n",
        "        self.model = SSVEPClassifier(\n",
        "            n_electrodes=n_electrodes,\n",
        "            n_samples=n_samples,\n",
        "            out_dim=out_size,\n",
        "            dropout=dropout,\n",
        "            kernLength=kernLength,\n",
        "            F1=F1,\n",
        "            D=D,\n",
        "            F2=F1,\n",
        "            hidden_dim=hidden_dim,\n",
        "            layer_dim=layer_dim\n",
        "        )\n",
        "        self.train_loader, self.val_loader, self.test_loader = split_and_get_loaders(self.dataset, batch_size)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
        "\n",
        "    def _objective(self, trial: optuna.Trial):\n",
        "        self.trial = trial\n",
        "        self._prepare_training(True)\n",
        "\n",
        "        self._train_loop(self.tune_epochs, should_save=False, should_print=False)\n",
        "        evaluation = evaluate_model(self.model, self.val_loader, self.device)\n",
        "        return evaluation\n",
        "\n",
        "    def _get_study(self):\n",
        "        return optuna.create_study(study_name=self.study_name, storage=self.storage, direction=\"maximize\", load_if_exists=True)\n",
        "\n",
        "    def optimize(self, delete_existing=False):\n",
        "        if delete_existing:\n",
        "            try:\n",
        "                optuna.delete_study(study_name=self.study_name, storage=self.storage)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        study = self._get_study()\n",
        "        study.optimize(self._objective, n_trials=self.optuna_n_trials, timeout=60 * 10)\n",
        "\n",
        "        # Print optimization results\n",
        "        print(\"\\nStudy statistics:\")\n",
        "        print(f\"  Number of finished trials: {len(study.trials)}\")\n",
        "        print(f\"  Number of pruned trials: {len(study.get_trials(states=[optuna.trial.TrialState.PRUNED]))}\")\n",
        "        print(f\"  Number of complete trials: {len(study.get_trials(states=[optuna.trial.TrialState.COMPLETE]))}\")\n",
        "\n",
        "        print(\"\\nBest trial:\")\n",
        "        trial = study.best_trial\n",
        "        print(f\"  Value: {trial.value}\")\n",
        "        print(\"\\nBest hyperparameters:\")\n",
        "        for key, value in trial.params.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "    def train(self):\n",
        "        self.trial = None\n",
        "        self._prepare_training(False)\n",
        "\n",
        "        self._train_loop(self.train_epochs, should_save=True, should_print=True)\n",
        "        evaluation = evaluate_model(self.model, self.val_loader, self.device)\n",
        "        print(\"done training\")\n",
        "        return evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a132bf51",
      "metadata": {
        "id": "a132bf51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9aa3e55-b05b-451b-898e-4c92b2eb3fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-18 03:50:44,409] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n",
            "[I 2025-06-18 03:52:01,424] Trial 4 finished with value: 0.5354166666666667 and parameters: {'n_electrodes': 16, 'n_samples': 256, 'dropout': 0.05482288557273096, 'kernLength': 256, 'F1': 128, 'D': 2, 'F2': 96, 'hidden_dim': 256, 'layer_dim': 1, 'window_length': 320, 'stride': 2, 'lr': 0.0003668474508971489, 'batch_size': 32}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:54:00,387] Trial 5 finished with value: 0.26322115384615385 and parameters: {'n_electrodes': 16, 'n_samples': 128, 'dropout': 0.1891406161326139, 'kernLength': 512, 'F1': 64, 'D': 3, 'F2': 128, 'hidden_dim': 64, 'layer_dim': 4, 'window_length': 160, 'stride': 3, 'lr': 0.0038582065406684105, 'batch_size': 32}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:54:45,438] Trial 6 finished with value: 0.471875 and parameters: {'n_electrodes': 16, 'n_samples': 128, 'dropout': 0.25541149299268967, 'kernLength': 128, 'F1': 128, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 2, 'window_length': 320, 'stride': 1, 'lr': 0.0010413061743519236, 'batch_size': 32}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:55:20,913] Trial 7 finished with value: 0.4390625 and parameters: {'n_electrodes': 16, 'n_samples': 128, 'dropout': 0.13745627270602118, 'kernLength': 512, 'F1': 64, 'D': 1, 'F2': 128, 'hidden_dim': 64, 'layer_dim': 4, 'window_length': 160, 'stride': 1, 'lr': 0.0018097578034844105, 'batch_size': 64}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:55:59,866] Trial 8 finished with value: 0.440625 and parameters: {'n_electrodes': 16, 'n_samples': 128, 'dropout': 0.4440478764361076, 'kernLength': 256, 'F1': 96, 'D': 2, 'F2': 128, 'hidden_dim': 64, 'layer_dim': 1, 'window_length': 320, 'stride': 1, 'lr': 0.0036017824900056814, 'batch_size': 32}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:56:56,223] Trial 9 finished with value: 0.465625 and parameters: {'n_electrodes': 16, 'n_samples': 256, 'dropout': 0.11948861266836397, 'kernLength': 256, 'F1': 96, 'D': 3, 'F2': 128, 'hidden_dim': 256, 'layer_dim': 4, 'window_length': 320, 'stride': 1, 'lr': 0.0007718654054003772, 'batch_size': 64}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:58:12,136] Trial 10 finished with value: 0.4314236111111111 and parameters: {'n_electrodes': 16, 'n_samples': 256, 'dropout': 0.4437528143066455, 'kernLength': 512, 'F1': 64, 'D': 1, 'F2': 96, 'hidden_dim': 128, 'layer_dim': 4, 'window_length': 160, 'stride': 2, 'lr': 0.00039589635613080726, 'batch_size': 32}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 03:59:08,176] Trial 11 finished with value: 0.4017857142857143 and parameters: {'n_electrodes': 32, 'n_samples': 256, 'dropout': 0.010204951937246402, 'kernLength': 128, 'F1': 128, 'D': 2, 'F2': 96, 'hidden_dim': 256, 'layer_dim': 1, 'window_length': 320, 'stride': 2, 'lr': 0.00968424468011415, 'batch_size': 64}. Best is trial 4 with value: 0.5354166666666667.\n",
            "[I 2025-06-18 04:01:38,445] Trial 12 finished with value: 0.65625 and parameters: {'n_electrodes': 32, 'n_samples': 256, 'dropout': 0.33066508963955576, 'kernLength': 256, 'F1': 128, 'D': 2, 'F2': 96, 'hidden_dim': 256, 'layer_dim': 3, 'window_length': 160, 'stride': 3, 'lr': 0.00030241790493218325, 'batch_size': 64}. Best is trial 12 with value: 0.65625.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Study statistics:\n",
            "  Number of finished trials: 13\n",
            "  Number of pruned trials: 0\n",
            "  Number of complete trials: 12\n",
            "\n",
            "Best trial:\n",
            "  Value: 0.65625\n",
            "\n",
            "Best hyperparameters:\n",
            "  n_electrodes: 32\n",
            "  n_samples: 256\n",
            "  dropout: 0.33066508963955576\n",
            "  kernLength: 256\n",
            "  F1: 128\n",
            "  D: 2\n",
            "  F2: 96\n",
            "  hidden_dim: 256\n",
            "  layer_dim: 3\n",
            "  window_length: 160\n",
            "  stride: 3\n",
            "  lr: 0.00030241790493218325\n",
            "  batch_size: 64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_electrodes': 32,\n",
              " 'n_samples': 256,\n",
              " 'dropout': 0.33066508963955576,\n",
              " 'kernLength': 256,\n",
              " 'F1': 128,\n",
              " 'D': 2,\n",
              " 'F2': 96,\n",
              " 'hidden_dim': 256,\n",
              " 'layer_dim': 3,\n",
              " 'window_length': 160,\n",
              " 'stride': 3,\n",
              " 'lr': 0.00030241790493218325,\n",
              " 'batch_size': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "trainer = Trainer()\n",
        "delete_existing = False\n",
        "trainer.optimize(delete_existing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93294ea",
      "metadata": {
        "id": "a93294ea"
      },
      "outputs": [],
      "source": [
        "# manual_write_study_params(trainer.study_name, trainer.storage)\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}