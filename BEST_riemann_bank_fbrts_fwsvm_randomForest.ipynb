{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f517e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from modules.competition_dataset import EEGDataset\n",
    "from Models import FilterBankRTSClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c412b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mtcaic3'\n",
    "lda_model_path = './checkpoints/mi/models/lda_mi.pkl'\n",
    "\n",
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a69b96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:00:21,900] A new study created in memory with name: no-name-7f6843c7-6c41-4c15-ab15-995dc8764f03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 12/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:02:01,160] Trial 0 finished with value: 0.577676531840226 and parameters: {'tmin': 70, 'filter_order': 3, 'fs': 300, 'n_estimators': 350, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.577676531840226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.992 | Val acc: 0.578\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:03:26,158] Trial 1 finished with value: 0.5750321573720879 and parameters: {'tmin': 230, 'filter_order': 4, 'fs': 210, 'n_estimators': 500, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.577676531840226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.999 | Val acc: 0.575\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:05:11,566] Trial 2 finished with value: 0.5678408521576039 and parameters: {'tmin': 10, 'filter_order': 5, 'fs': 190, 'n_estimators': 150, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.577676531840226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 1.000 | Val acc: 0.568\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 14/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:06:50,952] Trial 3 finished with value: 0.5682697622996131 and parameters: {'tmin': 150, 'filter_order': 4, 'fs': 280, 'n_estimators': 400, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.577676531840226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.998 | Val acc: 0.568\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:08:31,812] Trial 4 finished with value: 0.5510021608425416 and parameters: {'tmin': 90, 'filter_order': 4, 'fs': 240, 'n_estimators': 400, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.577676531840226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.999 | Val acc: 0.551\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 16/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:09:55,235] Trial 5 finished with value: 0.6214133728507264 and parameters: {'tmin': 240, 'filter_order': 3, 'fs': 150, 'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.6214133728507264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 1.000 | Val acc: 0.621\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:11:34,961] Trial 6 finished with value: 0.5694931541400491 and parameters: {'tmin': 110, 'filter_order': 4, 'fs': 210, 'n_estimators': 450, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.6214133728507264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.998 | Val acc: 0.569\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:13:14,873] Trial 7 finished with value: 0.5614235157271394 and parameters: {'tmin': 110, 'filter_order': 4, 'fs': 190, 'n_estimators': 450, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.6214133728507264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 1.000 | Val acc: 0.561\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:14:37,128] Trial 8 finished with value: 0.557707668929572 and parameters: {'tmin': 170, 'filter_order': 5, 'fs': 210, 'n_estimators': 50, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.6214133728507264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.995 | Val acc: 0.558\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:16:33,154] Trial 9 finished with value: 0.5728496191955338 and parameters: {'tmin': 40, 'filter_order': 4, 'fs': 300, 'n_estimators': 500, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.6214133728507264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.999 | Val acc: 0.573\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 16/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:17:58,312] Trial 10 finished with value: 0.6247614335896314 and parameters: {'tmin': 240, 'filter_order': 6, 'fs': 110, 'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.6247614335896314.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.990 | Val acc: 0.625\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 16/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:19:24,393] Trial 11 finished with value: 0.6287495905872867 and parameters: {'tmin': 240, 'filter_order': 6, 'fs': 110, 'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.6287495905872867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.988 | Val acc: 0.629\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:20:49,731] Trial 12 finished with value: 0.6235645744848198 and parameters: {'tmin': 200, 'filter_order': 6, 'fs': 70, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.6287495905872867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.990 | Val acc: 0.624\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 16/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:22:05,021] Trial 13 finished with value: 0.6088229910305692 and parameters: {'tmin': 250, 'filter_order': 6, 'fs': 110, 'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.6287495905872867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.994 | Val acc: 0.609\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:23:33,592] Trial 14 finished with value: 0.6203485633537448 and parameters: {'tmin': 190, 'filter_order': 6, 'fs': 140, 'n_estimators': 250, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.6287495905872867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.986 | Val acc: 0.620\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:24:57,118] Trial 15 finished with value: 0.6401474897251754 and parameters: {'tmin': 210, 'filter_order': 5, 'fs': 80, 'n_estimators': 150, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.993 | Val acc: 0.640\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:26:19,684] Trial 16 finished with value: 0.6339468302658487 and parameters: {'tmin': 200, 'filter_order': 5, 'fs': 70, 'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.993 | Val acc: 0.634\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 14/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:27:52,643] Trial 17 finished with value: 0.6258982863460475 and parameters: {'tmin': 150, 'filter_order': 5, 'fs': 70, 'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.991 | Val acc: 0.626\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:29:15,436] Trial 18 finished with value: 0.6273399402233758 and parameters: {'tmin': 200, 'filter_order': 5, 'fs': 90, 'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.994 | Val acc: 0.627\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:30:35,267] Trial 19 finished with value: 0.5987122766091515 and parameters: {'tmin': 210, 'filter_order': 5, 'fs': 150, 'n_estimators': 150, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.994 | Val acc: 0.599\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:31:57,118] Trial 20 finished with value: 0.6143656088747909 and parameters: {'tmin': 160, 'filter_order': 5, 'fs': 90, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.993 | Val acc: 0.614\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:33:19,704] Trial 21 finished with value: 0.623263888888889 and parameters: {'tmin': 220, 'filter_order': 6, 'fs': 110, 'n_estimators': 150, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.987 | Val acc: 0.623\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:34:47,501] Trial 22 finished with value: 0.6268008447322945 and parameters: {'tmin': 180, 'filter_order': 6, 'fs': 130, 'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.995 | Val acc: 0.627\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 15/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:36:07,370] Trial 23 finished with value: 0.6199494949494949 and parameters: {'tmin': 220, 'filter_order': 5, 'fs': 90, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.993 | Val acc: 0.620\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 16/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:37:23,527] Trial 24 finished with value: 0.6306058941973275 and parameters: {'tmin': 250, 'filter_order': 5, 'fs': 70, 'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 15 with value: 0.6401474897251754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.991 | Val acc: 0.631\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 16/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:38:38,145] Trial 25 finished with value: 0.6522057477576423 and parameters: {'tmin': 250, 'filter_order': 5, 'fs': 80, 'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.6522057477576423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.999 | Val acc: 0.652\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:40:17,552] Trial 26 finished with value: 0.6366762966020084 and parameters: {'tmin': 140, 'filter_order': 5, 'fs': 130, 'n_estimators': 350, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.6522057477576423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 1.000 | Val acc: 0.637\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:41:58,254] Trial 27 finished with value: 0.5725037218010649 and parameters: {'tmin': 120, 'filter_order': 5, 'fs': 160, 'n_estimators': 350, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.6522057477576423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 1.000 | Val acc: 0.573\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:43:40,780] Trial 28 finished with value: 0.634200027514101 and parameters: {'tmin': 140, 'filter_order': 5, 'fs': 130, 'n_estimators': 350, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.6522057477576423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 1.000 | Val acc: 0.634\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 12/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:46:06,284] Trial 29 finished with value: 0.6585397435343119 and parameters: {'tmin': 70, 'filter_order': 3, 'fs': 90, 'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 29 with value: 0.6585397435343119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.998 | Val acc: 0.659\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:47:51,512] Trial 30 finished with value: 0.6598790349742903 and parameters: {'tmin': 60, 'filter_order': 3, 'fs': 100, 'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.660\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:49:38,598] Trial 31 finished with value: 0.6503664826825545 and parameters: {'tmin': 60, 'filter_order': 3, 'fs': 90, 'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.999 | Val acc: 0.650\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:52:30,619] Trial 32 finished with value: 0.6586590617640045 and parameters: {'tmin': 60, 'filter_order': 3, 'fs': 100, 'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.659\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:55:39,434] Trial 33 finished with value: 0.6492184660123591 and parameters: {'tmin': 30, 'filter_order': 3, 'fs': 100, 'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.649\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:57:27,529] Trial 34 finished with value: 0.6571958701406393 and parameters: {'tmin': 60, 'filter_order': 3, 'fs': 120, 'n_estimators': 350, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.992 | Val acc: 0.657\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:59:05,147] Trial 35 finished with value: 0.6424205898359339 and parameters: {'tmin': 80, 'filter_order': 3, 'fs': 120, 'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.993 | Val acc: 0.642\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:00:50,886] Trial 36 finished with value: 0.5824796305108507 and parameters: {'tmin': 0, 'filter_order': 3, 'fs': 170, 'n_estimators': 400, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.582\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:02:40,004] Trial 37 finished with value: 0.5758540771605508 and parameters: {'tmin': 60, 'filter_order': 3, 'fs': 280, 'n_estimators': 350, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.576\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:04:25,374] Trial 38 finished with value: 0.5713074033684721 and parameters: {'tmin': 30, 'filter_order': 3, 'fs': 170, 'n_estimators': 250, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.571\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:06:07,729] Trial 39 finished with value: 0.5759239671893822 and parameters: {'tmin': 90, 'filter_order': 3, 'fs': 230, 'n_estimators': 450, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.996 | Val acc: 0.576\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:08:05,108] Trial 40 finished with value: 0.6451652089407192 and parameters: {'tmin': 50, 'filter_order': 4, 'fs': 120, 'n_estimators': 400, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.999 | Val acc: 0.645\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:09:48,090] Trial 41 finished with value: 0.6557433250158794 and parameters: {'tmin': 80, 'filter_order': 3, 'fs': 100, 'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.996 | Val acc: 0.656\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:11:30,271] Trial 42 finished with value: 0.6497643092264723 and parameters: {'tmin': 80, 'filter_order': 3, 'fs': 100, 'n_estimators': 350, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 30 with value: 0.6598790349742903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.997 | Val acc: 0.650\n",
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 13/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-28 20:13:04,212] Trial 43 failed with parameters: {'tmin': 100, 'filter_order': 3, 'fs': 100, 'n_estimators': 300, 'min_samples_split': 8, 'min_samples_leaf': 3} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_81244/3846833443.py\", line 178, in objective\n",
      "    scores = cross_validate(clf, X, y, cv=cv, scoring=\"accuracy\", return_train_score=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 915, in _fit_and_score\n",
      "    train_scores = _score(\n",
      "                   ^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_81244/3846833443.py\", line 67, in predict\n",
      "    fb_covs = self.compute_fb_covs(X)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_81244/3846833443.py\", line 25, in compute_fb_covs\n",
      "    fb_covs[:, i] = Covariances(estimator=\"lwf\").transform(Xf)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/estimation.py\", line 77, in transform\n",
      "    covmats = covariances(X, estimator=self.estimator, **self.kwds)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py\", line 400, in covariances\n",
      "    covmats[i] = est(X[i], **kwds)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py\", line 48, in wrapper\n",
      "    cov = func(X, **kwds)\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py\", line 61, in _lwf\n",
      "    C, _ = ledoit_wolf(X.T, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 464, in ledoit_wolf\n",
      "    ).fit(X)\n",
      "      ^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 605, in fit\n",
      "    covariance, shrinkage = _ledoit_wolf(\n",
      "                            ^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 40, in _ledoit_wolf\n",
      "    emp_cov = empirical_covariance(X, assume_centered=assume_centered)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_empirical_covariance.py\", line 107, in empirical_covariance\n",
      "    covariance = np.dot(X.T, X) / X.shape[0]\n",
      "                 ^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-28 20:13:04,225] Trial 43 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 190\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m val_acc\n\u001b[32m    189\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, pruner=MedianPruner())\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Best trial ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m best = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 178\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    175\u001b[39m clf.fit = custom_fit\n\u001b[32m    177\u001b[39m cv = StratifiedKFold(cv_folds, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m scores = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m train_acc = scores[\u001b[33m\"\u001b[39m\u001b[33mtrain_score\u001b[39m\u001b[33m\"\u001b[39m].mean()\n\u001b[32m    181\u001b[39m val_acc = scores[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m].mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    209\u001b[39m         skip_parameter_validation=(\n\u001b[32m    210\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    211\u001b[39m         )\n\u001b[32m    212\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    219\u001b[39m     msg = re.sub(\n\u001b[32m    220\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:423\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    422\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     69\u001b[39m config = get_config()\n\u001b[32m     70\u001b[39m iterable_with_config = (\n\u001b[32m     71\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     73\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m     config = {}\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:915\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    913\u001b[39m     score_time = time.time() - start_time - fit_time\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         train_scores = \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose > \u001b[32m1\u001b[39m:\n\u001b[32m    920\u001b[39m     total_time = score_time + fit_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971\u001b[39m, in \u001b[36m_score\u001b[39m\u001b[34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[39m\n\u001b[32m    969\u001b[39m         scores = scorer(estimator, X_test, **score_params)\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m         scores = \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    973\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[32m    974\u001b[39m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[32m    975\u001b[39m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:279\u001b[39m, in \u001b[36m_BaseScorer.__call__\u001b[39m\u001b[34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    277\u001b[39m     _kwargs[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:371\u001b[39m, in \u001b[36m_Scorer._score\u001b[39m\u001b[34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m pos_label = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_pos_label()\n\u001b[32m    370\u001b[39m response_method = _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m._response_method)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m y_pred = \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m scoring_kwargs = {**\u001b[38;5;28mself\u001b[39m._kwargs, **kwargs}\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sign * \u001b[38;5;28mself\u001b[39m._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:89\u001b[39m, in \u001b[36m_cached_call\u001b[39m\u001b[34m(cache, estimator, response_method, *args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m result, _ = \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     94\u001b[39m     cache[response_method] = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_response.py:211\u001b[39m, in \u001b[36m_get_response_values\u001b[39m\u001b[34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[39m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    209\u001b[39m         pos_label = classes[-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m y_pred = \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction_method.\u001b[34m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_log_proba\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    214\u001b[39m     y_pred = _process_predict_proba(\n\u001b[32m    215\u001b[39m         y_pred=y_pred,\n\u001b[32m    216\u001b[39m         target_type=target_type,\n\u001b[32m    217\u001b[39m         classes=classes,\n\u001b[32m    218\u001b[39m         pos_label=pos_label,\n\u001b[32m    219\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mFilterBankRTSClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     fb_covs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_fb_covs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     n, B, C, _ = fb_covs.shape\n\u001b[32m     70\u001b[39m     covs_flat = fb_covs.reshape(n * B, C, C)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mFilterBankRTSClassifier.compute_fb_covs\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, sos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.sos_bands):\n\u001b[32m     24\u001b[39m     Xf = sosfiltfilt(sos, X, axis=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     fb_covs[:, i] = \u001b[43mCovariances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlwf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fb_covs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/estimation.py:77\u001b[39m, in \u001b[36mCovariances.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m     65\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate covariance matrices.\u001b[39;00m\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m \u001b[33;03m        Covariance matrices.\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     covmats = \u001b[43mcovariances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m covmats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py:400\u001b[39m, in \u001b[36mcovariances\u001b[39m\u001b[34m(X, estimator, **kwds)\u001b[39m\n\u001b[32m    398\u001b[39m covmats = np.empty((n_matrices, n_channels, n_channels), dtype=X.dtype)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_matrices):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     covmats[i] = \u001b[43mest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m covmats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py:48\u001b[39m, in \u001b[36m_complex_estimator.<locals>.wrapper\u001b[39m\u001b[34m(X, **kwds)\u001b[39m\n\u001b[32m     46\u001b[39m     n_channels, n_times = X.shape\n\u001b[32m     47\u001b[39m     X = np.concatenate((X.real, X.imag), axis=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m cov = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iscomplex:\n\u001b[32m     50\u001b[39m     cov = cov[:n_channels, :n_channels] \\\n\u001b[32m     51\u001b[39m         + cov[n_channels:, n_channels:] \\\n\u001b[32m     52\u001b[39m         + \u001b[32m1\u001b[39mj * (cov[n_channels:, :n_channels]\n\u001b[32m     53\u001b[39m                 - cov[:n_channels, n_channels:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py:61\u001b[39m, in \u001b[36m_lwf\u001b[39m\u001b[34m(X, **kwds)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;129m@_complex_estimator\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lwf\u001b[39m(X, **kwds):\n\u001b[32m     60\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper for sklearn ledoit wolf covariance estimator\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     C, _ = \u001b[43mledoit_wolf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    209\u001b[39m         skip_parameter_validation=(\n\u001b[32m    210\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    211\u001b[39m         )\n\u001b[32m    212\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    219\u001b[39m     msg = re.sub(\n\u001b[32m    220\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:464\u001b[39m, in \u001b[36mledoit_wolf\u001b[39m\u001b[34m(X, assume_centered, block_size)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m    406\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m]},\n\u001b[32m    407\u001b[39m     prefer_skip_nested_validation=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    408\u001b[39m )\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mledoit_wolf\u001b[39m(X, *, assume_centered=\u001b[38;5;28;01mFalse\u001b[39;00m, block_size=\u001b[32m1000\u001b[39m):\n\u001b[32m    410\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate the shrunk Ledoit-Wolf covariance matrix.\u001b[39;00m\n\u001b[32m    411\u001b[39m \n\u001b[32m    412\u001b[39m \u001b[33;03m    Read more in the :ref:`User Guide <shrunk_covariance>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    458\u001b[39m \u001b[33;03m    np.float64(0.23...)\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    460\u001b[39m     estimator = \u001b[43mLedoitWolf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m=\u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstore_precision\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator.covariance_, estimator.shrinkage_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:605\u001b[39m, in \u001b[36mLedoitWolf.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    604\u001b[39m     \u001b[38;5;28mself\u001b[39m.location_ = X.mean(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m covariance, shrinkage = \u001b[43m_ledoit_wolf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocation_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock_size\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[38;5;28mself\u001b[39m.shrinkage_ = shrinkage\n\u001b[32m    609\u001b[39m \u001b[38;5;28mself\u001b[39m._set_covariance(covariance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:40\u001b[39m, in \u001b[36m_ledoit_wolf\u001b[39m\u001b[34m(X, assume_centered, block_size)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# get Ledoit-Wolf shrinkage\u001b[39;00m\n\u001b[32m     37\u001b[39m shrinkage = ledoit_wolf_shrinkage(\n\u001b[32m     38\u001b[39m     X, assume_centered=assume_centered, block_size=block_size\n\u001b[32m     39\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m emp_cov = \u001b[43mempirical_covariance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m=\u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m mu = np.sum(np.trace(emp_cov)) / n_features\n\u001b[32m     42\u001b[39m shrunk_cov = (\u001b[32m1.0\u001b[39m - shrinkage) * emp_cov\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m func_sig = signature(func)\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_empirical_covariance.py:107\u001b[39m, in \u001b[36mempirical_covariance\u001b[39m\u001b[34m(X, assume_centered)\u001b[39m\n\u001b[32m    102\u001b[39m     warnings.warn(\n\u001b[32m    103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOnly one sample available. You may want to reshape your data array\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    104\u001b[39m     )\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m assume_centered:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     covariance = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m / X.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    109\u001b[39m     covariance = np.cov(X.T, bias=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def load_eeg_data(data_path, window_length, stride, tmin, eeg_channels):\n",
    "    ds = EEGDataset(\n",
    "        data_path,\n",
    "        window_length=window_length,\n",
    "        stride=stride,\n",
    "        task=\"mi\",\n",
    "        split=\"train\",\n",
    "        data_fraction=0.4,\n",
    "        tmin=tmin,\n",
    "        eeg_channels=eeg_channels,\n",
    "    )\n",
    "    X = np.stack([x.numpy() for x, _ in ds])\n",
    "    y = np.array([label[0] for _, label in ds])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Optuna optimization\n",
    "data_path = \"./data/mtcaic3\"\n",
    "cv_folds = 3\n",
    "\n",
    "window_length = 1000\n",
    "stride = 85\n",
    "eeg_channels = ['FZ', 'CZ', 'PZ', 'C3', 'OZ']\n",
    "\n",
    "def objective(trial):\n",
    "    # Data parameters\n",
    "    tmin = trial.suggest_int(\"tmin\", 0, 250, step=10)\n",
    "\n",
    "    # Filter bank parameters\n",
    "    filter_order = trial.suggest_int(\"filter_order\", 3, 6)\n",
    "    fs = trial.suggest_int(\"fs\", 70, 300, step=10)\n",
    "\n",
    "    # Random Forest parameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500, step=50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
    "\n",
    "    try:\n",
    "        X, y = load_eeg_data(data_path, window_length=window_length, stride=stride, tmin=tmin, eeg_channels=eeg_channels)\n",
    "    except Exception as e:\n",
    "        print(\"Data loading failed:\", e)\n",
    "        return 0.0\n",
    "\n",
    "    clf = FilterBankRTSClassifier(fs=fs, order=filter_order, n_estimators=n_estimators, max_depth=max_depth, class_weight=\"balanced\", n_jobs=-1)\n",
    "\n",
    "    # Add RF-specific parameters\n",
    "    clf.min_samples_split = min_samples_split\n",
    "    clf.min_samples_leaf = min_samples_leaf\n",
    "    clf.max_features = max_features\n",
    "\n",
    "    # Override the classifier creation in fit method\n",
    "    original_fit = clf.fit\n",
    "\n",
    "    def custom_fit(X, y):\n",
    "        # Store the classes - this is required by scikit-learn\n",
    "        clf.classes_ = np.unique(y)\n",
    "\n",
    "        fb_covs = clf.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        labels_rep = np.repeat(y, B)\n",
    "\n",
    "        clf.ts = TangentSpace(metric=\"riemann\").fit(covs_flat, labels_rep)\n",
    "        Z = clf.ts.transform(covs_flat)\n",
    "        Z = Z.reshape(n, B, -1)\n",
    "\n",
    "        clf.w = mutual_info_classif(Z.reshape(n, -1), y, discrete_features=False).reshape(B, -1).mean(axis=1)\n",
    "        clf.w = clf.w / clf.w.sum()\n",
    "\n",
    "        Z_weighted = np.concatenate([np.sqrt(clf.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        clf.clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=None,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                max_features='sqrt',\n",
    "                class_weight=\"balanced\",\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        )\n",
    "        clf.clf.fit(Z_weighted, y)\n",
    "        return clf\n",
    "\n",
    "    clf.fit = custom_fit\n",
    "\n",
    "    cv = StratifiedKFold(cv_folds, shuffle=True, random_state=42)\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=\"accuracy\", return_train_score=True)\n",
    "\n",
    "    train_acc = scores[\"train_score\"].mean()\n",
    "    val_acc = scores[\"test_score\"].mean()\n",
    "\n",
    "    print(f\"   → Train acc: {train_acc:.3f} | Val acc: {val_acc:.3f}\")\n",
    "    trial.set_user_attr(\"train_acc\", train_acc)\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner())\n",
    "study.optimize(objective, n_trials=50 , timeout=7200)\n",
    "\n",
    "print(\"\\n=== Best trial ===\")\n",
    "best = study.best_trial\n",
    "print(\"Val Acc:\", best.value)\n",
    "print(\"Train Acc:\", best.user_attrs[\"train_acc\"])\n",
    "print(\"Params:\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f62b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 67 finished with value: 0.6263345734944465 and parameters: {'window_length': 250, 'stride': 250, 'tmin': 0, 'ch_FZ': 1, 'ch_C3': 0, 'ch_CZ': 1, 'ch_C4': 0, 'ch_PZ': 1, 'ch_PO7': 1, 'ch_OZ': 1, 'ch_PO8': 0, 'n_bands': 4, 'min_freq': 11, 'max_freq': 40, 'filter_order': 3, 'fs': 125, 'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 67 with value: 0.6263345734944465.\n",
    "\n",
    "class FilterBankRTSClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, bands=None, fs=250, order=4, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=\"sqrt\", class_weight=\"balanced\", n_jobs=-1):\n",
    "        self.bands = bands if bands else [(8, 12), (12, 16), (16, 20), (20, 24), (24, 30)]\n",
    "        self.fs = fs\n",
    "        self.order = order\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.class_weight = class_weight\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def compute_fb_covs(self, X):\n",
    "        \"\"\"X: (n_trials, C, T) → fb_covs: (n_trials, B, C, C)\"\"\"\n",
    "        # Pre-compute SOS filters if not done\n",
    "        if not hasattr(self, \"sos_bands\"):\n",
    "            self.sos_bands = [butter(self.order, (l / (self.fs / 2), h / (self.fs / 2)), btype=\"bandpass\", output=\"sos\") for l, h in self.bands]\n",
    "\n",
    "        n, C, _ = X.shape\n",
    "        B = len(self.sos_bands)\n",
    "        fb_covs = np.zeros((n, B, C, C))\n",
    "        for i, sos in enumerate(self.sos_bands):\n",
    "            Xf = sosfiltfilt(sos, X, axis=2)\n",
    "            fb_covs[:, i] = Covariances(estimator=\"lwf\").transform(Xf)\n",
    "        return fb_covs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        # Flatten for tangent space\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        labels_rep = np.repeat(y, B)\n",
    "\n",
    "        # Fit tangent space\n",
    "        self.ts = TangentSpace(metric=\"riemann\").fit(covs_flat, labels_rep)\n",
    "        Z = self.ts.transform(covs_flat)\n",
    "        Z = Z.reshape(n, B, -1)\n",
    "\n",
    "        # Compute mutual information weights\n",
    "        self.w = mutual_info_classif(Z.reshape(n, -1), y, discrete_features=False).reshape(B, -1).mean(axis=1)\n",
    "        self.w = self.w / self.w.sum()\n",
    "\n",
    "        # Weight features\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        # Train classifier\n",
    "        self.clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                max_features=self.max_features,\n",
    "                class_weight=self.class_weight,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        )\n",
    "        self.clf.fit(Z_weighted, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        Z = self.ts.transform(covs_flat).reshape(n, B, -1)\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        return self.clf.predict(Z_weighted)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        Z = self.ts.transform(covs_flat).reshape(n, B, -1)\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        return self.clf.predict_proba(Z_weighted)\n",
    "\n",
    "        \n",
    "window_length = 1000\n",
    "# Best parameters from Optuna trial 67\n",
    "stride = 250\n",
    "tmin = 0\n",
    "eeg_channels = ['FZ', 'CZ', 'PZ', 'PO7', 'OZ']\n",
    "n_bands = 4\n",
    "min_freq = 11\n",
    "max_freq = 40\n",
    "filter_order = 3\n",
    "fs = 125\n",
    "n_estimators = 200\n",
    "max_depth = None\n",
    "min_samples_split = 6\n",
    "min_samples_leaf = 2\n",
    "max_features = 'sqrt'\n",
    "data_path = \"./data/mtcaic3\"\n",
    "\n",
    "\n",
    "# Load data with besjt parameters\n",
    "ds_train = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task=\"mi\",\n",
    "    split=\"train\",\n",
    "    data_fraction=1,\n",
    "    tmin=tmin,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "X_train = np.stack([x.numpy() for x, _ in ds_train])\n",
    "y_train = np.array([label[0] for _, label in ds_train])\n",
    "\n",
    "# Load data with besjt parameters\n",
    "ds_val = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task=\"mi\",\n",
    "    split=\"train\",\n",
    "    data_fraction=1,\n",
    "    tmin=tmin,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "X_val = np.stack([x.numpy() for x, _ in ds_val])\n",
    "y_val = np.array([label[0] for _, label in ds_val])\n",
    "\n",
    "\n",
    "# Create frequency bands\n",
    "\n",
    "# Create FilterBank classifier with best parameters\n",
    "clf = FilterBankRTSClassifier(\n",
    "    fs=fs,\n",
    "    order=filter_order,\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf# Trial 67 finished with value: 0.6263345734944465 and parameters: {'window_length': 250, 'stride': 250, 'tmin': 0, 'ch_FZ': 1, 'ch_C3': 0, 'ch_CZ': 1, 'ch_C4': 0, 'ch_PZ': 1, 'ch_PO7': 1, 'ch_OZ': 1, 'ch_PO8': 0, 'n_bands': 4, 'min_freq': 11, 'max_freq': 40, 'filter_order': 3, 'fs': 125, 'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 67 with value: 0.6263345734944465.\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "y_pred = clf.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
