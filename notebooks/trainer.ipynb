{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a563374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download datasetaset files: \n",
      " /home/zeyadcode/.cache/kagglehub/datasets/girgismicheal/steadystate-visual-evoked-potential-signals/versions/1/SSVEP (BrainWheel)\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "# path_1 = kagglehub.dataset_download(\"xuannguyenuet2004/12-class-ssvep-eeg-data\") proofed to be bad\n",
    "path_1 = kagglehub.dataset_download(\"girgismicheal/steadystate-visual-evoked-potential-signals\")\n",
    "path_1 += \"/SSVEP (BrainWheel)\"\n",
    "print(\"Download datasetaset files:\", \"\\n\", path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dec2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMS\n",
    "WINDOW_LENGTH = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# PARAMS RELATED TO DATASET ONLY\n",
    "TRIAL_LENGTH = 640  # frequency of changing.. frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_path, trial_length, window_length=128, stride=None) -> None:\n",
    "        \"\"\"\n",
    "        todo complete documentation\n",
    "        trial_length: the number of rows before frequency shift in the dataset\n",
    "\n",
    "        N: sample length\n",
    "        C: channels (number of electrodes)\n",
    "        B: Batch Size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert trial_length % window_length == 0, \"Please choose window_length that divides by trial_length\"\n",
    "        self.data_path = data_path\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        if stride == None:\n",
    "            stride = window_length\n",
    "\n",
    "        # Load all subjects' data\n",
    "        subject_dirs = [d for d in os.listdir(data_path) if d.startswith(\"subject_\")]\n",
    "\n",
    "        for subject_dir in subject_dirs:\n",
    "            subject_path = os.path.join(data_path, subject_dir)\n",
    "            sample_files = [f for f in os.listdir(subject_path) if f.endswith(\".csv\")]\n",
    "\n",
    "            for sample_file in sample_files:\n",
    "                sample_file_path = os.path.join(subject_path, sample_file)\n",
    "                df = pd.read_csv(sample_file_path, header=None, skiprows=1)  # samples x (electrodes + 1)\n",
    "\n",
    "                freqs = df.iloc[:, -1].values\n",
    "\n",
    "                # first get of shape trial_length x freq\n",
    "                n_rows = len(freqs)\n",
    "                n_trials = n_rows // trial_length\n",
    "                for t in range(n_trials):\n",
    "                    start = t * trial_length\n",
    "                    end = start + trial_length\n",
    "                    block_freqs = freqs[start:end]  # shape Nx1\n",
    "\n",
    "                    assert np.all(block_freqs == block_freqs[0]), f\"Mixed labels in trial {t} of {sample_file}\"\n",
    "\n",
    "                    # trial_label = np.ones([window_length, 1]) * freqs[0]\n",
    "                    trial_label = block_freqs[0]\n",
    "                    trial_data = df.iloc[start:end, :-1].values  # shape [trial_length x C]\n",
    "\n",
    "                    for i in range(0, trial_length - window_length + 1, stride):\n",
    "                        win = trial_data[i: i + window_length, :].T # C x trial_window\n",
    "                        self.data.append(win.astype(np.float32))\n",
    "                        self.labels.append(trial_label)\n",
    "\n",
    "\n",
    "        self.data = np.array(self.data) # B x C x window_length = 5200 x 14 x 128\n",
    "        self.labels = np.array(self.labels) # B x 1 = 5200 x 1 \n",
    "\n",
    "        self.data = torch.tensor(self.data)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = EEGDataset(path_1, TRIAL_LENGTH, WINDOW_LENGTH, stride=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6fada6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3328, 832, 1040)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.data.numpy()\n",
    "Y = dataset.labels.numpy()\n",
    "\n",
    "\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y,\n",
    ")\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    Y_train_val,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y_train_val,\n",
    ")\n",
    "\n",
    "# Turn to tensors\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "Y_train_t = torch.from_numpy(Y_train).long()\n",
    "\n",
    "X_val_t   = torch.from_numpy(X_val).float()\n",
    "Y_val_t   = torch.from_numpy(Y_val).long()\n",
    "\n",
    "X_test_t  = torch.from_numpy(X_test).float()\n",
    "Y_test_t  = torch.from_numpy(Y_test).long()\n",
    "\n",
    "# Build dataset\n",
    "train_ds = TensorDataset(X_train_t, Y_train_t)\n",
    "val_ds   = TensorDataset(X_val_t,   Y_val_t)\n",
    "test_ds  = TensorDataset(X_test_t,  Y_test_t)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "299a4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(val_ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_ds,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
