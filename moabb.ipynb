{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4be59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from braindecode.models import EEGNetv4\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "from moabb.datasets.base import BaseDataset\n",
    "from moabb.paradigms import SSVEP\n",
    "from moabb.pipelines import SSVEP_CCA\n",
    "from moabb.pipelines.features import StandardScaler_Epoch\n",
    "from moabb.evaluations import WithinSessionEvaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d225ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dataset class name 'CompetitionDataset' must be an abbreviation of its code 'Competition'. See moabb.datasets.base.is_abbrev for more information.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 17495 and the array at index 1 has size 17500",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata_df\n\u001b[32m    111\u001b[39m dataset = CompetitionDataset()\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_single_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mCompetitionDataset._get_single_subject_data\u001b[39m\u001b[34m(self, subject)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Combine EEG and stimulus data\u001b[39;00m\n\u001b[32m     73\u001b[39m eeg_data = eeg_data[:, mask]\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m full_data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43meeg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstim_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Create Raw object\u001b[39;00m\n\u001b[32m     77\u001b[39m raw = mne.io.RawArray(data=full_data, info=info, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/numpy/core/shape_base.py:289\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    288\u001b[39m     arrs = [arrs]\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 17495 and the array at index 1 has size 17500"
     ]
    }
   ],
   "source": [
    "n_subjects = 30\n",
    "n_sessions = 8\n",
    "start_time = 1\n",
    "end_time = 6\n",
    "split = \"train\"\n",
    "\n",
    "label_to_freq = {\"Left\": \"10\", \"Right\": \"13\", \"Forward\": \"7\", \"Backward\": \"8\"}\n",
    "event_mapping = {\"10\": 0, \"13\": 1, \"7\": 2, \"8\": 3}\n",
    "event_mapping_decoder = np.vectorize({0: \"10\", 1: \"13\", 2: \"7\", 3: \"8\"}.get)\n",
    "\n",
    "\n",
    "class CompetitionDataset(BaseDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            subjects=list(range(1, n_subjects + 1)),\n",
    "            sessions_per_subject=n_sessions,\n",
    "            events=event_mapping,\n",
    "            code=\"Competition\",\n",
    "            interval=[start_time, end_time],\n",
    "            paradigm=\"ssvep\",\n",
    "        )\n",
    "\n",
    "        self.base_path = \"./data/mtcaic3/SSVEP\"\n",
    "        self.metadata_path = os.path.join('./data/mtcaic3', f\"{split}.csv\")\n",
    "\n",
    "    def data_path(self, subject, path=None, force_update=False, update_path=None, verbose=None):  # type: ignore\n",
    "        \"\"\"Return list of CSV file paths for this subject.\"\"\"\n",
    "        subject_dir = os.path.join(self.base_path, split, f\"S{int(subject)}\")\n",
    "        csv_files = []\n",
    "\n",
    "        # Collect all 8 session files for this subject\n",
    "        for session in range(1, n_sessions + 1):\n",
    "            csv_file = os.path.join(subject_dir, str(session), \"EEGdata.csv\")\n",
    "            if os.path.exists(csv_file):\n",
    "                csv_files.append(csv_file)\n",
    "            else:\n",
    "                print(f\"Warning: {csv_file} does not exist for subject {subject}, session {session}\")\n",
    "\n",
    "        return csv_files\n",
    "\n",
    "    def _get_single_subject_data(self, subject):  # type: ignore\n",
    "        \"\"\"Load and process data for a single subject.\"\"\"\n",
    "        csv_files = self.data_path(subject)\n",
    "        sessions = {}\n",
    "\n",
    "        for session_idx, csv_file in enumerate(csv_files):\n",
    "            # Load CSV data\n",
    "            # todo neglect invalid cols\n",
    "            eeg_columns = [\"FZ\", \"C3\", \"CZ\", \"C4\", \"PZ\", \"PO7\", \"OZ\", \"PO8\"]\n",
    "            df = pd.read_csv(csv_file, usecols=eeg_columns + [\"Validation\"])\n",
    "\n",
    "            mask = df['Validation'] == 1\n",
    "            eeg_data = df[eeg_columns].values.T  # Shape: (n_channels, n_timepoints)\n",
    "\n",
    "            # Create channel info\n",
    "            ch_names = eeg_columns + [\"stim\"]\n",
    "            ch_types = [\"eeg\"] * len(eeg_columns) + [\"stim\"]\n",
    "            sfreq = 250  # Your sampling frequency\n",
    "\n",
    "            info = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)  # type: ignore\n",
    "\n",
    "            # Create stimulus channel from event labels\n",
    "            # Assuming you have 10 trials of 1750 samples each\n",
    "            stim_data = np.zeros(len(df))\n",
    "\n",
    "            for trial in range(10):\n",
    "                trial_start = trial * 1750\n",
    "                if trial_start < len(df):\n",
    "                    trial_label = self._get_trial_label(subject, session_idx + 1, trial + 1)\n",
    "                    stim_data[trial_start] = event_mapping.get(trial_label)\n",
    "\n",
    "            # Combine EEG and stimulus data\n",
    "            eeg_data = eeg_data[:, mask]\n",
    "            full_data = np.vstack([eeg_data, stim_data[np.newaxis, :]])\n",
    "\n",
    "            # Create Raw object\n",
    "            raw = mne.io.RawArray(data=full_data, info=info, verbose=False)\n",
    "\n",
    "            # Store in sessions dictionary\n",
    "            session_name = str(session_idx)\n",
    "            if session_name not in sessions:\n",
    "                sessions[session_name] = {}\n",
    "            sessions[session_name][\"0\"] = raw  # Single run per session\n",
    "\n",
    "        return sessions\n",
    "\n",
    "    def _get_trial_label(self, subject_id, session_id, trial_idx):\n",
    "        \"\"\"Extract the event label for a specific trial.\"\"\"\n",
    "        metadata_df = self._load_metadata()\n",
    "\n",
    "        trial_number = trial_idx\n",
    "        subject_str = f\"S{subject_id}\"\n",
    "\n",
    "        # Filter the metadata for this specific trial\n",
    "        trial_row = metadata_df[\n",
    "            (metadata_df[\"subject_id\"] == subject_str) & (metadata_df[\"trial_session\"] == session_id) & (metadata_df[\"trial\"] == trial_number) & (metadata_df[\"task\"] == \"SSVEP\")  # Extra safety filter\n",
    "        ]\n",
    "        \n",
    "        label = trial_row.iloc[0][\"label\"]\n",
    "        return label_to_freq.get(label)\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load the metadata CSV file once and cache it.\"\"\"\n",
    "        if not hasattr(self, \"_metadata_df\"):\n",
    "            self._metadata_df = pd.read_csv(self.metadata_path)\n",
    "            self._metadata_df = self._metadata_df[self._metadata_df[\"task\"] == \"SSVEP\"]\n",
    "\n",
    "        return self._metadata_df\n",
    "\n",
    "\n",
    "dataset = CompetitionDataset()\n",
    "dataset._get_single_subject_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae73d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing the first 4 classes from all possible events\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 4 events (all good), 2 – 7 s (baseline off), ~323 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 0\n",
      " '7': 1\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 0\n",
      " '7': 1\n",
      " '8': 4>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 4\n",
      " '7': 1\n",
      " '8': 1>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 1\n",
      " '8': 5>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 0\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 4\n",
      " '7': 1\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 4\n",
      " '7': 1\n",
      " '8': 1>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 2\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 2\n",
      " '7': 0\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 1\n",
      " '8': 4>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 5\n",
      " '7': 2\n",
      " '8': 0>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 1\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 4 events (all good), 2 – 7 s (baseline off), ~323 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 2\n",
      " '7': 0\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 2\n",
      " '7': 2\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 4\n",
      " '7': 2\n",
      " '8': 0>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 2\n",
      " '7': 3\n",
      " '8': 0>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 4 events (all good), 2 – 7 s (baseline off), ~323 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 0\n",
      " '7': 1\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 2\n",
      " '7': 3\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 4\n",
      " '7': 2\n",
      " '8': 0>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 1\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 3\n",
      " '8': 3>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 2\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 2\n",
      " '8': 4>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 2\n",
      " '7': 3\n",
      " '8': 1>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 0\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 0\n",
      " '8': 6>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 1\n",
      " '8': 1>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 8 events (all good), 2 – 7 s (baseline off), ~636 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 4\n",
      " '7': 2\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 6 events (all good), 2 – 7 s (baseline off), ~480 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 1\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 7 events (all good), 2 – 7 s (baseline off), ~558 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 3\n",
      " '7': 0\n",
      " '8': 4>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 4 events (all good), 2 – 7 s (baseline off), ~323 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 2\n",
      " '8': 1>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 5 events (all good), 2 – 7 s (baseline off), ~402 KiB, data loaded,\n",
      " '10': 0\n",
      " '13': 1\n",
      " '7': 2\n",
      " '8': 2>\n",
      "  warn(f\"warnEpochs {epochs}\")\n"
     ]
    }
   ],
   "source": [
    "paradigm = SSVEP(n_classes=4, tmin=start_time, tmax=end_time)\n",
    "\n",
    "# # Get the data\n",
    "X, y, metadata = paradigm.get_data(dataset, subjects=list(range(1, 5)))  # , subjects=[1, 2])\n",
    "freqs = paradigm.used_events(dataset)\n",
    "interval = [paradigm.tmin, paradigm.tmax]\n",
    "# Create label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA 62.2%\n",
    "cca_clf = Pipeline([    \n",
    "    ('standardize', StandardScaler_Epoch()),  \n",
    "    (\"classifier\", SSVEP_CCA(interval=interval, freqs=freqs, n_harmonics=4)),\n",
    "    ])\n",
    "\n",
    "# custom_splitter = WithinSessionSplitter(n_folds=2)\n",
    "evaluation = WithinSessionEvaluation(paradigm=paradigm, datasets=[dataset], cv=custom_splitter)\n",
    "# pipeline = {\"SSVEP_CCA\": Pipeline([(\"classifier\", cca_clf)])}\n",
    "\n",
    "# results = evaluation.process(pipeline)\n",
    "\n",
    "cca_clf.fit(X, y_encoded)\n",
    "y_pred = cca_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 8, 1251])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'n_classes' is depreciated. Use 'n_outputs' instead.\n",
      "  warnings.warn(\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     26\u001b[39m net = NeuralNetClassifier(\n\u001b[32m     27\u001b[39m     torch_module,\n\u001b[32m     28\u001b[39m     criterion=nn.CrossEntropyLoss(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     max_epochs=\u001b[32m100\u001b[39m,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Use with your correctly shaped data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m y_pred = net.predict(X_tensor)  \u001b[38;5;66;03m# Use X_tensor for prediction as well\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/classifier.py:165\u001b[39m, in \u001b[36mNeuralNetClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[32m    155\u001b[39m \n\u001b[32m    156\u001b[39m \u001b[33;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m \n\u001b[32m    161\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# this is actually a pylint bug:\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNeuralNetClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1349\u001b[39m, in \u001b[36mNeuralNet.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1308\u001b[39m, in \u001b[36mNeuralNet.partial_fit\u001b[39m\u001b[34m(self, X, y, classes, **fit_params)\u001b[39m\n\u001b[32m   1306\u001b[39m \u001b[38;5;28mself\u001b[39m.notify(\u001b[33m'\u001b[39m\u001b[33mon_train_begin\u001b[39m\u001b[33m'\u001b[39m, X=X, y=y)\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1308\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1220\u001b[39m, in \u001b[36mNeuralNet.fit_loop\u001b[39m\u001b[34m(self, X, y, epochs, **fit_params)\u001b[39m\n\u001b[32m   1217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m   1218\u001b[39m     \u001b[38;5;28mself\u001b[39m.notify(\u001b[33m'\u001b[39m\u001b[33mon_epoch_begin\u001b[39m\u001b[33m'\u001b[39m, **on_epoch_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1220\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m     \u001b[38;5;28mself\u001b[39m.run_single_epoch(iterator_valid, training=\u001b[38;5;28;01mFalse\u001b[39;00m, prefix=\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1224\u001b[39m                           step_fn=\u001b[38;5;28mself\u001b[39m.validation_step, **fit_params)\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m.notify(\u001b[33m\"\u001b[39m\u001b[33mon_epoch_end\u001b[39m\u001b[33m\"\u001b[39m, **on_epoch_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1256\u001b[39m, in \u001b[36mNeuralNet.run_single_epoch\u001b[39m\u001b[34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m.notify(\u001b[33m\"\u001b[39m\u001b[33mon_batch_begin\u001b[39m\u001b[33m\"\u001b[39m, batch=batch, training=training)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     step = \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m     \u001b[38;5;28mself\u001b[39m.history.record_batch(prefix + \u001b[33m\"\u001b[39m\u001b[33m_loss\u001b[39m\u001b[33m\"\u001b[39m, step[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m].item())\n\u001b[32m   1258\u001b[39m     batch_size = (get_len(batch[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[32m   1259\u001b[39m                   \u001b[38;5;28;01melse\u001b[39;00m get_len(batch))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1135\u001b[39m, in \u001b[36mNeuralNet.train_step\u001b[39m\u001b[34m(self, batch, **fit_params)\u001b[39m\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28mself\u001b[39m.notify(\n\u001b[32m   1128\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mon_grad_computed\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1129\u001b[39m         named_parameters=TeeGenerator(\u001b[38;5;28mself\u001b[39m.get_all_learnable_params()),\n\u001b[32m   1130\u001b[39m         batch=batch,\n\u001b[32m   1131\u001b[39m         training=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1132\u001b[39m     )\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_accumulator.get_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1090\u001b[39m, in \u001b[36mNeuralNet._step_optimizer\u001b[39m\u001b[34m(self, step_fn)\u001b[39m\n\u001b[32m   1088\u001b[39m     optimizer.step()\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1090\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/adam.py:225\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n\u001b[32m    228\u001b[39m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1124\u001b[39m, in \u001b[36mNeuralNet.train_step.<locals>.step_fn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_fn\u001b[39m():\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._zero_grad_optimizer()\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1125\u001b[39m     step_accumulator.store_step(step)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28mself\u001b[39m.notify(\n\u001b[32m   1128\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mon_grad_computed\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1129\u001b[39m         named_parameters=TeeGenerator(\u001b[38;5;28mself\u001b[39m.get_all_learnable_params()),\n\u001b[32m   1130\u001b[39m         batch=batch,\n\u001b[32m   1131\u001b[39m         training=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1132\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1023\u001b[39m, in \u001b[36mNeuralNet.train_step_single\u001b[39m\u001b[34m(self, batch, **fit_params)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28mself\u001b[39m._set_training(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1022\u001b[39m Xi, yi = unpack_data(batch)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.get_loss(y_pred, yi, X=Xi, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1025\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1551\u001b[39m, in \u001b[36mNeuralNet.infer\u001b[39m\u001b[34m(self, x, **fit_params)\u001b[39m\n\u001b[32m   1549\u001b[39m     x_dict = \u001b[38;5;28mself\u001b[39m._merge_x_and_fit_params(x, fit_params)\n\u001b[32m   1550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module_(**x_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/modules.py:36\u001b[39m, in \u001b[36mExpression.forward\u001b[39m\u001b[34m(self, *x)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *x):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexpression_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/functions.py:32\u001b[39m, in \u001b[36msqueeze_final_output\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqueeze_final_output\u001b[39m(x):\n\u001b[32m     22\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Removes empty dimension at end and potentially removes empty time\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m     dimension. It does  not just use squeeze as we never want to remove\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m     first dimension.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[33;03m        squeezed tensor\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m x.size()[\u001b[32m3\u001b[39m] == \u001b[32m1\u001b[39m\n\u001b[32m     33\u001b[39m     x = x[:, :, :, \u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.size()[\u001b[32m2\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Assuming X and y_encoded are already available from your MOABB data loading\n",
    "# X.shape: ((191, 8, 1251), y_encoded.shape: (191,))\n",
    "\n",
    "# Convert X to float32 tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "mue = X_tensor.mean(dim=(0, 2), keepdim=True)\n",
    "std = (X_tensor.std(dim=(0, 2), keepdim=True) + 1e-8)\n",
    "X_tensor = (X_tensor - mue) / std\n",
    "print(X_tensor.shape)\n",
    "\n",
    "# Ensure y_encoded is a 1D array of integers (already done by LabelEncoder, but good to confirm)\n",
    "# No need for y_reshaped = np.repeat(y_encoded[:, None], 9, axis=1)\n",
    "y_target = torch.tensor(y_encoded, dtype=torch.int64)  # Use int64 for PyTorch labels\n",
    "\n",
    "# Create EEGNet model\n",
    "model = EEGNetv4(\n",
    "    n_chans=8,  # Your number of channels\n",
    "    n_classes=4,  # Your number of classes\n",
    "    input_window_samples=1251,  # Your time samples (updated from 1001 to 1251 based on X.shape)\n",
    "    F1=8,  # First filter parameter\n",
    "    D=2,  # Depth multiplier\n",
    "    F2=16,  # F1 * D\n",
    ")\n",
    "\n",
    "# Wrap in skorch for sklearn compatibility\n",
    "net = NeuralNetClassifier(\n",
    "    model,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=100,\n",
    ")\n",
    "\n",
    "# Use with your correctly shaped data\n",
    "net.fit(X_tensor, y_target)\n",
    "y_pred = net.predict(X_tensor)  # Use X_tensor for prediction as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1099476439790576\n"
     ]
    }
   ],
   "source": [
    "decoded_y_pred = event_mapping_decoder(y_pred)\n",
    "correct = (y == decoded_y_pred).sum()\n",
    "print(correct / len(y))\n",
    "# print((y == decoded_y_pred_mset).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94325653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model kwargs: {'in_chans': 3, 'n_classes': 2, 'input_window_samples': 385, 'drop_prob': 0.25}\n",
      "Pre-trained EEGNetv4 model loaded successfully!\n",
      "Starting training with pre-trained model...\n",
      "torch.Size([100, 8, 1251, 1]) torch.Size([100])\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6651\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.5189\u001b[0m  0.0655\n",
      "      2        \u001b[36m0.5948\u001b[0m       1.0000        \u001b[35m0.4511\u001b[0m  0.0410\n",
      "      3        \u001b[36m0.4666\u001b[0m       1.0000        \u001b[35m0.3953\u001b[0m  0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'in_chans' is depreciated. Use 'n_chans' instead.\n",
      "  warnings.warn(\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'n_classes' is depreciated. Use 'n_outputs' instead.\n",
      "  warnings.warn(\n",
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.3556\u001b[0m       1.0000        \u001b[35m0.3434\u001b[0m  0.0386\n",
      "      5        \u001b[36m0.2536\u001b[0m       1.0000        \u001b[35m0.2932\u001b[0m  0.0426\n",
      "      6        \u001b[36m0.2052\u001b[0m       1.0000        \u001b[35m0.2444\u001b[0m  0.0336\n",
      "      7        \u001b[36m0.1246\u001b[0m       1.0000        \u001b[35m0.1994\u001b[0m  0.0439\n",
      "      8        \u001b[36m0.0795\u001b[0m       1.0000        \u001b[35m0.1643\u001b[0m  0.0363\n",
      "      9        \u001b[36m0.0575\u001b[0m       1.0000        \u001b[35m0.1383\u001b[0m  0.0404\n",
      "     10        \u001b[36m0.0317\u001b[0m       1.0000        \u001b[35m0.1197\u001b[0m  0.0369\n",
      "     11        \u001b[36m0.0262\u001b[0m       1.0000        \u001b[35m0.1053\u001b[0m  0.0354\n",
      "     12        \u001b[36m0.0143\u001b[0m       1.0000        \u001b[35m0.0943\u001b[0m  0.0368\n",
      "     13        \u001b[36m0.0130\u001b[0m       1.0000        \u001b[35m0.0854\u001b[0m  0.0379\n",
      "     14        \u001b[36m0.0091\u001b[0m       1.0000        \u001b[35m0.0783\u001b[0m  0.0371\n",
      "     15        \u001b[36m0.0088\u001b[0m       1.0000        \u001b[35m0.0727\u001b[0m  0.0372\n",
      "     16        \u001b[36m0.0065\u001b[0m       1.0000        \u001b[35m0.0683\u001b[0m  0.0353\n",
      "     17        \u001b[36m0.0059\u001b[0m       1.0000        \u001b[35m0.0650\u001b[0m  0.0388\n",
      "     18        \u001b[36m0.0051\u001b[0m       1.0000        \u001b[35m0.0620\u001b[0m  0.0350\n",
      "     19        0.0051       1.0000        \u001b[35m0.0601\u001b[0m  0.0366\n",
      "     20        \u001b[36m0.0040\u001b[0m       1.0000        \u001b[35m0.0584\u001b[0m  0.0403\n",
      "     21        \u001b[36m0.0032\u001b[0m       1.0000        \u001b[35m0.0569\u001b[0m  0.0362\n",
      "     22        \u001b[36m0.0030\u001b[0m       1.0000        \u001b[35m0.0556\u001b[0m  0.0412\n",
      "     23        0.0034       1.0000        \u001b[35m0.0546\u001b[0m  0.0379\n",
      "     24        \u001b[36m0.0030\u001b[0m       1.0000        \u001b[35m0.0541\u001b[0m  0.0414\n",
      "     25        0.0037       1.0000        \u001b[35m0.0535\u001b[0m  0.0411\n",
      "     26        \u001b[36m0.0028\u001b[0m       1.0000        \u001b[35m0.0530\u001b[0m  0.0335\n",
      "     27        0.0030       1.0000        \u001b[35m0.0529\u001b[0m  0.0374\n",
      "     28        \u001b[36m0.0020\u001b[0m       1.0000        \u001b[35m0.0528\u001b[0m  0.0390\n",
      "     29        0.0021       1.0000        \u001b[35m0.0525\u001b[0m  0.0358\n",
      "     30        \u001b[36m0.0013\u001b[0m       1.0000        \u001b[35m0.0523\u001b[0m  0.0419\n",
      "     31        0.0018       1.0000        \u001b[35m0.0520\u001b[0m  0.0374\n",
      "     32        0.0026       1.0000        \u001b[35m0.0518\u001b[0m  0.0467\n",
      "     33        0.0019       1.0000        \u001b[35m0.0515\u001b[0m  0.0399\n",
      "     34        0.0022       1.0000        \u001b[35m0.0512\u001b[0m  0.0400\n",
      "     35        0.0015       1.0000        \u001b[35m0.0510\u001b[0m  0.0379\n",
      "     36        0.0021       1.0000        \u001b[35m0.0509\u001b[0m  0.0350\n",
      "     37        0.0019       1.0000        \u001b[35m0.0505\u001b[0m  0.0353\n",
      "     38        0.0025       1.0000        \u001b[35m0.0500\u001b[0m  0.0370\n",
      "     39        0.0017       1.0000        \u001b[35m0.0496\u001b[0m  0.0407\n",
      "     40        0.0015       1.0000        \u001b[35m0.0492\u001b[0m  0.0361\n",
      "     41        0.0013       1.0000        \u001b[35m0.0490\u001b[0m  0.0828\n",
      "     42        0.0015       1.0000        \u001b[35m0.0489\u001b[0m  0.0532\n",
      "     43        0.0013       1.0000        \u001b[35m0.0488\u001b[0m  0.0385\n",
      "     44        \u001b[36m0.0010\u001b[0m       1.0000        \u001b[35m0.0484\u001b[0m  0.0374\n",
      "     45        0.0012       1.0000        \u001b[35m0.0480\u001b[0m  0.0411\n",
      "     46        0.0011       1.0000        \u001b[35m0.0474\u001b[0m  0.0364\n",
      "     47        0.0014       1.0000        \u001b[35m0.0468\u001b[0m  0.0408\n",
      "     48        0.0017       1.0000        \u001b[35m0.0463\u001b[0m  0.0380\n",
      "     49        0.0019       1.0000        \u001b[35m0.0457\u001b[0m  0.0383\n",
      "     50        \u001b[36m0.0010\u001b[0m       1.0000        \u001b[35m0.0451\u001b[0m  0.0384\n",
      "     51        \u001b[36m0.0008\u001b[0m       1.0000        \u001b[35m0.0445\u001b[0m  0.0546\n",
      "     52        0.0010       1.0000        \u001b[35m0.0439\u001b[0m  0.0583\n",
      "     53        0.0010       1.0000        \u001b[35m0.0432\u001b[0m  0.0540\n",
      "     54        0.0018       1.0000        \u001b[35m0.0428\u001b[0m  0.0354\n",
      "     55        0.0021       1.0000        \u001b[35m0.0424\u001b[0m  0.0362\n",
      "     56        0.0011       1.0000        \u001b[35m0.0421\u001b[0m  0.0424\n",
      "     57        0.0011       1.0000        \u001b[35m0.0415\u001b[0m  0.0411\n",
      "     58        \u001b[36m0.0005\u001b[0m       1.0000        \u001b[35m0.0410\u001b[0m  0.0433\n",
      "     59        0.0007       1.0000        \u001b[35m0.0405\u001b[0m  0.0411\n",
      "     60        0.0009       1.0000        \u001b[35m0.0400\u001b[0m  0.0421\n",
      "     61        0.0007       1.0000        \u001b[35m0.0396\u001b[0m  0.0389\n",
      "     62        0.0023       1.0000        \u001b[35m0.0393\u001b[0m  0.0413\n",
      "     63        0.0008       1.0000        \u001b[35m0.0387\u001b[0m  0.0437\n",
      "     64        0.0006       1.0000        \u001b[35m0.0383\u001b[0m  0.0378\n",
      "     65        0.0009       1.0000        \u001b[35m0.0380\u001b[0m  0.0444\n",
      "     66        0.0012       1.0000        \u001b[35m0.0378\u001b[0m  0.0476\n",
      "     67        \u001b[36m0.0004\u001b[0m       1.0000        \u001b[35m0.0376\u001b[0m  0.0496\n",
      "     68        0.0007       1.0000        \u001b[35m0.0372\u001b[0m  0.0433\n",
      "     69        0.0009       1.0000        \u001b[35m0.0370\u001b[0m  0.0472\n",
      "     70        0.0006       1.0000        \u001b[35m0.0366\u001b[0m  0.0410\n",
      "     71        0.0007       1.0000        \u001b[35m0.0363\u001b[0m  0.0495\n",
      "     72        0.0008       1.0000        \u001b[35m0.0360\u001b[0m  0.0380\n",
      "     73        0.0005       1.0000        \u001b[35m0.0357\u001b[0m  0.0561\n",
      "     74        0.0007       1.0000        \u001b[35m0.0354\u001b[0m  0.0784\n",
      "     75        0.0008       1.0000        \u001b[35m0.0348\u001b[0m  0.0456\n",
      "     76        0.0006       1.0000        \u001b[35m0.0344\u001b[0m  0.0471\n",
      "     77        0.0005       1.0000        \u001b[35m0.0341\u001b[0m  0.0348\n",
      "     78        0.0005       1.0000        \u001b[35m0.0337\u001b[0m  0.0362\n",
      "     79        0.0005       1.0000        \u001b[35m0.0332\u001b[0m  0.0395\n",
      "     80        0.0005       1.0000        \u001b[35m0.0327\u001b[0m  0.0365\n",
      "     81        \u001b[36m0.0004\u001b[0m       1.0000        \u001b[35m0.0322\u001b[0m  0.0385\n",
      "     82        0.0007       1.0000        \u001b[35m0.0316\u001b[0m  0.0340\n",
      "     83        0.0005       1.0000        \u001b[35m0.0311\u001b[0m  0.0349\n",
      "     84        0.0006       1.0000        \u001b[35m0.0304\u001b[0m  0.0342\n",
      "     85        0.0005       1.0000        \u001b[35m0.0299\u001b[0m  0.0373\n",
      "     86        0.0007       1.0000        \u001b[35m0.0294\u001b[0m  0.0350\n",
      "     87        \u001b[36m0.0004\u001b[0m       1.0000        \u001b[35m0.0289\u001b[0m  0.0381\n",
      "     88        \u001b[36m0.0004\u001b[0m       1.0000        \u001b[35m0.0283\u001b[0m  0.0362\n",
      "     89        0.0007       1.0000        \u001b[35m0.0278\u001b[0m  0.0384\n",
      "     90        \u001b[36m0.0004\u001b[0m       1.0000        \u001b[35m0.0273\u001b[0m  0.0374\n",
      "     91        0.0007       1.0000        \u001b[35m0.0268\u001b[0m  0.0384\n",
      "     92        \u001b[36m0.0003\u001b[0m       1.0000        \u001b[35m0.0264\u001b[0m  0.0875\n",
      "     93        0.0005       1.0000        \u001b[35m0.0260\u001b[0m  0.0524\n",
      "     94        0.0004       1.0000        \u001b[35m0.0255\u001b[0m  0.0365\n",
      "     95        0.0004       1.0000        \u001b[35m0.0251\u001b[0m  0.0350\n",
      "     96        0.0003       1.0000        \u001b[35m0.0246\u001b[0m  0.0367\n",
      "     97        0.0003       1.0000        \u001b[35m0.0241\u001b[0m  0.0349\n",
      "     98        0.0005       1.0000        \u001b[35m0.0236\u001b[0m  0.0374\n",
      "     99        0.0003       1.0000        \u001b[35m0.0231\u001b[0m  0.0379\n",
      "    100        0.0008       1.0000        \u001b[35m0.0225\u001b[0m  0.0372\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m dummy_y = torch.zeros(\u001b[32m100\u001b[39m, dtype=torch.int64)  \u001b[38;5;66;03m# Dummy labels for dummy_x\u001b[39;00m\n\u001b[32m     65\u001b[39m net.fit(dummy_x, dummy_y)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m y_pred = \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/classifier.py:232\u001b[39m, in \u001b[36mNeuralNetClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    203\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m    205\u001b[39m \u001b[33;03m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m \n\u001b[32m    231\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m.argmax(axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/classifier.py:200\u001b[39m, in \u001b[36mNeuralNetClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Where applicable, return probability estimates for\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[33;03msamples.\u001b[39;00m\n\u001b[32m    170\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m \n\u001b[32m    197\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Only the docstring changed from parent.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1625\u001b[39m, in \u001b[36mNeuralNet.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1623\u001b[39m nonlin = \u001b[38;5;28mself\u001b[39m._get_predict_nonlinearity()\n\u001b[32m   1624\u001b[39m y_probas = []\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1471\u001b[39m, in \u001b[36mNeuralNet.forward_iter\u001b[39m\u001b[34m(self, X, training, device)\u001b[39m\n\u001b[32m   1469\u001b[39m iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(dataset, training=training)\n\u001b[32m   1470\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[32m-> \u001b[39m\u001b[32m1471\u001b[39m     yp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m to_device(yp, device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1164\u001b[39m, in \u001b[36mNeuralNet.evaluation_step\u001b[39m\u001b[34m(self, batch, training)\u001b[39m\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(training):\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_training(training)\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/skorch/net.py:1551\u001b[39m, in \u001b[36mNeuralNet.infer\u001b[39m\u001b[34m(self, x, **fit_params)\u001b[39m\n\u001b[32m   1549\u001b[39m     x_dict = \u001b[38;5;28mself\u001b[39m._merge_x_and_fit_params(x, fit_params)\n\u001b[32m   1550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module_(**x_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/modules.py:36\u001b[39m, in \u001b[36mExpression.forward\u001b[39m\u001b[34m(self, *x)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *x):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexpression_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/braindecode/models/functions.py:32\u001b[39m, in \u001b[36msqueeze_final_output\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqueeze_final_output\u001b[39m(x):\n\u001b[32m     22\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Removes empty dimension at end and potentially removes empty time\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m     dimension. It does  not just use squeeze as we never want to remove\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m     first dimension.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[33;03m        squeezed tensor\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m x.size()[\u001b[32m3\u001b[39m] == \u001b[32m1\u001b[39m\n\u001b[32m     33\u001b[39m     x = x[:, :, :, \u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.size()[\u001b[32m2\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pickle # Still needed for kwargs.pkl, as it's likely a standard pickle file\n",
    "\n",
    "# --- Your existing data loading and preprocessing ---\n",
    "# (Keep this as is)\n",
    "import numpy as np\n",
    "X = np.random.rand(100, 8, 1251) # Example: 100 samples, 8 channels, 1251 timepoints\n",
    "y_encoded = np.random.randint(0, 4, 100) # Example: 100 labels for 4 classes\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "mue = X_tensor.mean(dim=(0, 2), keepdim=True)\n",
    "std = (X_tensor.std(dim=(0, 2), keepdim=True) + 1e-8)\n",
    "X_tensor = (X_tensor - mue) / std\n",
    "X_tensor = X_tensor.unsqueeze(3)\n",
    "y_target = torch.tensor(y_encoded, dtype=torch.int64)\n",
    "\n",
    "# --- Hugging Face Model Loading ---\n",
    "# Download the model architecture and parameters\n",
    "path_kwargs = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/kwargs.pkl',\n",
    ")\n",
    "path_params = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/model-params.pkl',\n",
    ")\n",
    "\n",
    "with open(path_kwargs, 'rb') as f:\n",
    "    kwargs = pickle.load(f) # kwargs.pkl is likely a standard pickle file\n",
    "\n",
    "module_cls = kwargs['module_cls']\n",
    "module_kwargs = kwargs['module_kwargs']\n",
    "\n",
    "print(f\"Pre-trained model kwargs: {module_kwargs}\")\n",
    "\n",
    "torch_module = module_cls(**module_kwargs)\n",
    "\n",
    "# --- CHANGE HERE: Use torch.load() instead of pickle.load() for model-params.pkl ---\n",
    "# The map_location='cpu' is important if you're not using a GPU,\n",
    "# or if the model was trained on GPU but you want to load it on CPU.\n",
    "pretrained_state_dict = torch.load(path_params, map_location='cpu')\n",
    "\n",
    "torch_module.load_state_dict(pretrained_state_dict)\n",
    "\n",
    "print(\"Pre-trained EEGNetv4 model loaded successfully!\")\n",
    "\n",
    "# --- Wrap in skorch for sklearn compatibility ---\n",
    "net = NeuralNetClassifier(\n",
    "    torch_module,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=100,\n",
    ")\n",
    "\n",
    "print(\"Starting training with pre-trained model...\")\n",
    "print(X_tensor.shape, y_target.shape)\n",
    "dummy_x = torch.rand(100, 3, 385, 1)\n",
    "dummy_y = torch.zeros(100, dtype=torch.int64)\n",
    "\n",
    "net.fit(dummy_x, dummy_y)\n",
    "y_pred = net.predict(X_tensor)\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Predictions shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6aa54c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEGNetv4(\n",
       "  (ensuredims): Ensure4d()\n",
       "  (dimshuffle): Rearrange('batch ch t 1 -> batch 1 ch t')\n",
       "  (conv_temporal): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=(0, 32), bias=False)\n",
       "  (bnorm_temporal): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (conv_spatial): Conv2dWithConstraint(8, 16, kernel_size=(3, 1), stride=(1, 1), groups=8, bias=False)\n",
       "  (bnorm_1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (elu_1): Expression(expression=elu) \n",
       "  (pool_1): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "  (drop_1): Dropout(p=0.25, inplace=False)\n",
       "  (conv_separable_depth): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=(0, 8), groups=16, bias=False)\n",
       "  (conv_separable_point): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bnorm_2): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (elu_2): Expression(expression=elu) \n",
       "  (pool_2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
       "  (drop_2): Dropout(p=0.25, inplace=False)\n",
       "  (final_layer): Sequential(\n",
       "    (conv_classifier): Conv2d(16, 2, kernel_size=(1, 12), stride=(1, 1))\n",
       "    (permute_back): Rearrange('batch x y z -> batch x z y')\n",
       "    (squeeze): Expression(expression=squeeze_final_output) \n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
