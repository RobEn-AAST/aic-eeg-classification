{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f517e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from modules.competition_dataset import EEGDataset\n",
    "from pyriemann.utils.mean import mean_riemann\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.linalg import expm, logm, inv\n",
    "from scipy.optimize import minimize\n",
    "from Models import FilterBankRTSClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c412b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mtcaic3'\n",
    "lda_model_path = './checkpoints/mi/models/lda_mi.pkl'\n",
    "\n",
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69b96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:25:28,127] A new study created in memory with name: no-name-50228663-b5ca-4e00-8b7a-1bedb61f580c\n",
      "[I 2025-06-28 22:28:48,938] Trial 0 finished with value: 0.5598784371887556 and parameters: {'rsf_d': 4, 'filter_order': 6, 'fs': 125, 'C': 17.796913417063408, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.6522116873223839}. Best is trial 0 with value: 0.5598784371887556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.569 | Val acc: 0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:30:30,466] Trial 1 finished with value: 0.5234123596888054 and parameters: {'rsf_d': 2, 'filter_order': 3, 'fs': 250, 'C': 0.24949163879331557, 'kernel': 'linear', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8115646169421447}. Best is trial 0 with value: 0.5598784371887556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.531 | Val acc: 0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:32:03,531] Trial 2 finished with value: 0.5225600691932295 and parameters: {'rsf_d': 2, 'filter_order': 5, 'fs': 500, 'C': 1.8007429871212501, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.0514839356423179}. Best is trial 0 with value: 0.5598784371887556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.534 | Val acc: 0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:36:39,037] Trial 3 finished with value: 0.5635379553218661 and parameters: {'rsf_d': 5, 'filter_order': 6, 'fs': 500, 'C': 364.72059659157196, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3, 'coef0': 0.5001319564232748}. Best is trial 3 with value: 0.5635379553218661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.979 | Val acc: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:44:54,457] Trial 4 finished with value: 0.5386589243625531 and parameters: {'rsf_d': 5, 'filter_order': 3, 'fs': 500, 'C': 30.107461402825148, 'kernel': 'linear', 'gamma': 'scale', 'degree': 2, 'coef0': 0.17589855276013622}. Best is trial 3 with value: 0.5635379553218661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.568 | Val acc: 0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:47:03,313] Trial 5 finished with value: 0.5178049529297425 and parameters: {'rsf_d': 3, 'filter_order': 4, 'fs': 500, 'C': 0.002133930524120991, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3, 'coef0': 0.6289868713099951}. Best is trial 3 with value: 0.5635379553218661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.519 | Val acc: 0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:49:08,086] Trial 6 finished with value: 0.5243903635901143 and parameters: {'rsf_d': 4, 'filter_order': 5, 'fs': 500, 'C': 0.0759630945832062, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.14198198294205988}. Best is trial 3 with value: 0.5635379553218661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.555 | Val acc: 0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:51:03,647] Trial 7 finished with value: 0.5140233794814844 and parameters: {'rsf_d': 2, 'filter_order': 5, 'fs': 500, 'C': 0.015084259382027471, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 5, 'coef0': 0.18499795340352065}. Best is trial 3 with value: 0.5635379553218661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.524 | Val acc: 0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:52:34,786] Trial 8 finished with value: 0.5364640700112143 and parameters: {'rsf_d': 2, 'filter_order': 3, 'fs': 500, 'C': 3.7996061484882855, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 4, 'coef0': 0.14095658777607734}. Best is trial 3 with value: 0.5635379553218661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Train acc: 0.589 | Val acc: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-28 22:53:04,247] Trial 9 failed with parameters: {'rsf_d': 2, 'filter_order': 6, 'fs': 500, 'C': 7.28625061913845, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.09279765268273243} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_94761/3783384118.py\", line 184, in objective\n",
      "    scores = cross_validate(pipeline, X, y, cv=cv, scoring=\"accuracy\", return_train_score=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 915, in _fit_and_score\n",
      "    train_scores = _score(\n",
      "                   ^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 601, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_94761/3783384118.py\", line 63, in predict\n",
      "    fb_covs = self.compute_fb_covs(X)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_94761/3783384118.py\", line 24, in compute_fb_covs\n",
      "    fb_covs[:, i] = Covariances(estimator=\"lwf\").transform(Xf)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/estimation.py\", line 77, in transform\n",
      "    covmats = covariances(X, estimator=self.estimator, **self.kwds)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py\", line 400, in covariances\n",
      "    covmats[i] = est(X[i], **kwds)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py\", line 48, in wrapper\n",
      "    cov = func(X, **kwds)\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py\", line 61, in _lwf\n",
      "    C, _ = ledoit_wolf(X.T, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 464, in ledoit_wolf\n",
      "    ).fit(X)\n",
      "      ^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 605, in fit\n",
      "    covariance, shrinkage = _ledoit_wolf(\n",
      "                            ^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 37, in _ledoit_wolf\n",
      "    shrinkage = ledoit_wolf_shrinkage(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 385, in ledoit_wolf_shrinkage\n",
      "    np.dot(X.T[block_size * n_splits :], X[:, block_size * n_splits :]) ** 2\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-28 22:53:04,323] Trial 9 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 196\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m val_acc\n\u001b[32m    195\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, pruner=MedianPruner())\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Best trial ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    199\u001b[39m best = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    181\u001b[39m cv = StratifiedKFold(cv_folds, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Run cross-validation on the entire pipeline\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m scores = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m train_acc = scores[\u001b[33m\"\u001b[39m\u001b[33mtrain_score\u001b[39m\u001b[33m\"\u001b[39m].mean()\n\u001b[32m    187\u001b[39m val_acc = scores[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m].mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    209\u001b[39m         skip_parameter_validation=(\n\u001b[32m    210\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    211\u001b[39m         )\n\u001b[32m    212\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    219\u001b[39m     msg = re.sub(\n\u001b[32m    220\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:423\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    422\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     69\u001b[39m config = get_config()\n\u001b[32m     70\u001b[39m iterable_with_config = (\n\u001b[32m     71\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     73\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m     config = {}\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:915\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    913\u001b[39m     score_time = time.time() - start_time - fit_time\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         train_scores = \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose > \u001b[32m1\u001b[39m:\n\u001b[32m    920\u001b[39m     total_time = score_time + fit_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971\u001b[39m, in \u001b[36m_score\u001b[39m\u001b[34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[39m\n\u001b[32m    969\u001b[39m         scores = scorer(estimator, X_test, **score_params)\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m         scores = \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    973\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[32m    974\u001b[39m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[32m    975\u001b[39m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:279\u001b[39m, in \u001b[36m_BaseScorer.__call__\u001b[39m\u001b[34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    277\u001b[39m     _kwargs[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:371\u001b[39m, in \u001b[36m_Scorer._score\u001b[39m\u001b[34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m pos_label = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_pos_label()\n\u001b[32m    370\u001b[39m response_method = _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m._response_method)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m y_pred = \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m scoring_kwargs = {**\u001b[38;5;28mself\u001b[39m._kwargs, **kwargs}\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sign * \u001b[38;5;28mself\u001b[39m._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:89\u001b[39m, in \u001b[36m_cached_call\u001b[39m\u001b[34m(cache, estimator, response_method, *args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m result, _ = \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     94\u001b[39m     cache[response_method] = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_response.py:211\u001b[39m, in \u001b[36m_get_response_values\u001b[39m\u001b[34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[39m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    209\u001b[39m         pos_label = classes[-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m y_pred = \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction_method.\u001b[34m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_log_proba\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    214\u001b[39m     y_pred = _process_predict_proba(\n\u001b[32m    215\u001b[39m         y_pred=y_pred,\n\u001b[32m    216\u001b[39m         target_type=target_type,\n\u001b[32m    217\u001b[39m         classes=classes,\n\u001b[32m    218\u001b[39m         pos_label=pos_label,\n\u001b[32m    219\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/pipeline.py:601\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    599\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    600\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    604\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mFilterBankRTSClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     fb_covs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_fb_covs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     n, B, C, _ = fb_covs.shape\n\u001b[32m     66\u001b[39m     covs_flat = fb_covs.reshape(n * B, C, C)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mFilterBankRTSClassifier.compute_fb_covs\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, sos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.sos_bands):\n\u001b[32m     23\u001b[39m     Xf = sosfiltfilt(sos, X, axis=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     fb_covs[:, i] = \u001b[43mCovariances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlwf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fb_covs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/estimation.py:77\u001b[39m, in \u001b[36mCovariances.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m     65\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate covariance matrices.\u001b[39;00m\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m \u001b[33;03m        Covariance matrices.\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     covmats = \u001b[43mcovariances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m covmats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py:400\u001b[39m, in \u001b[36mcovariances\u001b[39m\u001b[34m(X, estimator, **kwds)\u001b[39m\n\u001b[32m    398\u001b[39m covmats = np.empty((n_matrices, n_channels, n_channels), dtype=X.dtype)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_matrices):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     covmats[i] = \u001b[43mest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m covmats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py:48\u001b[39m, in \u001b[36m_complex_estimator.<locals>.wrapper\u001b[39m\u001b[34m(X, **kwds)\u001b[39m\n\u001b[32m     46\u001b[39m     n_channels, n_times = X.shape\n\u001b[32m     47\u001b[39m     X = np.concatenate((X.real, X.imag), axis=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m cov = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iscomplex:\n\u001b[32m     50\u001b[39m     cov = cov[:n_channels, :n_channels] \\\n\u001b[32m     51\u001b[39m         + cov[n_channels:, n_channels:] \\\n\u001b[32m     52\u001b[39m         + \u001b[32m1\u001b[39mj * (cov[n_channels:, :n_channels]\n\u001b[32m     53\u001b[39m                 - cov[:n_channels, n_channels:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/pyriemann/utils/covariance.py:61\u001b[39m, in \u001b[36m_lwf\u001b[39m\u001b[34m(X, **kwds)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;129m@_complex_estimator\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lwf\u001b[39m(X, **kwds):\n\u001b[32m     60\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper for sklearn ledoit wolf covariance estimator\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     C, _ = \u001b[43mledoit_wolf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    209\u001b[39m         skip_parameter_validation=(\n\u001b[32m    210\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    211\u001b[39m         )\n\u001b[32m    212\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    219\u001b[39m     msg = re.sub(\n\u001b[32m    220\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:464\u001b[39m, in \u001b[36mledoit_wolf\u001b[39m\u001b[34m(X, assume_centered, block_size)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m    406\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m]},\n\u001b[32m    407\u001b[39m     prefer_skip_nested_validation=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    408\u001b[39m )\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mledoit_wolf\u001b[39m(X, *, assume_centered=\u001b[38;5;28;01mFalse\u001b[39;00m, block_size=\u001b[32m1000\u001b[39m):\n\u001b[32m    410\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate the shrunk Ledoit-Wolf covariance matrix.\u001b[39;00m\n\u001b[32m    411\u001b[39m \n\u001b[32m    412\u001b[39m \u001b[33;03m    Read more in the :ref:`User Guide <shrunk_covariance>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    458\u001b[39m \u001b[33;03m    np.float64(0.23...)\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    460\u001b[39m     estimator = \u001b[43mLedoitWolf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m=\u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstore_precision\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator.covariance_, estimator.shrinkage_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:605\u001b[39m, in \u001b[36mLedoitWolf.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    604\u001b[39m     \u001b[38;5;28mself\u001b[39m.location_ = X.mean(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m covariance, shrinkage = \u001b[43m_ledoit_wolf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocation_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock_size\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[38;5;28mself\u001b[39m.shrinkage_ = shrinkage\n\u001b[32m    609\u001b[39m \u001b[38;5;28mself\u001b[39m._set_covariance(covariance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:37\u001b[39m, in \u001b[36m_ledoit_wolf\u001b[39m\u001b[34m(X, assume_centered, block_size)\u001b[39m\n\u001b[32m     34\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# get Ledoit-Wolf shrinkage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m shrinkage = \u001b[43mledoit_wolf_shrinkage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m=\u001b[49m\u001b[43massume_centered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m emp_cov = empirical_covariance(X, assume_centered=assume_centered)\n\u001b[32m     41\u001b[39m mu = np.sum(np.trace(emp_cov)) / n_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m func_sig = signature(func)\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/sklearn/covariance/_shrunk_covariance.py:385\u001b[39m, in \u001b[36mledoit_wolf_shrinkage\u001b[39m\u001b[34m(X, assume_centered, block_size)\u001b[39m\n\u001b[32m    382\u001b[39m     beta_ += np.sum(np.dot(X2.T[block_size * n_splits :], X2[:, cols]))\n\u001b[32m    383\u001b[39m     delta_ += np.sum(np.dot(X.T[block_size * n_splits :], X[:, cols]) ** \u001b[32m2\u001b[39m)\n\u001b[32m    384\u001b[39m delta_ += np.sum(\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m ** \u001b[32m2\u001b[39m\n\u001b[32m    386\u001b[39m )\n\u001b[32m    387\u001b[39m delta_ /= n_samples**\u001b[32m2\u001b[39m\n\u001b[32m    388\u001b[39m beta_ += np.sum(\n\u001b[32m    389\u001b[39m     np.dot(X2.T[block_size * n_splits :], X2[:, block_size * n_splits :])\n\u001b[32m    390\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class FilterBankRTSClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, fs=250, order=4, C=1.0, kernel=\"rbf\", gamma=\"scale\", degree=3, coef0=0.0, probability=True, class_weight=\"balanced\", random_state=42):\n",
    "        self.bands = [(8, 12), (12, 16), (16, 20), (20, 24), (24, 30)]\n",
    "        self.fs = fs\n",
    "        self.order = order\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.probability = probability\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def compute_fb_covs(self, X):\n",
    "        \"\"\"X: (n_trials, C, T) → fb_covs: (n_trials, B, C, C)\"\"\"\n",
    "        if not hasattr(self, \"sos_bands\"):\n",
    "            self.sos_bands = [butter(self.order, (l / (self.fs / 2), h / (self.fs / 2)), btype=\"bandpass\", output=\"sos\") for l, h in self.bands]\n",
    "        n, C, _ = X.shape\n",
    "        B = len(self.sos_bands)\n",
    "        fb_covs = np.zeros((n, B, C, C))\n",
    "        for i, sos in enumerate(self.sos_bands):\n",
    "            Xf = sosfiltfilt(sos, X, axis=2)\n",
    "            fb_covs[:, i] = Covariances(estimator=\"lwf\").transform(Xf)\n",
    "        return fb_covs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        labels_rep = np.repeat(y, B)\n",
    "\n",
    "        self.ts = TangentSpace(metric=\"riemann\").fit(covs_flat, labels_rep)\n",
    "        Z = self.ts.transform(covs_flat)\n",
    "        Z = Z.reshape(n, B, -1)\n",
    "\n",
    "        self.w = mutual_info_classif(Z.reshape(n, -1), y, discrete_features=False).reshape(B, -1).mean(axis=1)\n",
    "        self.w = self.w / self.w.sum()\n",
    "\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "\n",
    "        self.clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            SVC(\n",
    "                C=self.C,\n",
    "                kernel=self.kernel,\n",
    "                gamma=self.gamma,\n",
    "                degree=self.degree,\n",
    "                coef0=self.coef0,\n",
    "                probability=self.probability,\n",
    "                class_weight=self.class_weight,\n",
    "                random_state=self.random_state,\n",
    "            ),\n",
    "        )\n",
    "        self.clf.fit(Z_weighted, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        Z = self.ts.transform(covs_flat).reshape(n, B, -1)\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        return self.clf.predict(Z_weighted)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        Z = self.ts.transform(covs_flat).reshape(n, B, -1)\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        return self.clf.predict_proba(Z_weighted)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) RSFTransformer that learns W_opt using BFGS\n",
    "# -----------------------------------------------------------------------------\n",
    "class RSFTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d=8, eps=1e-6, maxiter=500):\n",
    "        self.d = d\n",
    "        self.eps = eps\n",
    "        self.maxiter = maxiter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        covs = Covariances(estimator=\"lwf\").transform(X)\n",
    "        C1 = mean_riemann(covs[y == 0])\n",
    "        C2 = mean_riemann(covs[y == 1])\n",
    "        Nc = C1.shape[0]\n",
    "        W0 = np.random.randn(Nc, self.d)\n",
    "\n",
    "        def J(w_flat):\n",
    "            W = w_flat.reshape(Nc, self.d)\n",
    "            S1 = W.T @ C1 @ W + np.eye(self.d) * self.eps\n",
    "            S2 = W.T @ C2 @ W + np.eye(self.d) * self.eps\n",
    "            return np.linalg.norm(logm(inv(S1) @ S2), \"fro\") ** 2\n",
    "\n",
    "        def grad(w_flat):\n",
    "            W = w_flat.reshape(Nc, self.d)\n",
    "            S1 = W.T @ C1 @ W + np.eye(self.d) * self.eps\n",
    "            S2 = W.T @ C2 @ W + np.eye(self.d) * self.eps\n",
    "            A = inv(S1) @ S2\n",
    "            L = logm(A)\n",
    "            t1 = 2 * C1 @ W @ inv(S1) @ L @ inv(S1)\n",
    "            t2 = 2 * C2 @ W @ inv(S2) @ L @ inv(S2)\n",
    "            return (t1 - t2).ravel()\n",
    "\n",
    "        res = minimize(lambda w: -J(w), W0.ravel(), jac=lambda w: -grad(w), method=\"BFGS\", options={\"maxiter\": self.maxiter})\n",
    "        self.W_opt = res.x.reshape(Nc, self.d)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.einsum(\"cd,ect->edt\", self.W_opt, X)\n",
    "\n",
    "\n",
    "def load_eeg_data(data_path, window_length, stride, tmin, eeg_channels):\n",
    "    ds = EEGDataset(\n",
    "        data_path,\n",
    "        window_length=window_length,\n",
    "        stride=stride,\n",
    "        task=\"mi\",\n",
    "        split=\"train\",\n",
    "        data_fraction=0.4,\n",
    "        tmin=tmin,\n",
    "        eeg_channels=eeg_channels,\n",
    "    )\n",
    "    X = np.stack([x.numpy() for x, _ in ds])\n",
    "    y = np.array([label[0] for _, label in ds])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Optuna optimization\n",
    "data_path = \"./data/mtcaic3\"\n",
    "cv_folds = 3\n",
    "\n",
    "window_length = 1000\n",
    "stride = 85\n",
    "tmin = 60\n",
    "eeg_channels = [\"FZ\", \"CZ\", \"PZ\", \"C3\", \"OZ\"]\n",
    "\n",
    "X, y = load_eeg_data(data_path, window_length, stride, tmin, eeg_channels)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # --- Data and channel selection parameters (same as before) ---\n",
    "    d_rsf = trial.suggest_int(\"rsf_d\", 2, len(eeg_channels))\n",
    "\n",
    "    # --- Filter bank parameters (same as before) ---\n",
    "    filter_order = trial.suggest_int(\"filter_order\", 3, 6)\n",
    "    fs = trial.suggest_categorical(\"fs\", [125, 250, 500])\n",
    "\n",
    "    # --- SVM parameters ---\n",
    "    C = trial.suggest_float(\"C\", 1e-3, 1e3, log=True)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "    degree = trial.suggest_int(\"degree\", 2, 5)  # only for 'poly'\n",
    "    coef0 = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "\n",
    "    # --- CORE CHANGE: Build the pipeline ---\n",
    "    pipeline = make_pipeline(\n",
    "        RSFTransformer(d=d_rsf),\n",
    "        FilterBankRTSClassifier(\n",
    "            fs=fs,\n",
    "            order=filter_order,\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            coef0=coef0,\n",
    "            probability=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Run cross-validation on the entire pipeline\n",
    "    scores = cross_validate(pipeline, X, y, cv=cv, scoring=\"accuracy\", return_train_score=True)\n",
    "\n",
    "    train_acc = scores[\"train_score\"].mean()\n",
    "    val_acc = scores[\"test_score\"].mean()\n",
    "\n",
    "    print(f\"   → Train acc: {train_acc:.3f} | Val acc: {val_acc:.3f}\")\n",
    "    trial.set_user_attr(\"train_acc\", train_acc)\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner())\n",
    "study.optimize(objective, n_trials=100, timeout=7200)\n",
    "\n",
    "print(\"\\n=== Best trial ===\")\n",
    "best = study.best_trial\n",
    "print(\"Val Acc:\", best.value)\n",
    "print(\"Train Acc:\", best.user_attrs[\"train_acc\"])\n",
    "print(\"Params:\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a087e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: mi, split: train, domain: time, data_fraction: 1\n",
      "skipped: 21/2400\n",
      "task: mi, split: train, domain: time, data_fraction: 1\n",
      "skipped: 21/2400\n",
      "Validation accuracy: 0.5602\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58      3317\n",
      "           1       0.57      0.51      0.54      3374\n",
      "\n",
      "    accuracy                           0.56      6691\n",
      "   macro avg       0.56      0.56      0.56      6691\n",
      "weighted avg       0.56      0.56      0.56      6691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trial 7 finished with value: 0.5871394563472291 and parameters: {'window_length': 250, 'stride': 500, 'tmin': 500, 'ch_FZ': 0, 'ch_C3': 0, 'ch_CZ': 1, 'ch_C4': 1, 'ch_PZ': 0, 'ch_PO7': 1, 'ch_OZ': 1, 'ch_PO8': 1, 'rsf_d': 5, 'n_bands': 3, 'min_freq': 4, 'max_freq': 39, 'filter_order': 3, 'fs': 125, 'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.5871394563472291.\n",
    "\n",
    "class FilterBankRTSClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, bands=None, fs=250, order=4, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=\"sqrt\", class_weight=\"balanced\", n_jobs=-1):\n",
    "        self.bands = bands if bands else [(8, 12), (12, 16), (16, 20), (20, 24), (24, 30)]\n",
    "        self.fs = fs\n",
    "        self.order = order\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.class_weight = class_weight\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def compute_fb_covs(self, X):\n",
    "        \"\"\"X: (n_trials, C, T) → fb_covs: (n_trials, B, C, C)\"\"\"\n",
    "        # Pre-compute SOS filters if not done\n",
    "        if not hasattr(self, \"sos_bands\"):\n",
    "            self.sos_bands = [butter(self.order, (l / (self.fs / 2), h / (self.fs / 2)), btype=\"bandpass\", output=\"sos\") for l, h in self.bands]\n",
    "\n",
    "        n, C, _ = X.shape\n",
    "        B = len(self.sos_bands)\n",
    "        fb_covs = np.zeros((n, B, C, C))\n",
    "        for i, sos in enumerate(self.sos_bands):\n",
    "            Xf = sosfiltfilt(sos, X, axis=2)\n",
    "            fb_covs[:, i] = Covariances(estimator=\"lwf\").transform(Xf)\n",
    "        return fb_covs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        # Flatten for tangent space\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        labels_rep = np.repeat(y, B)\n",
    "\n",
    "        # Fit tangent space\n",
    "        self.ts = TangentSpace(metric=\"riemann\").fit(covs_flat, labels_rep)\n",
    "        Z = self.ts.transform(covs_flat)\n",
    "        Z = Z.reshape(n, B, -1)\n",
    "\n",
    "        # Compute mutual information weights\n",
    "        self.w = mutual_info_classif(Z.reshape(n, -1), y, discrete_features=False).reshape(B, -1).mean(axis=1)\n",
    "        self.w = self.w / self.w.sum()\n",
    "\n",
    "        # Weight features\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        # Train classifier\n",
    "        self.clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                max_features=self.max_features,\n",
    "                class_weight=self.class_weight,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        )\n",
    "        self.clf.fit(Z_weighted, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        Z = self.ts.transform(covs_flat).reshape(n, B, -1)\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        return self.clf.predict(Z_weighted)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        fb_covs = self.compute_fb_covs(X)\n",
    "        n, B, C, _ = fb_covs.shape\n",
    "\n",
    "        covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "        Z = self.ts.transform(covs_flat).reshape(n, B, -1)\n",
    "        Z_weighted = np.concatenate([np.sqrt(self.w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "\n",
    "        return self.clf.predict_proba(Z_weighted)\n",
    "\n",
    "class RSFTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d=8, eps=1e-6, maxiter=500):\n",
    "        self.d = d\n",
    "        self.eps = eps\n",
    "        self.maxiter = maxiter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        covs = Covariances(estimator=\"lwf\").transform(X)\n",
    "        C1 = mean_riemann(covs[y == 0])\n",
    "        C2 = mean_riemann(covs[y == 1])\n",
    "        Nc = C1.shape[0]\n",
    "        W0 = np.random.randn(Nc, self.d)\n",
    "\n",
    "        def J(w_flat):\n",
    "            W = w_flat.reshape(Nc, self.d)\n",
    "            S1 = W.T @ C1 @ W + np.eye(self.d) * self.eps\n",
    "            S2 = W.T @ C2 @ W + np.eye(self.d) * self.eps\n",
    "            return np.linalg.norm(logm(inv(S1) @ S2), \"fro\") ** 2\n",
    "\n",
    "        def grad(w_flat):\n",
    "            W = w_flat.reshape(Nc, self.d)\n",
    "            S1 = W.T @ C1 @ W + np.eye(self.d) * self.eps\n",
    "            S2 = W.T @ C2 @ W + np.eye(self.d) * self.eps\n",
    "            A = inv(S1) @ S2\n",
    "            L = logm(A)\n",
    "            t1 = 2 * C1 @ W @ inv(S1) @ L @ inv(S1)\n",
    "            t2 = 2 * C2 @ W @ inv(S2) @ L @ inv(S2)\n",
    "            return (t1 - t2).ravel()\n",
    "\n",
    "        res = minimize(lambda w: -J(w), W0.ravel(), jac=lambda w: -grad(w), method=\"BFGS\", options={\"maxiter\": self.maxiter})\n",
    "        self.W_opt = res.x.reshape(Nc, self.d)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.einsum(\"cd,ect->edt\", self.W_opt, X)\n",
    "\n",
    "\n",
    "window_length = 1000\n",
    "stride = 85\n",
    "tmin = 500\n",
    "eeg_channels = ['CZ', 'FZ', 'PZ', 'C3', 'OZ']\n",
    "d_rsf = 5\n",
    "n_bands = 3\n",
    "min_freq = 4\n",
    "max_freq = 39\n",
    "filter_order = 3\n",
    "fs = 125\n",
    "n_estimators = 150\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "min_samples_leaf = 1\n",
    "max_features = 'sqrt'\n",
    "data_path = \"./data/mtcaic3\"\n",
    "\n",
    "\n",
    "# Load data with besjt parameters\n",
    "ds_train = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task=\"mi\",\n",
    "    split=\"train\",\n",
    "    data_fraction=1,\n",
    "    tmin=tmin,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "X_train = np.stack([x.numpy() for x, _ in ds_train])\n",
    "y_train = np.array([label[0] for _, label in ds_train])\n",
    "\n",
    "# Load data with besjt parameters\n",
    "freq_step = (max_freq - min_freq) / n_bands\n",
    "bands = [(min_freq + i * freq_step, min_freq + (i + 1) * freq_step) for i in range(n_bands)]\n",
    "ds_val = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task=\"mi\",\n",
    "    split=\"train\",\n",
    "    data_fraction=1,\n",
    "    tmin=tmin,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "X_val = np.stack([x.numpy() for x, _ in ds_val])\n",
    "y_val = np.array([label[0] for _, label in ds_val])\n",
    "\n",
    "freq_step = (max_freq - min_freq) / n_bands\n",
    "bands = [(min_freq + i * freq_step, min_freq + (i + 1) * freq_step) for i in range(n_bands)]\n",
    "\n",
    "# Create frequency bands\n",
    "\n",
    "# Create FilterBank classifier with best parameters\n",
    "clf = make_pipeline(\n",
    "    # This single object now contains your entire workflow.\n",
    "        RSFTransformer(d=d_rsf),\n",
    "        FilterBankRTSClassifier(\n",
    "            bands=bands,\n",
    "            fs=fs,\n",
    "            order=filter_order,\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Fit on training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "y_pred = clf.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
