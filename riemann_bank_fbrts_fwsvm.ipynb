{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f517e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from modules.competition_dataset import EEGDataset\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.linalg import expm, logm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.mean import mean_riemann\n",
    "from pyriemann.utils.distance import distance_riemann\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.signal import sosfiltfilt, butter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c412b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mtcaic3'\n",
    "lda_model_path = './checkpoints/mi/models/lda_mi.pkl'\n",
    "\n",
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f62b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 256 * 3\n",
    "stride = window_length // 3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac48c31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: mi, split: train, domain: time, data_fraction: 0.4\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 11/960\n",
      "task: mi, split: validation, domain: time, data_fraction: 1.0\n",
      "skipped: 0/50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_channels = [\n",
    "    \"FZ\",\n",
    "    \"C3\",\n",
    "    \"CZ\",\n",
    "    \"C4\",\n",
    "    # \"PZ\",\n",
    "    # \"PO7\",\n",
    "    # \"OZ\",\n",
    "    \"PO8\",\n",
    "]\n",
    "\n",
    "dataset_train = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task=\"mi\",\n",
    "    split=\"train\",\n",
    "    data_fraction=0.4,\n",
    "    tmin=250,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task='mi',\n",
    "    split='validation',\n",
    "    read_labels=True,\n",
    "    tmin=250,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "\n",
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246cdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for train/val/test\n",
    "X_train = np.stack([x.numpy() for x, y in dataset_train])  # shape: [N, C, T]\n",
    "y_train = np.array([y[0] for x, y in dataset_train])\n",
    "\n",
    "X_val = np.stack([x.numpy() for x, y in dataset_val])\n",
    "y_val = np.array([y[0] for x, y in dataset_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90478c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.5142857142857142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.38      0.47        79\n",
      "           1       0.46      0.69      0.55        61\n",
      "\n",
      "    accuracy                           0.51       140\n",
      "   macro avg       0.54      0.53      0.51       140\n",
      "weighted avg       0.55      0.51      0.51       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- A) Define your filter-bank & pre-compute SOS filters ---\n",
    "bands = [(8, 12), (12, 16), (16, 20), (20, 24), (24, 30)]\n",
    "sos_bands = [butter(4, (l / 125, h / 125), btype=\"bandpass\", output=\"sos\") for l, h in bands]\n",
    "\n",
    "\n",
    "def compute_fb_covs(X):\n",
    "    \"\"\"X: (n_trials, C, T) → fb_covs: (n_trials, B, C, C)\"\"\"\n",
    "    n, C, _ = X.shape\n",
    "    B = len(sos_bands)\n",
    "    fb_covs = np.zeros((n, B, C, C))\n",
    "    for i, sos in enumerate(sos_bands):\n",
    "        Xf = sosfiltfilt(sos, X, axis=2)\n",
    "        fb_covs[:, i] = Covariances(estimator=\"lwf\").transform(Xf)\n",
    "    return fb_covs\n",
    "\n",
    "\n",
    "def fb_rts_fsvm(X, y):\n",
    "    \"\"\"\n",
    "    Implements Filter-Bank + Riemannian Tangent Space +\n",
    "    Feature-weighted SVM (FBRTS + FWSVM).\n",
    "    \"\"\"\n",
    "    fb_covs = compute_fb_covs(X)  # (n_trials, B, C, C)\n",
    "    n, B, C, _ = fb_covs.shape\n",
    "\n",
    "    covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "    labels_rep = np.repeat(y, B)\n",
    "\n",
    "    ts = TangentSpace(metric=\"riemann\").fit(covs_flat, labels_rep)\n",
    "    Z = ts.transform(covs_flat)  # (n*B, D), with D = C(C+1)/2\n",
    "    Z = Z.reshape(n, B, -1)  # (n, B, D)\n",
    "\n",
    "    w = mutual_info_classif(Z.reshape(n, -1), y, discrete_features=False).reshape(B, -1).mean(axis=1)  # flatten all bands → (n, B·D)  # average MI per band → (B,)\n",
    "    w = w / w.sum()\n",
    "\n",
    "    Z_weighted = np.concatenate([np.sqrt(w[i]) * Z[:, i, :] for i in range(B)], axis=1)  # → (n, B·D)\n",
    "\n",
    "    clf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        # SVC(kernel=\"linear\", probability=True),\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    )\n",
    "    clf.fit(Z_weighted, y)\n",
    "    return ts, w, clf\n",
    "\n",
    "\n",
    "def predict_fb_rts(ts, w, clf, X):\n",
    "    \"\"\"Given fitted ts, weights w, and clf, predict on new X.\"\"\"\n",
    "    fb_covs = compute_fb_covs(X)\n",
    "    n, B, C, _ = fb_covs.shape\n",
    "    covs_flat = fb_covs.reshape(n * B, C, C)\n",
    "    Z = ts.transform(covs_flat).reshape(n, B, -1)\n",
    "    Z_weighted = np.concatenate([np.sqrt(w[i]) * Z[:, i, :] for i in range(B)], axis=1)\n",
    "    return clf.predict(Z_weighted)\n",
    "\n",
    "\n",
    "# --- Example usage (no re-initialization of X_train, etc.) ---\n",
    "ts, w, clf = fb_rts_fsvm(X_train, y_train)\n",
    "y_pred = predict_fb_rts(ts, w, clf, X_val)\n",
    "\n",
    "\n",
    "print(\"Val Acc:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
