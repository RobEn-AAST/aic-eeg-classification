{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2a563374",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "2a563374",
        "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "if not os.path.exists('./modules') and not os.path.exists('modules.zip'):\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "if not os.path.exists('./modules') and os.path.exists('modules.zip'):\n",
        "    os.system('unzip modules.zip -d .')\n",
        "\n",
        "!pip3 install optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import optuna\n",
        "from modules import Trainer\n",
        "from modules.competition_dataset import EEGDataset\n",
        "from modules.utils import split_and_get_loaders, evaluate_model, get_closest_divisor\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c5bf7b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8c5bf7b0",
        "outputId": "e981327e-6451-4cf6-8020-c4fb791c5b99"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# data_path = '/content/drive/MyDrive/ai_data/eeg_detection/data/mtcaic3'\n",
        "# model_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/models/ssvep.pth'\n",
        "# optuna_db_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/optuna/optuna_studies.db'\n",
        "data_path = './data/mtcaic3'\n",
        "model_path = './checkpoints/ssvep/models/75_lstm.pth'\n",
        "optuna_db_path = './checkpoints/ssvep/optuna/2_optuna_studies.db'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a17b42a7",
      "metadata": {
        "id": "a17b42a7"
      },
      "outputs": [],
      "source": [
        "# Add this at the beginning of your notebook, after imports\n",
        "def set_random_seeds(seed=42):\n",
        "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Call this function before creating datasets and models\n",
        "set_random_seeds(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b83a09b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8b83a09b",
        "outputId": "7953a54d-dc84-4d00-c6e0-176c3d3d5133"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4964, 0.4826, 0.4628, 0.5279],\n",
              "        [0.4981, 0.4752, 0.4634, 0.5338],\n",
              "        [0.5023, 0.4834, 0.4610, 0.5220],\n",
              "        [0.4969, 0.4791, 0.4632, 0.5333],\n",
              "        [0.4995, 0.4798, 0.4620, 0.5322]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of the LConvNet model described in the paper:\n",
        "    \"Enhancing EEG signals classification using LSTM-CNN architecture\" (Omar et al., 2024).\n",
        "\n",
        "    The architecture is based on the specifications in Table 1 of the paper.\n",
        "    There are some inconsistencies between the paper's text/diagrams and Table 1.\n",
        "    This implementation follows Table 1, as the parameter counts confirm its structure.\n",
        "    For example, the final Conv2D layer has 68 filters (not 64), and the Dense/LSTM layers\n",
        "    use 32 units (not 64).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_channels=25, n_samples=256, n_classes=1, dropout_rate=0.5, lstm_units=32, dense_units=32):\n",
        "        super(LConvNet, self).__init__()\n",
        "\n",
        "        self.n_channels = n_channels\n",
        "        self.n_samples = n_samples\n",
        "        self.n_classes = n_classes # Binary classification (epileptic vs healthy)\n",
        "\n",
        "        # --- CNN Feature Extractor ---\n",
        "        # This block corresponds to layers 1, 2, and 3 in Table 1.\n",
        "        # It processes the input EEG data to extract spatial features.\n",
        "        self.cnn_block = nn.Sequential(\n",
        "            # Input shape for Conv2D: (B, 1, n_channels, n_samples)\n",
        "            # Layer 1\n",
        "            nn.Conv2d(1, 16, kernel_size=(3, 3), padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "            \n",
        "            # Layer 2\n",
        "            nn.Conv2d(16, 32, kernel_size=(5, 5), padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "\n",
        "            # Layer 3 - Note: Table 1's parameter count confirms 68 filters, not 64.\n",
        "            nn.Conv2d(32, 68, kernel_size=(7, 7), padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "            \n",
        "            # Layer 3 also includes dropout\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        # --- Time-Distributed Dense Layer ---\n",
        "        # Corresponds to layer 5 in Table 1.\n",
        "        # The output of the CNN block is flattened and fed into a dense layer,\n",
        "        # applied to each \"time step\" from the CNN's output.\n",
        "        # The input features are calculated from the CNN output shape: 68 filters * 3 * 32 = 6912.\n",
        "        # Let's re-calculate the flattened dimension from the CNN output.\n",
        "        # After MaxPool3: H_out = floor((H_in-2)/2 + 1), W_out = floor((W_in-2)/2 + 1)\n",
        "        # H1 = floor(25/2) = 12, W1 = floor(256/2) = 128\n",
        "        # H2 = floor(12/2) = 6, W2 = floor(128/2) = 64\n",
        "        # H3 = floor(6/2) = 3, W3 = floor(64/2) = 32\n",
        "        # So the flattened dimension is 68 * 3 * 32 = 6528. The paper's param count for layer 5 (69664)\n",
        "        # implies an input of 2176, which is 68 * 32. This suggests they permuted the dimensions\n",
        "        # so that the height (3) became the time dimension.\n",
        "        # Input to this layer will be (B, 3, 6528/3) = (B, 3, 2176)\n",
        "        self.time_distributed_dense = nn.Linear(68 * 32, dense_units)\n",
        "\n",
        "        # --- LSTM for Temporal Dependencies ---\n",
        "        # Corresponds to layer 6 in Table 1. It processes the sequence from the\n",
        "        # Time-Distributed Dense layer. Table 1 parameter count confirms 32 units.\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=dense_units,\n",
        "            hidden_size=lstm_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True # This is important for matching tensor shapes\n",
        "        )\n",
        "\n",
        "        # --- Global Average Pooling Branch ---\n",
        "        # Corresponds to layer 7 in Table 1. This branch takes the original input\n",
        "        # and computes the average over the time dimension.\n",
        "        # It provides a summary of the spatial information.\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # --- Final Classifier ---\n",
        "        # Corresponds to layer 8 in Table 1. It concatenates the features from the\n",
        "        # LSTM branch and the GAP branch and makes the final prediction.\n",
        "        # Input features = lstm_units + n_channels = 32 + 25 = 57.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_units + n_channels, self.n_classes),\n",
        "            nn.Sigmoid() # Sigmoid for binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Expected input shape: (B, C, T) -> (Batch, Channels, Samples)\n",
        "        Example from paper: (B, 25, 256)\n",
        "        \"\"\"\n",
        "        # Keep a reference to the original input for the GAP branch\n",
        "        gap_input = x\n",
        "\n",
        "        # 1. CNN Block\n",
        "        # Add a channel dimension for Conv2D: (B, C, T) -> (B, 1, C, T)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.cnn_block(x) # Output shape: (B, 68, 3, 32)\n",
        "\n",
        "        # 2. Time-Distributed Dense\n",
        "        # Permute to make the height dimension (3) the time dimension for the sequence\n",
        "        x = x.permute(0, 2, 1, 3) # (B, 3, 68, 32)\n",
        "        # Flatten the spatial features for the dense layer\n",
        "        x = x.reshape(x.size(0), x.size(1), -1) # (B, 3, 68 * 32) -> (B, 3, 2176)\n",
        "        x = self.time_distributed_dense(x) # (B, 3, 32)\n",
        "        \n",
        "        # 3. LSTM Block\n",
        "        # We only need the final hidden state for classification\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        lstm_features = hn.squeeze(0) # Shape: (B, 32)\n",
        "\n",
        "        # 4. Global Average Pooling Block\n",
        "        # Input shape: (B, 25, 256)\n",
        "        pooled_features = self.global_avg_pool(gap_input) # Output shape: (B, 25, 1)\n",
        "        pooled_features = pooled_features.squeeze(2) # Output shape: (B, 25)\n",
        "\n",
        "        # 5. Concatenate and Classify\n",
        "        combined_features = torch.cat((lstm_features, pooled_features), dim=1) # Shape: (B, 57)\n",
        "        output = self.classifier(combined_features) # Shape: (B, 1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "dummy_x = torch.randn(5, 8, 256)\n",
        "model = LConvNet(n_channels=8, n_classes=4).to(device)\n",
        "model(dummy_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "42089fb8",
      "metadata": {
        "id": "42089fb8"
      },
      "outputs": [],
      "source": [
        "window_length = 256\n",
        "stride = 128\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2c8ee6c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean: [[[  18.94653916]\n",
            "  [  -4.79315914]\n",
            "  [-155.33400078]\n",
            "  ...\n",
            "  [  -0.85366908]\n",
            "  [ -21.21283221]\n",
            "  [ -10.88007821]]\n",
            "\n",
            " [[   2.88797945]\n",
            "  [  14.03066089]\n",
            "  [ 158.92097775]\n",
            "  ...\n",
            "  [   0.64594806]\n",
            "  [   9.30438465]\n",
            "  [   4.13539372]]\n",
            "\n",
            " [[ -27.57951229]\n",
            "  [ -16.84199493]\n",
            "  [ -86.29044736]\n",
            "  ...\n",
            "  [   1.26474958]\n",
            "  [   7.93034018]\n",
            "  [   4.70334708]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[   5.58468604]\n",
            "  [ -38.77063466]\n",
            "  [ -24.45822144]\n",
            "  ...\n",
            "  [ -12.18208337]\n",
            "  [ -28.22180953]\n",
            "  [  -9.72892152]]\n",
            "\n",
            " [[  -3.73300704]\n",
            "  [  38.75802838]\n",
            "  [  27.31917901]\n",
            "  ...\n",
            "  [  10.76662178]\n",
            "  [  27.31073366]\n",
            "  [   9.00676603]]\n",
            "\n",
            " [[   1.75415838]\n",
            "  [ -36.39651433]\n",
            "  [ -30.74731076]\n",
            "  ...\n",
            "  [  -9.18116839]\n",
            "  [ -25.04968969]\n",
            "  [  -8.3511859 ]]], std: [[[ 534.64056483]\n",
            "  [ 247.66103768]\n",
            "  [2263.63560173]\n",
            "  ...\n",
            "  [  22.00025365]\n",
            "  [ 346.158536  ]\n",
            "  [ 172.03318645]]\n",
            "\n",
            " [[ 562.32708628]\n",
            "  [ 236.51261777]\n",
            "  [2192.90329526]\n",
            "  ...\n",
            "  [  18.76510161]\n",
            "  [ 333.84927349]\n",
            "  [ 164.23415602]]\n",
            "\n",
            " [[ 562.43575935]\n",
            "  [ 239.90310922]\n",
            "  [2155.81437682]\n",
            "  ...\n",
            "  [  18.16956075]\n",
            "  [ 326.37162847]\n",
            "  [ 161.36398785]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[  96.8656742 ]\n",
            "  [ 491.66399278]\n",
            "  [ 382.8196734 ]\n",
            "  ...\n",
            "  [ 146.80514879]\n",
            "  [ 349.18153871]\n",
            "  [ 118.21435155]]\n",
            "\n",
            " [[  98.87665269]\n",
            "  [ 491.52560706]\n",
            "  [ 381.30759531]\n",
            "  ...\n",
            "  [ 145.80431966]\n",
            "  [ 349.12469353]\n",
            "  [ 118.09898611]]\n",
            "\n",
            " [[  98.34491204]\n",
            "  [ 490.56764332]\n",
            "  [ 383.68477547]\n",
            "  ...\n",
            "  [ 144.54239911]\n",
            "  [ 348.62287798]\n",
            "  [ 118.10158911]]]\n"
          ]
        }
      ],
      "source": [
        "dataset = EEGDataset(data_path, window_length=window_length, stride=stride, split='train')\n",
        "train_loader, val_loader, test_loader = split_and_get_loaders(dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "12b164b5",
      "metadata": {
        "id": "12b164b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0, avg_loss: 1.3845494298169212, val_evaluation: 0.26424632352941174\n",
            "epoch: 1, avg_loss: 1.3834319915214595, val_evaluation: 0.2686121323529412\n",
            "epoch: 2, avg_loss: 1.381959608436501, val_evaluation: 0.27090992647058826\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m     opt.zero_grad()\n\u001b[32m     17\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     avg_loss += loss.item()\n\u001b[32m     21\u001b[39m avg_loss /= \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/optim/adam.py:525\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    523\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "avg_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    avg_loss = 0\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        y_pred = model(x).to(device)\n",
        "\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "    avg_loss /= len(train_loader)\n",
        "    avg_losses.append(avg_loss)\n",
        "\n",
        "    evaluation = evaluate_model(model, val_loader, device)\n",
        "    val_accuracies.append(evaluation)\n",
        "    print(f'epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "OBfEejXsGwBy",
      "metadata": {
        "id": "OBfEejXsGwBy"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'avg_losses' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# maxpool\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mavg_losses\u001b[49m)), avg_losses, \u001b[33m\"\u001b[39m\u001b[33mb-\u001b[39m\u001b[33m\"\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mtrainingg loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_accuracies)), val_accuracies, \u001b[33m\"\u001b[39m\u001b[33mr-\u001b[39m\u001b[33m\"\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mvalidation accuracies\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.legend()\n",
            "\u001b[31mNameError\u001b[39m: name 'avg_losses' is not defined"
          ]
        }
      ],
      "source": [
        "# maxpool\n",
        "plt.plot(range(len(avg_losses)), avg_losses, \"b-\", label=\"trainingg loss\")\n",
        "plt.plot(range(len(val_accuracies)), val_accuracies, \"r-\", label=\"validation accuracies\")\n",
        "plt.legend()\n",
        "print(f\"min avg_losses: {min(avg_losses)}\")\n",
        "print(f\"max val_accuracies: {max(val_accuracies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "PpaZKc26qyr4",
      "metadata": {
        "id": "PpaZKc26qyr4"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "window_length = 175\n",
        "stride_factor=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2dec2ee1",
      "metadata": {
        "id": "2dec2ee1"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def _prepare_training(self, is_trial, do_not_modify_network=True, batch_size=batch_size, window_length=window_length, stride_factor=stride_factor):\n",
        "        super()._prepare_training(is_trial, do_not_modify_network, batch_size=batch_size,\n",
        "                                  window_length=window_length,\n",
        "                                  stride_factor=stride_factor)\n",
        "        assert self.dataset is not None\n",
        "\n",
        "        if is_trial:\n",
        "            assert isinstance(self.trial, optuna.Trial), \"trial is none, cant' suggest params\"\n",
        "\n",
        "            if do_not_modify_network:\n",
        "                best_params = self._get_study().best_params if do_not_modify_network else None\n",
        "                assert best_params is not None, \"best_params is None, can't use them\"\n",
        "\n",
        "                kernLength = best_params[\"kernLength\"]\n",
        "                F1 = best_params[\"F1\"]\n",
        "                D = best_params[\"D\"]\n",
        "                F2 = best_params[\"F2\"]\n",
        "                hidden_dim = best_params[\"hidden_dim\"]\n",
        "                layer_dim = best_params[\"layer_dim\"]\n",
        "\n",
        "            else:\n",
        "                kernLength = self.trial.suggest_categorical(\"kernLength\", [128, 256, 512])\n",
        "                F1 = self.trial.suggest_categorical(\"F1\", [64, 96, 128])\n",
        "                D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
        "                F2 = self.trial.suggest_categorical(\"F2\", [64, 96, 128])\n",
        "                hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
        "                layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3, 4])\n",
        "\n",
        "            dropout = self.trial.suggest_float(\"dropout\", 0, 0.5)\n",
        "            lr = self.trial.suggest_float(\"lr\", 3e-4, 3e-2, log=True)\n",
        "\n",
        "        else:\n",
        "            # best_params = self._get_study().best_params\n",
        "            # kernLength = best_params[\"kernLength\"]\n",
        "            # F1 = best_params[\"F1\"]\n",
        "            # D = best_params[\"D\"]\n",
        "            # F2 = best_params[\"F2\"]\n",
        "            # hidden_dim = best_params[\"hidden_dim\"]\n",
        "            # layer_dim = best_params[\"layer_dim\"]\n",
        "            # dropout = best_params[\"dropout\"]\n",
        "            # lr = best_params[\"lr\"]\n",
        "            dropout=0.33066508963955576\n",
        "            kernLength=256\n",
        "            F1 = 128\n",
        "            D = 2\n",
        "            F2 = F1 # OOPS 96\n",
        "            hidden_dim=256\n",
        "            layer_dim=3\n",
        "            lr = 0.000010241790493218325\n",
        "\n",
        "        n_samples = self.dataset.data[0].shape[1]  # data[x] shape CxT\n",
        "        n_electrodes = self.dataset.data[0].shape[0]\n",
        "\n",
        "        n_samples = self.dataset.data[0].shape[1]  # data[x] shape CxT\n",
        "        n_electrodes = self.dataset.data[0].shape[0]\n",
        "\n",
        "        self.model = SSVEPClassifier(\n",
        "            n_electrodes=n_electrodes, n_samples=n_samples, out_dim=4, dropout=dropout, kernLength=kernLength, F1=F1, D=D, F2=F2, hidden_dim=hidden_dim, layer_dim=layer_dim\n",
        "        )\n",
        "        print(f\"lr: {lr}\")\n",
        "        try:\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "            print(f\"loaded model weights\")\n",
        "        except Exception:\n",
        "            print(f\"no model weights found at {model_path}\")\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
        "\n",
        "trainer = CustomTrainer(data_path, optuna_db_path, model_path, train_epochs=10000, optuna_n_trials=35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a132bf51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "a132bf51",
        "outputId": "fce5db39-6f8c-4201-da84-09fc34a1779e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-20 18:42:30,753] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n",
            "[I 2025-06-20 18:42:30,815] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n",
            "[W 2025-06-20 18:42:30,839] Trial 0 failed with parameters: {} because of the following error: ValueError('Record does not exist.').\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/Workspace/ai_projects/eeg_detection/modules/trainer.py\", line 101, in _objective\n",
            "    self._prepare_training(True)\n",
            "  File \"/tmp/ipykernel_306525/3387801006.py\", line 3, in _prepare_training\n",
            "    super()._prepare_training(is_trial, do_not_modify_network, batch_size=batch_size,\n",
            "  File \"/home/zeyadcode/Workspace/ai_projects/eeg_detection/modules/trainer.py\", line 80, in _prepare_training\n",
            "    best_params = self._get_study().best_params\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py\", line 119, in best_params\n",
            "    return self.best_trial.params\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py\", line 155, in best_trial\n",
            "    return self._get_best_trial(deepcopy=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py\", line 307, in _get_best_trial\n",
            "    best_trial = self._storage.get_best_trial(self._study_id)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_cached_storage.py\", line 180, in get_best_trial\n",
            "    return self._backend.get_best_trial(study_id)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py\", line 914, in get_best_trial\n",
            "    trial_id = models.TrialModel.find_max_value_trial_id(study_id, 0, session)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/models.py\", line 211, in find_max_value_trial_id\n",
            "    raise ValueError(NOT_FOUND_MSG)\n",
            "ValueError: Record does not exist.\n",
            "[W 2025-06-20 18:42:30,845] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Record does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m delete_existing = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelete_existing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/ai_projects/eeg_detection/modules/trainer.py:120\u001b[39m, in \u001b[36mTrainer.optimize\u001b[39m\u001b[34m(self, delete_existing)\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    119\u001b[39m study = \u001b[38;5;28mself\u001b[39m._get_study()\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptuna_n_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Print optimization results\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStudy statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/ai_projects/eeg_detection/modules/trainer.py:101\u001b[39m, in \u001b[36mTrainer._objective\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial: optuna.Trial):\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m.trial = trial\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mmodel is not set, can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt train, ensure to set it after overriding\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33moptimizer is not set, can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt train, ensure to set it after overriding\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mCustomTrainer._prepare_training\u001b[39m\u001b[34m(self, is_trial, do_not_modify_network, batch_size, window_length, stride_factor)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, is_trial, do_not_modify_network=\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size=batch_size, window_length=window_length, stride_factor=stride_factor):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_prepare_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_not_modify_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mstride_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/ai_projects/eeg_detection/modules/trainer.py:80\u001b[39m, in \u001b[36mTrainer._prepare_training\u001b[39m\u001b[34m(self, is_trial, do_not_modify_network, batch_size, window_length, stride_factor)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.trial, optuna.Trial), \u001b[33m\"\u001b[39m\u001b[33mtrial is none, cant\u001b[39m\u001b[33m'\u001b[39m\u001b[33m suggest params\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_not_modify_network:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     best_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_params\u001b[49m\n\u001b[32m     81\u001b[39m     window_length = best_params[\u001b[33m'\u001b[39m\u001b[33mwindow_length\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     82\u001b[39m     batch_size = batch_size \u001b[38;5;129;01mor\u001b[39;00m best_params[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:119\u001b[39m, in \u001b[36mStudy.best_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    109\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[32m    110\u001b[39m \n\u001b[32m    111\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_trial\u001b[49m.params\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:155\u001b[39m, in \u001b[36mStudy.best_trial\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> FrozenTrial:\n\u001b[32m    140\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the best trial in the study.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:307\u001b[39m, in \u001b[36mStudy._get_best_trial\u001b[39m\u001b[34m(self, deepcopy)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi_objective():\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m best_trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[32m    312\u001b[39m constraints = best_trial.system_attrs.get(_CONSTRAINTS_KEY)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_cached_storage.py:180\u001b[39m, in \u001b[36m_CachedStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_best_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_id: \u001b[38;5;28mint\u001b[39m) -> FrozenTrial:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py:914\u001b[39m, in \u001b[36mRDBStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    911\u001b[39m direction = _directions[\u001b[32m0\u001b[39m]\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m direction == StudyDirection.MAXIMIZE:\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     trial_id = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrialModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_max_value_trial_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    916\u001b[39m     trial_id = models.TrialModel.find_min_value_trial_id(study_id, \u001b[32m0\u001b[39m, session)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/models.py:211\u001b[39m, in \u001b[36mTrialModel.find_max_value_trial_id\u001b[39m\u001b[34m(cls, study_id, objective, session)\u001b[39m\n\u001b[32m    191\u001b[39m trial = (\n\u001b[32m    192\u001b[39m     session.query(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    193\u001b[39m     .with_entities(\u001b[38;5;28mcls\u001b[39m.trial_id)\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m     .one_or_none()\n\u001b[32m    209\u001b[39m )\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(NOT_FOUND_MSG)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mValueError\u001b[39m: Record does not exist."
          ]
        }
      ],
      "source": [
        "delete_existing = False\n",
        "trainer.optimize(delete_existing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93294ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "a93294ea",
        "outputId": "e77ed180-3a33-492a-c29e-15a57befbbae"
      },
      "outputs": [],
      "source": [
        "# manual_write_study_params(trainer.study_name, trainer.storage)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1d8d4e73",
      "metadata": {
        "id": "1d8d4e73",
        "outputId": "879ad0ae-f397-49f7-e3ba-7d299bdcecf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr: 1.0241790493218325e-05\n",
            "loaded model weights\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'test accuracy: 0.74484375'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer._prepare_training(False)\n",
        "trainer.model.eval()\n",
        "f\"test accuracy: {evaluate_model(trainer.model, trainer.test_loader, device)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cb8d0abe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from scipy.fft import fft, rfft\n",
        "from scipy import signal\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "\n",
        "\n",
        "LABELS = ['Backward', 'Forward', 'Left', 'Right']\n",
        "LABEL_TO_IDX = {lbl: i for i, lbl in enumerate(LABELS)}\n",
        "IDX_TO_LABEL = {idx: label for idx, label in enumerate(LABELS)}\n",
        "\n",
        "# Precompute filter once\n",
        "_SFREQ    = 256\n",
        "_LOW, _HI = 3, 100\n",
        "_NYQ      = _SFREQ / 2.0\n",
        "_B, _A    = signal.butter(4, [_LOW/_NYQ, _HI/_NYQ], btype='bandpass')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "70d65268",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0)\n",
            "tensor([285661.468750, 299282.437500, 351748.000000, 387430.937500,\n",
            "        429527.781250, 281785.593750, 272474.312500, 271807.593750])\n",
            "torch.Size([10, 8, 175])\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'eval'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m tensor = torch.from_numpy(data_array.copy()).to(torch.float32)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(tensor.shape)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m()\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.softmax(trainer.model(tensor), dim=\u001b[32m1\u001b[39m))\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.argmax(trainer.model(tensor), dim=\u001b[32m1\u001b[39m))\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'eval'"
          ]
        }
      ],
      "source": [
        "fn = \"./data/mtcaic3/SSVEP/validation/S35/1/EEGdata.csv\"\n",
        "torch.set_printoptions(sci_mode=False, precision=6)\n",
        "#correct is backward, forwaard, left, right\n",
        "\n",
        "def avg_refrencing(data: np.ndarray):\n",
        "    return data - data.mean(axis=2, keepdims=True)\n",
        "\n",
        "def band_pass_filter(data: np.ndarray):\n",
        "    return signal.filtfilt(_B, _A, data, axis=2)\n",
        "\n",
        "def normalize(data: np.ndarray):\n",
        "    mean = data.mean(axis=2, keepdims=True)\n",
        "    std  = data.std(axis=2, keepdims=True) + 1e-6\n",
        "    data = (data - mean) / std\n",
        "    return data\n",
        "\n",
        "cols = ['FZ','C3','CZ','C4','PZ','PO7','OZ','PO8']\n",
        "\n",
        "df = pd.read_csv(fn, usecols=cols)\n",
        "df_valid = pd.read_csv(fn, usecols=['Validation'])\n",
        "last175 = df\n",
        "\n",
        "i = 7\n",
        "tensor = torch.tensor(last175.values, dtype=torch.float32)[-1750 * i:-1750 * (i - 1), :].view(10, 175, 8).permute(0, 2, 1)\n",
        "valid_tensor = torch.tensor(df_valid.values, dtype=torch.float32)[-1750 * i:-1750 * (i - 1), :].view(10, 175, 1)\n",
        "print((valid_tensor == 0).sum())\n",
        "print(tensor[-1][:, 0])\n",
        "data_array = avg_refrencing(tensor.numpy())\n",
        "data_array = band_pass_filter(data_array)\n",
        "data_array = normalize(data_array)\n",
        "\n",
        "tensor = torch.from_numpy(data_array.copy()).to(torch.float32)\n",
        "print(tensor.shape)\n",
        "trainer.model.eval()\n",
        "print(torch.softmax(trainer.model(tensor), dim=1))\n",
        "print(torch.argmax(trainer.model(tensor), dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "ca653d4b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.014051,  0.760070, -0.390054,  ...,  1.452694,  0.092904,\n",
            "          0.152871],\n",
            "        [ 0.080737, -1.386883, -1.813527,  ..., -2.237866, -1.017529,\n",
            "          0.188362],\n",
            "        [ 0.061857,  0.087862, -1.565250,  ...,  0.266991, -0.599239,\n",
            "          0.293950],\n",
            "        ...,\n",
            "        [ 0.075408, -1.377178, -1.511927,  ..., -2.300731, -0.829118,\n",
            "          0.133468],\n",
            "        [ 0.075436, -1.367463, -1.623659,  ..., -2.319957, -0.983773,\n",
            "          0.143160],\n",
            "        [ 0.112787, -1.282061, -2.147263,  ..., -2.190778, -1.087937,\n",
            "          0.217843]])\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "# 1. Your target tensor (shape [8,175])\n",
        "target = tensor[0]  \n",
        "\n",
        "# 2. Grab the underlying Dataset\n",
        "ds = trainer.train_loader.dataset\n",
        "\n",
        "best_dist = float('inf')\n",
        "best_label = None\n",
        "best_data = None\n",
        "\n",
        "# 3. Iterate over every sample in the Dataset\n",
        "for i in range(len(ds)):\n",
        "    item = ds[i]\n",
        "    # unpack data & label\n",
        "    if isinstance(item, (tuple, list)):\n",
        "        data_i, label_i = item[0], item[1]\n",
        "    elif isinstance(item, dict):\n",
        "        # adjust key names if needed\n",
        "        data_i, label_i = item.get('eeg', item.get('data')), item['label']\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # convert numpy → torch if necessary\n",
        "    if isinstance(data_i, np.ndarray):\n",
        "        data_i = torch.from_numpy(data_i)\n",
        "\n",
        "    # ensure same shape\n",
        "    data_i = data_i.view_as(target)\n",
        "\n",
        "    # compute Euclidean distance\n",
        "    dist = torch.norm(data_i - target).item()\n",
        "\n",
        "    if dist < best_dist:\n",
        "        best_dist = dist\n",
        "        best_label = label_i\n",
        "        best_data = data_i\n",
        "\n",
        "print(best_data)\n",
        "# 4. Print the label of the most similar sample\n",
        "print(best_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "632bb841",
      "metadata": {
        "id": "632bb841",
        "outputId": "e183c6ea-de52-4d6d-b8a2-2f6cdfcaa899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[     7.525880,    366.709625,   -187.037323,  ...,\n",
              "            700.185608,     45.491299,     74.363281],\n",
              "        [    -1.113108,   -418.527405,   -539.871704,  ...,\n",
              "           -660.560547,   -313.477386,     29.497141],\n",
              "        [     4.467845,     13.405240,   -554.742981,  ...,\n",
              "             74.969322,   -222.740326,     84.234581],\n",
              "        ...,\n",
              "        [    -0.338264,   -185.773224,   -202.974960,  ...,\n",
              "           -303.672516,   -115.808647,      7.073462],\n",
              "        [    -1.511939,   -404.904968,   -476.529968,  ...,\n",
              "           -671.194824,   -297.636383,     17.421761],\n",
              "        [     1.490031,   -154.565750,   -251.364700,  ...,\n",
              "           -256.233124,   -132.847198,     13.243663]])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "icmtc_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
