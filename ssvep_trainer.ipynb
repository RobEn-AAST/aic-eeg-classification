{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563374",
   "metadata": {
    "cellUniqueIdByVincent": "b5c77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "2a563374",
    "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from modules import Trainer\n",
    "from modules.competition_dataset import EEGDataset, LABELS\n",
    "from modules.utils import evaluate_model\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset, random_split, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5bf7b0",
   "metadata": {
    "cellUniqueIdByVincent": "e6823",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8c5bf7b0",
    "outputId": "e981327e-6451-4cf6-8020-c4fb791c5b99"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/ai_data/eeg_detection/data/mtcaic3'\n",
    "# model_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/models/ssvep.pth'\n",
    "# optuna_db_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/optuna/optuna_studies.db'\n",
    "data_path = './data/mtcaic3'\n",
    "model_path = './checkpoints/ssvep/models/ssvep_the_honored_one.pth'\n",
    "optuna_db_path = './checkpoints/ssvep/optuna/ssvep.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17b42a7",
   "metadata": {
    "cellUniqueIdByVincent": "285db",
    "id": "a17b42a7"
   },
   "outputs": [],
   "source": [
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call this function before creating datasets and models\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42089fb8",
   "metadata": {
    "cellUniqueIdByVincent": "77c22",
    "id": "42089fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Using 50.0% of data: 1200/1200 samples\n",
      "skipped: 1/1200\n",
      "data shape: (12529, 2, 384), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (514, 2, 384), mean shape: (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "window_length = 128 * 3 # ensure divisble by 64 the kernel size\n",
    "print(window_length)\n",
    "stride = window_length // 3\n",
    "batch_size = 64\n",
    "\n",
    "dataset_train = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    domain=\"time\",\n",
    "    data_fraction=0.5,\n",
    "    hardcoded_mean=True,\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task='ssvep',\n",
    "    split='validation',\n",
    "    read_labels=True,\n",
    "    hardcoded_mean=True,\n",
    "    data_fraction=1\n",
    ")\n",
    "\n",
    "combined = ConcatDataset([dataset_train, dataset_val])\n",
    "train_len = int(len(combined) * 0.8)\n",
    "val_len = len(combined) - train_len\n",
    "train_ds, val_ds = random_split(combined, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd5f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0235,  0.0492, -0.0168,  0.0635],\n",
       "        [-0.0001,  0.0575, -0.0109,  0.0280],\n",
       "        [-0.0014,  0.0460, -0.0001,  0.0372],\n",
       "        [-0.0050,  0.0383, -0.0173,  0.0532],\n",
       "        [ 0.0113,  0.0471, -0.0220,  0.0520]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class DepthWiseConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, dim_mult=1, padding=0, bias=False):\n",
    "        super(DepthWiseConv2D, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels * dim_mult, padding=padding, kernel_size=kernel_size, groups=in_channels, bias=bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.depthwise(x)\n",
    "\n",
    "\n",
    "class SeperableConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=False):\n",
    "        super(SeperableConv2D, self).__init__()\n",
    "        self.depthwise = DepthWiseConv2D(in_channels, kernel_size, padding=padding)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class SSVEPClassifier(nn.Module):\n",
    "    # EEG Net Based\n",
    "    # todo look at this https://paperswithcode.com/paper/a-transformer-based-deep-neural-network-model\n",
    "    def __init__(self, n_electrodes=16, out_dim=4, dropout=0.25, kernLength=256, F1=96, D=1, F2=96, hidden_dim=100, layer_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # B x C x T\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernLength), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            #\n",
    "            DepthWiseConv2D(F1, (n_electrodes, 1), dim_mult=D, bias=False),\n",
    "            nn.BatchNorm2d(F1*D),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((1, 2)), # todo try making this max pool\n",
    "            nn.Dropout(dropout),\n",
    "            #\n",
    "            SeperableConv2D(F1 * D, F2, kernel_size=(1, 16), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.lstm_head = LSTMModel(F2, hidden_dim, layer_dim, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"expected input shape: BxCxT\"\"\"\n",
    "        x = x.unsqueeze(1)\n",
    "        y = self.block_1(x) # B x F1 x 1 x time_sub\n",
    "\n",
    "        y = y.squeeze(2) # B x F1 x time_sub\n",
    "        y = y.permute(0, 2, 1) # B x time_sub x F1\n",
    "        y = self.lstm_head(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "dummy_x = torch.randn(5, 2, 256).to(device)\n",
    "model = SSVEPClassifier(\n",
    "    n_electrodes=2,\n",
    "    dropout=0.33066508963955576,\n",
    "    kernLength=64,\n",
    "    F1 = 128,\n",
    "    D = 1,\n",
    "    F2 = 256,\n",
    "    hidden_dim=256,\n",
    "    layer_dim=2,\n",
    ").to(device)\n",
    "\n",
    "model(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b164b5",
   "metadata": {
    "cellUniqueIdByVincent": "c9b4e",
    "id": "12b164b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, avg_loss: 1.2615062517694908, val_evaluation: 0.44597126795752656\n",
      "epoch: 5, avg_loss: 1.2056106163723634, val_evaluation: 0.4415990006246096\n",
      "epoch: 10, avg_loss: 1.1648569112957115, val_evaluation: 0.46595877576514677\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m     loss.backward()\n\u001b[32m     24\u001b[39m     opt.step()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     avg_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m avg_loss /= \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m     28\u001b[39m avg_losses.append(avg_loss)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "except Exception:\n",
    "    print(\"skipping model loading...\")\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.00030241790493218325)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "avg_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 4000\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).to(torch.int64)\n",
    "        y_pred = model(x).to(device)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader)\n",
    "    avg_losses.append(avg_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        evaluation = evaluate_model(model, val_loader, device)\n",
    "        val_accuracies.append(evaluation)\n",
    "        model.cpu()\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        model.to(device)\n",
    "        print(f\"epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dec2ee1",
   "metadata": {
    "cellUniqueIdByVincent": "e8792",
    "id": "2dec2ee1"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    # This method is called by _objective during an Optuna trial\n",
    "    def prepare_trial_run(self):\n",
    "        assert isinstance(self.trial, optuna.Trial), \"Trial not set!\"\n",
    "\n",
    "        # 1. Define Hyperparameters for this trial\n",
    "        #    a. Data/Loader parameters\n",
    "        window_length = self.trial.suggest_categorical(\"window_length\", [128, 256, 640]) # e.g. 64*2, 64*4, 64*10\n",
    "        batch_size = self.trial.suggest_categorical(\"batch_size\", [32, 64])\n",
    "\n",
    "        #    b. Model architecture parameters\n",
    "        kernLength = self.trial.suggest_categorical(\"kernLength\", [64, 128, 256])\n",
    "        F1 = self.trial.suggest_categorical(\"F1\", [8, 16, 32])\n",
    "        D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
    "        F2 = self.trial.suggest_categorical(\"F2\", [16, 32, 64]) # F2 must be F1 * D\n",
    "        hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3])\n",
    "        dropout = self.trial.suggest_float(\"dropout\", 0.1, 0.6)\n",
    "        \n",
    "        #    c. Optimizer parameters\n",
    "        lr = self.trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "        # 2. Prepare the data using these parameters\n",
    "        super()._prepare_data(is_trial=True, batch_size=batch_size, window_length=window_length)\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0] # Get shape from underlying dataset\n",
    "\n",
    "        # 3. Build the model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes, # Use value from data\n",
    "            dropout=dropout,\n",
    "            kernLength=kernLength,\n",
    "            F1=F1,\n",
    "            D=D,\n",
    "            F2=F1 * D, # F2 is dependent on F1 and D\n",
    "            hidden_dim=hidden_dim,\n",
    "            layer_dim=layer_dim,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    # This method is called by train() for the final run\n",
    "    def prepare_final_run(self):\n",
    "        # 1. Get the best hyperparameters from the completed study\n",
    "        study = self._get_study()\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        # 2. Prepare data using the best params\n",
    "        super()._prepare_data(is_trial=False) # is_trial=False handles getting params from study\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0]\n",
    "\n",
    "        # 3. Build the final model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes,\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            kernLength=best_params[\"kernLength\"],\n",
    "            F1=best_params[\"F1\"],\n",
    "            D=best_params[\"D\"],\n",
    "            F2=best_params[\"F1\"] * best_params[\"D\"],\n",
    "            hidden_dim=best_params[\"hidden_dim\"],\n",
    "            layer_dim=best_params[\"layer_dim\"],\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Optional: Load pre-existing weights if you are resuming\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(self.model_path))\n",
    "            print(f\"Loaded existing model weights from {self.model_path}\")\n",
    "        except Exception:\n",
    "            print(f\"No existing model weights found at {self.model_path}. Training from scratch.\")\n",
    "        \n",
    "        lr = 0.00018182233882257615 # best_params[\"lr\"]\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',        # “min” if you want to reduce lr when the quantity monitored has stopped decreasing\n",
    "            factor=0.5,        # new_lr = lr * factor\n",
    "            patience=20,        # number of epochs with no improvement after which lr will be reduced\n",
    "            threshold=1e-4,    # threshold for measuring the new optimum, to only focus on significant changes\n",
    "            threshold_mode='rel', # `'rel'` means compare change relative to best value. Could use `'abs'`.\n",
    "            cooldown=0,        # epochs to wait before resuming normal operation after lr has been reduced\n",
    "            min_lr=1e-6,       # lower bound on the lr\n",
    "        )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        data_path=data_path,\n",
    "        optuna_db_path=optuna_db_path,\n",
    "        model_path=model_path,\n",
    "        train_epochs=500, # Final training epochs\n",
    "        tune_epochs=50,   # Epochs per trial\n",
    "        optuna_n_trials=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132bf51",
   "metadata": {
    "cellUniqueIdByVincent": "00f49",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "a132bf51",
    "outputId": "fce5db39-6f8c-4201-da84-09fc34a1779e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:15:19,301] A new study created in RDB with name: ssvep_classifier_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study 'ssvep_classifier_optimization' deleted.\n",
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=141, Val batches=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:16:54,230] Trial 0 finished with value: 0.3016014234875445 and parameters: {'window_length': 640, 'batch_size': 32, 'kernLength': 256, 'F1': 8, 'D': 3, 'F2': 64, 'hidden_dim': 128, 'layer_dim': 2, 'dropout': 0.5209686203255685, 'lr': 0.000396594163838901}. Best is trial 0 with value: 0.3016014234875445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:18:51,308] Trial 1 finished with value: 0.4016274338854984 and parameters: {'window_length': 256, 'batch_size': 32, 'kernLength': 256, 'F1': 16, 'D': 2, 'F2': 16, 'hidden_dim': 64, 'layer_dim': 2, 'dropout': 0.34178090696330155, 'lr': 0.00012013939686290462}. Best is trial 1 with value: 0.4016274338854984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:21:05,733] Trial 2 finished with value: 0.5047951176983435 and parameters: {'window_length': 256, 'batch_size': 32, 'kernLength': 256, 'F1': 32, 'D': 3, 'F2': 16, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.27072914067188847, 'lr': 0.003415544035465565}. Best is trial 2 with value: 0.5047951176983435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:22:37,744] Trial 3 finished with value: 0.34670154024992733 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 8, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.2766800118548799, 'lr': 0.007986336796775765}. Best is trial 2 with value: 0.5047951176983435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=141, Val batches=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:24:28,098] Trial 4 finished with value: 0.31583629893238435 and parameters: {'window_length': 640, 'batch_size': 32, 'kernLength': 64, 'F1': 8, 'D': 2, 'F2': 16, 'hidden_dim': 128, 'layer_dim': 2, 'dropout': 0.25794926040204724, 'lr': 0.005782682258467888}. Best is trial 2 with value: 0.5047951176983435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=71, Val batches=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:25:03,842] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:25:19,853] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=468, Val batches=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:25:33,051] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=468, Val batches=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:25:50,105] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=936, Val batches=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:26:09,092] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:26:23,742] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:26:40,026] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:26:54,318] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:27:10,078] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:27:23,887] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:27:36,705] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:27:49,205] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:28:07,011] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=936, Val batches=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:28:22,532] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=141, Val batches=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:28:38,324] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=431, Val batches=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:28:53,974] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:29:06,169] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:29:19,033] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:30:56,168] Trial 23 finished with value: 0.5068294100552165 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 16, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.23034280399057303, 'lr': 0.004496130654360325}. Best is trial 23 with value: 0.5068294100552165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:32:21,345] Trial 24 finished with value: 0.43591979075850046 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 16, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.21824936853593288, 'lr': 0.0017365954870900704}. Best is trial 23 with value: 0.5068294100552165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:33:53,983] Trial 25 finished with value: 0.5260098808485906 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 16, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.2038648541113718, 'lr': 0.0020667262541921487}. Best is trial 25 with value: 0.5260098808485906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:34:06,261] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:34:17,481] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=71, Val batches=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:34:28,525] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=468, Val batches=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:34:42,632] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=71, Val batches=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:34:58,248] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:36:18,930] Trial 31 finished with value: 0.5297878523684976 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 16, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.2077357526503814, 'lr': 0.0017738156653704668}. Best is trial 31 with value: 0.5297878523684976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:36:29,857] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:37:54,836] Trial 33 finished with value: 0.5419936065097355 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 16, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.1952344844575938, 'lr': 0.0014640183506411913}. Best is trial 33 with value: 0.5419936065097355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:38:11,199] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:38:29,947] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:39:53,896] Trial 36 finished with value: 0.5896541702993315 and parameters: {'window_length': 256, 'batch_size': 64, 'kernLength': 256, 'F1': 16, 'D': 3, 'F2': 64, 'hidden_dim': 64, 'layer_dim': 1, 'dropout': 0.10328170267309397, 'lr': 0.0018182233882257615}. Best is trial 36 with value: 0.5896541702993315.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:40:05,723] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 44/960\n",
      "data shape: (5345, 2, 640), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (271, 2, 640), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=71, Val batches=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:40:16,023] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:40:28,029] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=468, Val batches=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:40:52,728] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:41:07,417] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:41:21,409] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:41:32,238] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:41:45,558] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:41:56,680] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:42:13,000] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:42:26,327] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (16360, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=216, Val batches=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:42:39,318] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40.0% of data: 960/960 samples\n",
      "skipped: 0/960\n",
      "data shape: (35569, 2, 128), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (1834, 2, 128), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=468, Val batches=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 21:42:51,651] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimization Finished ---\n",
      "Study statistics: \n",
      "  Number of finished trials: 50\n",
      "  Number of pruned trials: 39\n",
      "  Number of complete trials: 11\n",
      "Best trial:\n",
      "  Value: 0.5896541702993315\n",
      "  Best hyperparameters: \n",
      "    window_length: 256\n",
      "    batch_size: 64\n",
      "    kernLength: 256\n",
      "    F1: 16\n",
      "    D: 3\n",
      "    F2: 64\n",
      "    hidden_dim: 64\n",
      "    layer_dim: 1\n",
      "    dropout: 0.10328170267309397\n",
      "    lr: 0.0018182233882257615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'window_length': 256,\n",
       " 'batch_size': 64,\n",
       " 'kernLength': 256,\n",
       " 'F1': 16,\n",
       " 'D': 3,\n",
       " 'F2': 64,\n",
       " 'hidden_dim': 64,\n",
       " 'layer_dim': 1,\n",
       " 'dropout': 0.10328170267309397,\n",
       " 'lr': 0.0018182233882257615}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_existing = False\n",
    "trainer.optimize(delete_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a93294ea",
   "metadata": {
    "cellUniqueIdByVincent": "9a628",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "a93294ea",
    "outputId": "e77ed180-3a33-492a-c29e-15a57befbbae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 22:14:56,274] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n",
      "[I 2025-06-23 22:14:56,313] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped: 0/2400\n",
      "data shape: (41141, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n",
      "Data prepared: Train batches=525, Val batches=132\n",
      "Loaded existing model weights from ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Warning: self.trial is None. Assuming this is the final training phase.\n",
      "Epoch 0/500, Validation Accuracy: 0.7243, Avg Loss: 0.7900, lr: 0.00018182233882257614\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 1/500, Validation Accuracy: 0.7163, Avg Loss: 0.7953, lr: 0.00018182233882257614\n",
      "Epoch 2/500, Validation Accuracy: 0.7147, Avg Loss: 0.7896, lr: 0.00018182233882257614\n",
      "Epoch 3/500, Validation Accuracy: 0.7153, Avg Loss: 0.7854, lr: 0.00018182233882257614\n",
      "Epoch 4/500, Validation Accuracy: 0.6945, Avg Loss: 0.7832, lr: 0.00018182233882257614\n",
      "Epoch 5/500, Validation Accuracy: 0.7080, Avg Loss: 0.7862, lr: 0.00018182233882257614\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 6/500, Validation Accuracy: 0.7123, Avg Loss: 0.7848, lr: 0.00018182233882257614\n",
      "Epoch 7/500, Validation Accuracy: 0.6994, Avg Loss: 0.7847, lr: 0.00018182233882257614\n",
      "Epoch 8/500, Validation Accuracy: 0.6935, Avg Loss: 0.7851, lr: 0.00018182233882257614\n",
      "Epoch 9/500, Validation Accuracy: 0.7092, Avg Loss: 0.7835, lr: 0.00018182233882257614\n",
      "Epoch 10/500, Validation Accuracy: 0.7058, Avg Loss: 0.7809, lr: 0.00018182233882257614\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 11/500, Validation Accuracy: 0.6711, Avg Loss: 0.7818, lr: 0.00018182233882257614\n",
      "Epoch 12/500, Validation Accuracy: 0.6967, Avg Loss: 0.7840, lr: 0.00018182233882257614\n",
      "Epoch 13/500, Validation Accuracy: 0.7132, Avg Loss: 0.7826, lr: 0.00018182233882257614\n",
      "Epoch 14/500, Validation Accuracy: 0.7087, Avg Loss: 0.7729, lr: 0.00018182233882257614\n",
      "Epoch 15/500, Validation Accuracy: 0.7095, Avg Loss: 0.7775, lr: 0.00018182233882257614\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 16/500, Validation Accuracy: 0.7093, Avg Loss: 0.7846, lr: 0.00018182233882257614\n",
      "Epoch 17/500, Validation Accuracy: 0.7125, Avg Loss: 0.7778, lr: 0.00018182233882257614\n",
      "Epoch 18/500, Validation Accuracy: 0.7007, Avg Loss: 0.7792, lr: 0.00018182233882257614\n",
      "Epoch 19/500, Validation Accuracy: 0.6936, Avg Loss: 0.7801, lr: 0.00018182233882257614\n",
      "Epoch 20/500, Validation Accuracy: 0.7058, Avg Loss: 0.7756, lr: 0.00018182233882257614\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 21/500, Validation Accuracy: 0.7101, Avg Loss: 0.7730, lr: 9.091116941128807e-05\n",
      "Epoch 22/500, Validation Accuracy: 0.7134, Avg Loss: 0.7695, lr: 9.091116941128807e-05\n",
      "Epoch 23/500, Validation Accuracy: 0.6999, Avg Loss: 0.7649, lr: 9.091116941128807e-05\n",
      "Epoch 24/500, Validation Accuracy: 0.7068, Avg Loss: 0.7640, lr: 9.091116941128807e-05\n",
      "Epoch 25/500, Validation Accuracy: 0.7045, Avg Loss: 0.7692, lr: 9.091116941128807e-05\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 26/500, Validation Accuracy: 0.7108, Avg Loss: 0.7773, lr: 9.091116941128807e-05\n",
      "Epoch 27/500, Validation Accuracy: 0.7099, Avg Loss: 0.7746, lr: 9.091116941128807e-05\n",
      "Epoch 28/500, Validation Accuracy: 0.7118, Avg Loss: 0.7631, lr: 9.091116941128807e-05\n",
      "Epoch 29/500, Validation Accuracy: 0.7117, Avg Loss: 0.7679, lr: 9.091116941128807e-05\n",
      "Epoch 30/500, Validation Accuracy: 0.7112, Avg Loss: 0.7666, lr: 9.091116941128807e-05\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 31/500, Validation Accuracy: 0.7129, Avg Loss: 0.7736, lr: 9.091116941128807e-05\n",
      "Epoch 32/500, Validation Accuracy: 0.7081, Avg Loss: 0.7687, lr: 9.091116941128807e-05\n",
      "Epoch 33/500, Validation Accuracy: 0.6999, Avg Loss: 0.7668, lr: 9.091116941128807e-05\n",
      "Epoch 34/500, Validation Accuracy: 0.7103, Avg Loss: 0.7665, lr: 9.091116941128807e-05\n",
      "Epoch 35/500, Validation Accuracy: 0.7110, Avg Loss: 0.7656, lr: 9.091116941128807e-05\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 36/500, Validation Accuracy: 0.7125, Avg Loss: 0.7679, lr: 9.091116941128807e-05\n",
      "Epoch 37/500, Validation Accuracy: 0.7112, Avg Loss: 0.7702, lr: 9.091116941128807e-05\n",
      "Epoch 38/500, Validation Accuracy: 0.7037, Avg Loss: 0.7682, lr: 9.091116941128807e-05\n",
      "Epoch 39/500, Validation Accuracy: 0.7076, Avg Loss: 0.7726, lr: 9.091116941128807e-05\n",
      "Epoch 40/500, Validation Accuracy: 0.7079, Avg Loss: 0.7684, lr: 9.091116941128807e-05\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n",
      "Epoch 41/500, Validation Accuracy: 0.7036, Avg Loss: 0.7655, lr: 9.091116941128807e-05\n",
      "Epoch 42/500, Validation Accuracy: 0.6857, Avg Loss: 0.7663, lr: 4.5455584705644034e-05\n",
      "Epoch 43/500, Validation Accuracy: 0.7080, Avg Loss: 0.7620, lr: 4.5455584705644034e-05\n",
      "Epoch 44/500, Validation Accuracy: 0.7117, Avg Loss: 0.7621, lr: 4.5455584705644034e-05\n",
      "Epoch 45/500, Validation Accuracy: 0.7125, Avg Loss: 0.7585, lr: 4.5455584705644034e-05\n",
      "Model saved to ./checkpoints/ssvep/models/ssvep_the_honored_one.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# manual_write_study_params(trainer.study_name, trainer.storage)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:5\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:18\u001b[39m, in \u001b[36m_train_loop\u001b[39m\u001b[34m(self, n_epochs, should_save, should_print)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# manual_write_study_params(trainer.study_name, trainer.storage)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d4e73",
   "metadata": {
    "cellUniqueIdByVincent": "72394",
    "id": "1d8d4e73",
    "outputId": "879ad0ae-f397-49f7-e3ba-7d299bdcecf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.0241790493218325e-05\n",
      "loaded model weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test accuracy: 0.74484375'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._prepare_training(False)\n",
    "trainer.model.eval()\n",
    "f\"test accuracy: {evaluate_model(trainer.model, trainer.eval_loader, device)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "bb6251503a76299c2e1994d5_2025-06-21T14-24-00-772Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
