{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a563374",
   "metadata": {
    "cellUniqueIdByVincent": "b5c77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "2a563374",
    "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Requirement already satisfied: optuna in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: kymatio in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: appdirs in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from kymatio) (1.4.4)\n",
      "Requirement already satisfied: configparser in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from kymatio) (7.2.0)\n",
      "Requirement already satisfied: numpy in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from kymatio) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from kymatio) (25.0)\n",
      "Requirement already satisfied: scipy in /home/zeyadcode/.pyenv/versions/3.12.11/envs/icmtc_venv/lib/python3.12/site-packages (from kymatio) (1.15.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "if not os.path.exists('./modules') and not os.path.exists('modules.zip'):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "if not os.path.exists('./modules') and os.path.exists('modules.zip'):\n",
    "    os.system('unzip modules.zip -d .')\n",
    "\n",
    "!pip3 install optuna\n",
    "!pip3 install kymatio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from modules import Trainer\n",
    "from modules.competition_dataset import EEGDataset, LABELS\n",
    "from modules.utils import split_and_get_loaders, evaluate_model, get_closest_divisor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from torchsummary import summary\n",
    "from sklearn.feature_selection import f_classif\n",
    "from torch.utils.data import ConcatDataset, random_split, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c5bf7b0",
   "metadata": {
    "cellUniqueIdByVincent": "e6823",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8c5bf7b0",
    "outputId": "e981327e-6451-4cf6-8020-c4fb791c5b99"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/ai_data/eeg_detection/data/mtcaic3'\n",
    "# model_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/models/ssvep.pth'\n",
    "# optuna_db_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/optuna/optuna_studies.db'\n",
    "data_path = './data/mtcaic3'\n",
    "model_path = './checkpoints/ssvep/models/the_great_one.pth'\n",
    "pca_model_path = './checkpoints/ssvep/models/pca.pkl'\n",
    "ica_model_path = './checkpoints/ssvep/models/ica.pkl'\n",
    "optuna_db_path = './checkpoints/ssvep/optuna/2_optuna_studies.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17b42a7",
   "metadata": {
    "cellUniqueIdByVincent": "285db",
    "id": "a17b42a7"
   },
   "outputs": [],
   "source": [
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call this function before creating datasets and models\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42089fb8",
   "metadata": {
    "cellUniqueIdByVincent": "77c22",
    "id": "42089fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "skipped: 0/2400\n",
      "data shape: (41141, 2, 256), mean shape: (1, 2, 1)\n",
      "skipped: 0/50\n",
      "data shape: (842, 2, 256), mean shape: (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "window_length = 128 * 2 # ensure divisble by 64 the kernel size\n",
    "print(window_length)\n",
    "stride = window_length // 3\n",
    "batch_size = 64\n",
    "\n",
    "dataset_train = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    domain=\"time\",\n",
    "    data_fraction=1.0,\n",
    "    hardcoded_mean=True,\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    task='ssvep',\n",
    "    split='validation',\n",
    "    read_labels=True,\n",
    "    hardcoded_mean=True,\n",
    ")\n",
    "\n",
    "combined = ConcatDataset([dataset_train, dataset_val])\n",
    "train_len = int(len(combined) * 0.8)\n",
    "val_len = len(combined) - train_len\n",
    "train_ds, val_ds = random_split(combined, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd5f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0079, -0.0211,  0.0180, -0.0745],\n",
       "        [-0.0083, -0.0288,  0.0360, -0.0791],\n",
       "        [-0.0072, -0.0262,  0.0315, -0.0845],\n",
       "        [-0.0098, -0.0269,  0.0263, -0.0684],\n",
       "        [-0.0098, -0.0373,  0.0177, -0.0746]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class DepthWiseConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, dim_mult=1, padding=0, bias=False):\n",
    "        super(DepthWiseConv2D, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels * dim_mult, padding=padding, kernel_size=kernel_size, groups=in_channels, bias=bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.depthwise(x)\n",
    "\n",
    "\n",
    "class SeperableConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=False):\n",
    "        super(SeperableConv2D, self).__init__()\n",
    "        self.depthwise = DepthWiseConv2D(in_channels, kernel_size, padding=padding)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class SSVEPClassifier(nn.Module):\n",
    "    # EEG Net Based\n",
    "    # todo look at this https://paperswithcode.com/paper/a-transformer-based-deep-neural-network-model\n",
    "    def __init__(self, n_electrodes=16, out_dim=4, dropout=0.25, kernLength=256, F1=96, D=1, F2=96, hidden_dim=100, layer_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # B x C x T\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernLength), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            #\n",
    "            DepthWiseConv2D(F1, (n_electrodes, 1), dim_mult=D, bias=False),\n",
    "            nn.BatchNorm2d(F1*D),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((1, 2)), # todo try making this max pool\n",
    "            nn.Dropout(dropout),\n",
    "            #\n",
    "            SeperableConv2D(F1 * D, F2, kernel_size=(1, 16), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.lstm_head = LSTMModel(F2, hidden_dim, layer_dim, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"expected input shape: BxCxT\"\"\"\n",
    "        x = x.unsqueeze(1)\n",
    "        y = self.block_1(x) # B x F1 x 1 x time_sub\n",
    "\n",
    "        y = y.squeeze(2) # B x F1 x time_sub\n",
    "        y = y.permute(0, 2, 1) # B x time_sub x F1\n",
    "        y = self.lstm_head(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "dummy_x = torch.randn(5, 2, 256).to(device)\n",
    "model = SSVEPClassifier(\n",
    "    n_electrodes=2,\n",
    "    dropout=0.33066508963955576,\n",
    "    kernLength=64,\n",
    "    F1 = 8,\n",
    "    D = 2,\n",
    "    F2 = 32,\n",
    "    hidden_dim=256,\n",
    "    layer_dim=2,\n",
    ").to(device)\n",
    "\n",
    "model(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12b164b5",
   "metadata": {
    "cellUniqueIdByVincent": "c9b4e",
    "id": "12b164b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping model loading...\n",
      "epoch: 0, avg_loss: 1.3850079456965128, val_evaluation: 0.2889127069191378\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m loss = criterion(y_pred, y)\n\u001b[32m     22\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m opt.step()\n\u001b[32m     25\u001b[39m avg_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "except Exception:\n",
    "    print(\"skipping model loading...\")\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.00030241790493218325)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "avg_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).to(torch.int64)\n",
    "        y_pred = model(x).to(device)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader)\n",
    "    avg_losses.append(avg_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        evaluation = evaluate_model(model, val_loader, device)\n",
    "        val_accuracies.append(evaluation)\n",
    "        model.cpu()\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        model.to(device)\n",
    "        print(f\"epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OBfEejXsGwBy",
   "metadata": {
    "cellUniqueIdByVincent": "5b12f",
    "id": "OBfEejXsGwBy"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# maxpool\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mavg_losses\u001b[49m)), avg_losses, \u001b[33m\"\u001b[39m\u001b[33mb-\u001b[39m\u001b[33m\"\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mtrainingg loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_accuracies)), val_accuracies, \u001b[33m\"\u001b[39m\u001b[33mr-\u001b[39m\u001b[33m\"\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mvalidation accuracies\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.legend()\n",
      "\u001b[31mNameError\u001b[39m: name 'avg_losses' is not defined"
     ]
    }
   ],
   "source": [
    "# maxpool\n",
    "plt.plot(range(len(avg_losses)), avg_losses, \"b-\", label=\"trainingg loss\")\n",
    "plt.plot(range(len(val_accuracies)), val_accuracies, \"r-\", label=\"validation accuracies\")\n",
    "plt.legend()\n",
    "print(f\"min avg_losses: {min(avg_losses)}\")\n",
    "print(f\"max val_accuracies: {max(val_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec2ee1",
   "metadata": {
    "cellUniqueIdByVincent": "e8792",
    "id": "2dec2ee1"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def _prepare_training(self, is_trial, do_not_modify_network=True, batch_size=batch_size, window_length=window_length, stride_factor=3):\n",
    "        super()._prepare_training(is_trial, do_not_modify_network, batch_size=batch_size,\n",
    "                                  window_length=window_length,\n",
    "                                  stride_factor=stride_factor, is_wavelet=True)\n",
    "        assert self.dataset is not None\n",
    "\n",
    "        if is_trial:\n",
    "            assert isinstance(self.trial, optuna.Trial), \"trial is none, cant' suggest params\"\n",
    "\n",
    "            if do_not_modify_network:\n",
    "                best_params = self._get_study().best_params if do_not_modify_network else None\n",
    "                assert best_params is not None, \"best_params is None, can't use them\"\n",
    "\n",
    "                kernLength = best_params[\"kernLength\"]\n",
    "                F1 = best_params[\"F1\"]\n",
    "                D = best_params[\"D\"]\n",
    "                F2 = best_params[\"F2\"]\n",
    "                hidden_dim = best_params[\"hidden_dim\"]\n",
    "                layer_dim = best_params[\"layer_dim\"]\n",
    "\n",
    "            else:\n",
    "                kernLength = self.trial.suggest_categorical(\"kernLength\", [128, 256, 512])\n",
    "                F1 = self.trial.suggest_categorical(\"F1\", [64, 96, 128])\n",
    "                D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
    "                F2 = self.trial.suggest_categorical(\"F2\", [64, 96, 128])\n",
    "                hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "                layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3, 4])\n",
    "\n",
    "            dropout = self.trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "            lr = self.trial.suggest_float(\"lr\", 3e-4, 3e-2, log=True)\n",
    "        else:\n",
    "            # best_params = self._get_study().best_params\n",
    "            # kernLength = best_params[\"kernLength\"]\n",
    "            # F1 = best_params[\"F1\"]\n",
    "            # D = best_params[\"D\"]\n",
    "            # F2 = best_params[\"F2\"]\n",
    "            # hidden_dim = best_params[\"hidden_dim\"]\n",
    "            # layer_dim = best_params[\"layer_dim\"]\n",
    "            # dropout = best_params[\"dropout\"]\n",
    "            # lr = best_params[\"lr\"]\n",
    "            dropout=0.33066508963955576\n",
    "            kernLength=256\n",
    "            F1 = 128\n",
    "            D = 2\n",
    "            F2 = F1 # OOPS 96\n",
    "            hidden_dim=256\n",
    "            layer_dim=3\n",
    "            lr = 0.000010241790493218325\n",
    "\n",
    "        n_samples = self.dataset.data[0].shape[1]  # data[x] shape CxT\n",
    "        n_electrodes = self.dataset.data[0].shape[0]\n",
    "\n",
    "        n_samples = self.dataset.data[0].shape[1]  # data[x] shape CxT\n",
    "        n_electrodes = self.dataset.data[0].shape[0]\n",
    "\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes, n_samples=n_samples, out_dim=4, dropout=dropout, kernLength=kernLength, F1=F1, D=D, F2=F2, hidden_dim=hidden_dim, layer_dim=layer_dim\n",
    "        )\n",
    "        print(f\"lr: {lr}\")\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "            print(f\"loaded model weights\")\n",
    "        except Exception:\n",
    "            print(f\"no model weights found at {model_path}\")\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "\n",
    "trainer = CustomTrainer(data_path, optuna_db_path, model_path, train_epochs=10000, optuna_n_trials=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132bf51",
   "metadata": {
    "cellUniqueIdByVincent": "00f49",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "a132bf51",
    "outputId": "fce5db39-6f8c-4201-da84-09fc34a1779e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-20 18:42:30,753] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n",
      "[I 2025-06-20 18:42:30,815] Using an existing study with name 'ssvep_classifier_optimization' instead of creating a new one.\n",
      "[W 2025-06-20 18:42:30,839] Trial 0 failed with parameters: {} because of the following error: ValueError('Record does not exist.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/Workspace/ai_projects/eeg_detection/modules/trainer.py\", line 101, in _objective\n",
      "    self._prepare_training(True)\n",
      "  File \"/tmp/ipykernel_306525/3387801006.py\", line 3, in _prepare_training\n",
      "    super()._prepare_training(is_trial, do_not_modify_network, batch_size=batch_size,\n",
      "  File \"/home/zeyadcode/Workspace/ai_projects/eeg_detection/modules/trainer.py\", line 80, in _prepare_training\n",
      "    best_params = self._get_study().best_params\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py\", line 119, in best_params\n",
      "    return self.best_trial.params\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py\", line 155, in best_trial\n",
      "    return self._get_best_trial(deepcopy=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py\", line 307, in _get_best_trial\n",
      "    best_trial = self._storage.get_best_trial(self._study_id)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_cached_storage.py\", line 180, in get_best_trial\n",
      "    return self._backend.get_best_trial(study_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py\", line 914, in get_best_trial\n",
      "    trial_id = models.TrialModel.find_max_value_trial_id(study_id, 0, session)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/models.py\", line 211, in find_max_value_trial_id\n",
      "    raise ValueError(NOT_FOUND_MSG)\n",
      "ValueError: Record does not exist.\n",
      "[W 2025-06-20 18:42:30,845] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Record does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m delete_existing = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelete_existing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/ai_projects/eeg_detection/modules/trainer.py:120\u001b[39m, in \u001b[36mTrainer.optimize\u001b[39m\u001b[34m(self, delete_existing)\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    119\u001b[39m study = \u001b[38;5;28mself\u001b[39m._get_study()\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptuna_n_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Print optimization results\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStudy statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/ai_projects/eeg_detection/modules/trainer.py:101\u001b[39m, in \u001b[36mTrainer._objective\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial: optuna.Trial):\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m.trial = trial\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mmodel is not set, can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt train, ensure to set it after overriding\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33moptimizer is not set, can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt train, ensure to set it after overriding\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mCustomTrainer._prepare_training\u001b[39m\u001b[34m(self, is_trial, do_not_modify_network, batch_size, window_length, stride_factor)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, is_trial, do_not_modify_network=\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size=batch_size, window_length=window_length, stride_factor=stride_factor):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_prepare_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_not_modify_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mstride_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/ai_projects/eeg_detection/modules/trainer.py:80\u001b[39m, in \u001b[36mTrainer._prepare_training\u001b[39m\u001b[34m(self, is_trial, do_not_modify_network, batch_size, window_length, stride_factor)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.trial, optuna.Trial), \u001b[33m\"\u001b[39m\u001b[33mtrial is none, cant\u001b[39m\u001b[33m'\u001b[39m\u001b[33m suggest params\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_not_modify_network:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     best_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_params\u001b[49m\n\u001b[32m     81\u001b[39m     window_length = best_params[\u001b[33m'\u001b[39m\u001b[33mwindow_length\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     82\u001b[39m     batch_size = batch_size \u001b[38;5;129;01mor\u001b[39;00m best_params[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:119\u001b[39m, in \u001b[36mStudy.best_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    109\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[32m    110\u001b[39m \n\u001b[32m    111\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_trial\u001b[49m.params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:155\u001b[39m, in \u001b[36mStudy.best_trial\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> FrozenTrial:\n\u001b[32m    140\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the best trial in the study.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/study/study.py:307\u001b[39m, in \u001b[36mStudy._get_best_trial\u001b[39m\u001b[34m(self, deepcopy)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi_objective():\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m best_trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[32m    312\u001b[39m constraints = best_trial.system_attrs.get(_CONSTRAINTS_KEY)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_cached_storage.py:180\u001b[39m, in \u001b[36m_CachedStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_best_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_id: \u001b[38;5;28mint\u001b[39m) -> FrozenTrial:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py:914\u001b[39m, in \u001b[36mRDBStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    911\u001b[39m direction = _directions[\u001b[32m0\u001b[39m]\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m direction == StudyDirection.MAXIMIZE:\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     trial_id = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrialModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_max_value_trial_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    916\u001b[39m     trial_id = models.TrialModel.find_min_value_trial_id(study_id, \u001b[32m0\u001b[39m, session)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/optuna/storages/_rdb/models.py:211\u001b[39m, in \u001b[36mTrialModel.find_max_value_trial_id\u001b[39m\u001b[34m(cls, study_id, objective, session)\u001b[39m\n\u001b[32m    191\u001b[39m trial = (\n\u001b[32m    192\u001b[39m     session.query(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    193\u001b[39m     .with_entities(\u001b[38;5;28mcls\u001b[39m.trial_id)\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m     .one_or_none()\n\u001b[32m    209\u001b[39m )\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(NOT_FOUND_MSG)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Record does not exist."
     ]
    }
   ],
   "source": [
    "delete_existing = False\n",
    "trainer.optimize(delete_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93294ea",
   "metadata": {
    "cellUniqueIdByVincent": "9a628",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "a93294ea",
    "outputId": "e77ed180-3a33-492a-c29e-15a57befbbae"
   },
   "outputs": [],
   "source": [
    "# manual_write_study_params(trainer.study_name, trainer.storage)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d4e73",
   "metadata": {
    "cellUniqueIdByVincent": "72394",
    "id": "1d8d4e73",
    "outputId": "879ad0ae-f397-49f7-e3ba-7d299bdcecf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.0241790493218325e-05\n",
      "loaded model weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test accuracy: 0.74484375'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._prepare_training(False)\n",
    "trainer.model.eval()\n",
    "f\"test accuracy: {evaluate_model(trainer.model, trainer.test_loader, device)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vincent": {
   "sessionId": "bb6251503a76299c2e1994d5_2025-06-21T14-24-00-772Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
