{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ddfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.datasets import PhysionetMI, Cho2017, BNCI2014_001, Weibo2014\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne import create_info\n",
    "from mne.io import RawArray\n",
    "from moabb.datasets.base import BaseDataset\n",
    "import mne\n",
    "import os\n",
    "\n",
    "\n",
    "# %%\n",
    "data_path = \"/home/zeyadcode/Workspace/ai_projects/eeg_detection/data/mtcaic3\"\n",
    "\n",
    "\n",
    "class CompetitionDataset(BaseDataset):\n",
    "    def __init__(self, split=\"train\"):\n",
    "        super().__init__(\n",
    "            subjects=list(range(1, 31)),  # List of subject IDs\n",
    "            sessions_per_subject=1,  # Number of sessions per subject\n",
    "            events={\"left_hand\": 1, \"right_hand\": 2},\n",
    "            code=\"CompetitionDataset\",\n",
    "            interval=[0, 4],  # Time interval for trials\n",
    "            paradigm=\"imagery\",  # \"ssvep\" or \"imagery\" or \"p300\"\n",
    "            doi=None,\n",
    "        )\n",
    "        self.split = split\n",
    "\n",
    "    def _get_single_subject_data(self, subject):\n",
    "        \"\"\"\n",
    "            Return data for one subject - THIS IS THE KEY METHOD\n",
    "            tips for Motor Imagery:\n",
    "                include C3, CZ, C4\n",
    "                may include FZ, PZ\n",
    "                don't include PO7, PO8, Oz\n",
    "\n",
    "        \"\"\"\n",
    "        ch_names = [\"FZ\", \"C3\", \"CZ\", \"C4\", \"PZ\", \"PO7\", \"OZ\", \"PO8\"]\n",
    "        moabb_channels = [\"Fz\", \"C3\", \"Cz\", \"C4\", \"Pz\", \"PO7\", \"Oz\", \"PO8\"]\n",
    "        if self.paradigm == \"ssvep\":\n",
    "            task = \"SSVEP\"\n",
    "        elif self.paradigm == \"imagery\":\n",
    "            task = \"MI\"\n",
    "        else:\n",
    "            raise ValueError(f\"got unexpected paradigm {self.paradigm}\")\n",
    "\n",
    "        # they competition forced us to do this...\n",
    "        subject_row = subject + 30 if self.split == \"validation\" else subject\n",
    "        # Load labels for this subject\n",
    "        labels_df = pd.read_csv(os.path.join(data_path, f\"{self.split}.csv\"), usecols=[\"subject_id\", \"trial_session\", \"trial\", \"task\", \"label\"])\n",
    "        task_df = labels_df.query(f\"task=='{task}' and subject_id=='S{subject_row}'\")\n",
    "\n",
    "        if task_df.empty:\n",
    "            print(f\"\\n\\n\\nWARNING TASK DF EMPTY {subject} AT ROW {subject_row} AT SPLIT {self.split}\\n\\n\\n\")\n",
    "            return {\"0\": {\"0\": None}}  # No data for this subject\n",
    "\n",
    "        sfreq = 250\n",
    "        ch_types = [\"eeg\"] * len(ch_names)\n",
    "\n",
    "        # Process each session\n",
    "        sessions = {}\n",
    "        for session_id in task_df[\"trial_session\"].unique():\n",
    "            session_trials = task_df[task_df[\"trial_session\"] == session_id]\n",
    "\n",
    "            # Load EEG data for this session\n",
    "            fp = os.path.join(data_path, task, self.split, f\"S{subject_row}\", str(session_id), \"EEGdata.csv\")\n",
    "            if not os.path.exists(fp):\n",
    "                continue\n",
    "\n",
    "            # Load the full session data\n",
    "            eeg_data = pd.read_csv(fp, usecols=ch_names).values\n",
    "            total_samples = eeg_data.shape[0]\n",
    "            trial_length = total_samples // 10  # 10 trials per session\n",
    "\n",
    "            # Create continuous data and events\n",
    "            all_trial_data = []\n",
    "            events_list = []\n",
    "            current_sample = 0\n",
    "\n",
    "            for _, trial_row in session_trials.iterrows():\n",
    "                trial_num = int(trial_row[\"trial\"])\n",
    "\n",
    "                # Extract trial data (trial numbers are 1-indexed)\n",
    "                start_idx = (trial_num - 1) * trial_length\n",
    "                end_idx = trial_num * trial_length\n",
    "                trial_data = eeg_data[start_idx:end_idx]\n",
    "\n",
    "                all_trial_data.append(trial_data)\n",
    "\n",
    "                # Create event at trial start\n",
    "                label = \"left_hand\" if trial_row.label == \"Left\" else \"right_hand\"\n",
    "                events_list.append([current_sample, 0, self.event_id[label]])\n",
    "                current_sample += trial_data.shape[0]\n",
    "\n",
    "            if not all_trial_data:\n",
    "                continue\n",
    "\n",
    "            # Concatenate all trials for this session\n",
    "            continuous_data = np.vstack(all_trial_data).T  # Shape: (channels, samples)\n",
    "\n",
    "            # Create MNE info object\n",
    "            info = create_info(moabb_channels, sfreq, ch_types)\n",
    "\n",
    "            # Create Raw object (convert to microvolts)\n",
    "            raw = RawArray(continuous_data * 1e-6, info, verbose=False)\n",
    "\n",
    "            # Add events as annotations\n",
    "            if events_list:\n",
    "                events_array = np.array(events_list)\n",
    "                event_desc = {v: k for k, v in self.event_id.items()}\n",
    "                annotations = mne.annotations_from_events(events_array, sfreq=sfreq, event_desc=event_desc)\n",
    "                raw.set_annotations(annotations)\n",
    "\n",
    "            sessions[str(session_id)] = {\"0\": raw}\n",
    "\n",
    "        if sessions is None:\n",
    "            print(f\"\\n\\n\\nWARNING TASK DF EMPTY {subject} AT ROW {subject_row} AT SPLIT {self.split}\\n\\n\\n\")\n",
    "            return {\"0\": {\"0\": None}}\n",
    "        else:\n",
    "            return sessions\n",
    "        # Return in required format: {\"session_id\": {\"run_id\": raw}}\n",
    "\n",
    "    def data_path(self, subject, path=None, force_update=False, update_path=None, verbose=None):\n",
    "        \"\"\"Return file paths for the subject's data\"\"\"\n",
    "        subject_paths = []\n",
    "\n",
    "        # Get all session directories for this subject\n",
    "        task = \"mi\" if self.paradigm == \"imagery\" else \"ssvep\"\n",
    "        subject_dir = os.path.join(data_path, task, self.split, f\"S{subject}\")\n",
    "        if os.path.exists(subject_dir):\n",
    "            for session in os.listdir(subject_dir):\n",
    "                session_path = os.path.join(subject_dir, session)\n",
    "                eeg_file = os.path.join(session_path, \"EEGdata.csv\")\n",
    "                if os.path.exists(eeg_file):\n",
    "                    subject_paths.append(eeg_file)\n",
    "\n",
    "        return subject_paths\n",
    "\n",
    "\n",
    "def load_combined_moabb_data(datasets, paradigm_config=None, subjects_per_dataset=None):\n",
    "    \"\"\"\n",
    "    Load and combine multiple MOABB datasets for DANN training.\n",
    "\n",
    "    Args:\n",
    "        datasets: List of MOABB dataset instances\n",
    "        paradigm_config: Dict with paradigm parameters (channels, tmin, tmax, resample)\n",
    "        subjects_per_dataset: Dict mapping dataset names to subject lists, or None for all\n",
    "\n",
    "    Returns:\n",
    "        X: Combined feature array\n",
    "        class_labels: Binary class labels (0/1)\n",
    "        domain_labels: Dataset-specific subject IDs (continuous across datasets)\n",
    "        dataset_info: Metadata about each dataset\n",
    "    \"\"\"\n",
    "    if paradigm_config is None:\n",
    "        paradigm_config = {\n",
    "            \"channels\": [\"Cz\", \"C3\", \"C4\"],\n",
    "            \"tmin\": 0.0,\n",
    "            \"tmax\": 4.0,\n",
    "            \"resample\": 250,\n",
    "        }\n",
    "\n",
    "    paradigm = LeftRightImagery(**paradigm_config)\n",
    "\n",
    "    all_X = []\n",
    "    all_class_labels = []\n",
    "    all_domain_labels = []\n",
    "    dataset_info = {}\n",
    "\n",
    "    current_subject_offset = 0\n",
    "\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        dataset_name = dataset.__class__.__name__\n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "\n",
    "        # Get subjects for this dataset\n",
    "        if subjects_per_dataset and dataset_name in subjects_per_dataset:\n",
    "            subjects = subjects_per_dataset[dataset_name]\n",
    "        else:\n",
    "            subjects = dataset.subject_list\n",
    "\n",
    "        print(f\"Original subject range: {min(subjects)} to {max(subjects)}\")\n",
    "\n",
    "        # Load data for this dataset\n",
    "        X, labels, metadata = paradigm.get_data(dataset, subjects=subjects)\n",
    "\n",
    "        # Convert string labels to binary\n",
    "        class_labels = []\n",
    "        for label in labels:\n",
    "            if label == \"left_hand\":\n",
    "                class_labels.append(0)\n",
    "            elif label == \"right_hand\":\n",
    "                class_labels.append(1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected label {label}\")\n",
    "\n",
    "        # Create domain labels with offset to avoid conflicts\n",
    "        domain_labels = []\n",
    "        for i in range(len(labels)):\n",
    "            original_subject = metadata.iloc[i][\"subject\"]\n",
    "            adjusted_subject = original_subject + current_subject_offset\n",
    "            domain_labels.append(adjusted_subject)\n",
    "\n",
    "        # Update offset for next dataset\n",
    "        max_subject_in_dataset = max(metadata[\"subject\"])\n",
    "        next_offset = current_subject_offset + max_subject_in_dataset\n",
    "\n",
    "        # Store dataset info\n",
    "        dataset_info[dataset_name] = {\n",
    "            \"original_subject_range\": (min(subjects), max(subjects)),\n",
    "            \"adjusted_subject_range\": (current_subject_offset + min(subjects), current_subject_offset + max_subject_in_dataset),\n",
    "            \"n_trials\": len(X),\n",
    "            \"n_subjects\": len(set(metadata[\"subject\"])),\n",
    "            \"subject_offset\": current_subject_offset,\n",
    "        }\n",
    "\n",
    "        print(f\"Adjusted subject range: {dataset_info[dataset_name]['adjusted_subject_range']}\")\n",
    "        print(f\"Number of trials: {len(X)}\")\n",
    "        print(f\"Number of subjects: {len(set(metadata['subject']))}\")\n",
    "\n",
    "        # Accumulate data\n",
    "        all_X.append(X)\n",
    "        all_class_labels.extend(class_labels)\n",
    "        all_domain_labels.extend(domain_labels)\n",
    "\n",
    "        current_subject_offset = next_offset\n",
    "\n",
    "    # drop to match\n",
    "    tmin = paradigm_config['tmin']\n",
    "    tmax =paradigm_config['tmax']\n",
    "    sfreq = paradigm_config['resample']\n",
    "    max_possible_value = int((tmax - tmin) * sfreq)\n",
    "\n",
    "    for i, x in enumerate(all_X):\n",
    "        all_X[i] = x[:, :, :max_possible_value]\n",
    "\n",
    "    # Combine all data\n",
    "    combined_X = np.concatenate(all_X, axis=0)\n",
    "    combined_class_labels = np.array(all_class_labels)\n",
    "    combined_domain_labels = np.array(all_domain_labels)\n",
    "\n",
    "    print(f\"\\n=== COMBINED DATASET SUMMARY ===\")\n",
    "    print(f\"Total trials: {len(combined_X)}\")\n",
    "    print(f\"Feature shape: {combined_X.shape}\")\n",
    "    print(f\"Class distribution: {np.bincount(combined_class_labels)}\")\n",
    "    print(f\"Subject range: {min(combined_domain_labels)} to {max(combined_domain_labels)}\")\n",
    "    print(f\"Total unique subjects: {len(np.unique(combined_domain_labels))}\")\n",
    "\n",
    "    return combined_X, combined_class_labels, combined_domain_labels, dataset_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563374",
   "metadata": {
    "cellUniqueIdByVincent": "b5c77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "2a563374",
    "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2  \n",
    "  \n",
    "import random  \n",
    "import numpy as np  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "from torch.autograd import Function  \n",
    "import optuna  \n",
    "from modules.utils import evaluate_model  \n",
    "import matplotlib.pyplot as plt  \n",
    "from braindecode.models import EEGInceptionMI, EEGSimpleConv, MSVTNet, FBCNet, ATCNet\n",
    "from braindecode import EEGClassifier  \n",
    "import torch.optim as optim  \n",
    "  \n",
    "# dataset related  \n",
    "from modules import CompetitionDataset, load_combined_moabb_data  \n",
    "from torch.utils.data import DataLoader, TensorDataset  \n",
    "from moabb.datasets import BNCI2014_001, PhysionetMI, Weibo2014, Cho2017  # 250 hz  \n",
    "from braindecode.datasets import MOABBDataset, create_from_X_y  \n",
    "from braindecode.preprocessing import preprocess, Preprocessor, exponential_moving_standardize, filterbank  \n",
    "from skorch.helper import predefined_split  \n",
    "from braindecode.datasets.base import BaseConcatDataset  \n",
    "import random\n",
    "import mne\n",
    "import numpy as np\n",
    "  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "device  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b42a7",
   "metadata": {
    "cellUniqueIdByVincent": "285db",
    "id": "a17b42a7"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call this function before creating datasets and models\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42089fb8",
   "metadata": {
    "cellUniqueIdByVincent": "77c22",
    "id": "42089fb8"
   },
   "outputs": [],
   "source": [
    "moabb_train_datasets = [\n",
    "    PhysionetMI(imagined=True),  # 109 subjects\n",
    "    Weibo2014(),  # 10 subjects, 64 channels\n",
    "    CompetitionDataset(),\n",
    "]\n",
    "train_val = [CompetitionDataset(split=\"validation\")]\n",
    "\n",
    "# Load combined data # BEST tmin=1, tmax=4, resample=250\n",
    "eeg_channels = [\"Fz\", \"C3\", \"Cz\", \"C4\", \"Pz\"]\n",
    "X_train, y_train, domain_labels_train, info_train = load_combined_moabb_data(\n",
    "    datasets=moabb_train_datasets,\n",
    "    paradigm_config={\n",
    "        \"channels\": eeg_channels,\n",
    "        \"tmin\": 1.0,\n",
    "        \"tmax\": 4.0,\n",
    "        \"resample\": 250,\n",
    "    }\n",
    "    # subjects_per_dataset={\n",
    "    #     \"PhysionetMI\": list(range(1, 50)),\n",
    "    #     \"Weibo2014\": list(range(1, 11)),\n",
    "    #     \"CompetitionDataset\": list(range(1, 31)),\n",
    "    # },\n",
    ")\n",
    "\n",
    "# Load combined data\n",
    "X_val, y_val, domain_labels_val, info_val = load_combined_moabb_data(\n",
    "    datasets=train_val,\n",
    "    paradigm_config={\n",
    "        \"channels\": eeg_channels,\n",
    "        \"tmin\": 1.0,\n",
    "        \"tmax\": 4.0,\n",
    "        \"resample\": 250,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0b3a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.4800\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.39      0.46        28\n",
      "           1       0.43      0.59      0.50        22\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.49      0.49      0.48        50\n",
      "weighted avg       0.50      0.48      0.48        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Models import FilterBankRTSClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "n_bands = 4\n",
    "filter_order = 3\n",
    "fs = 100\n",
    "n_estimators = 300\n",
    "max_depth = None\n",
    "min_samples_split = 7\n",
    "min_samples_leaf = 3\n",
    "max_features = 'sqrt'\n",
    "# Create frequency bands\n",
    "\n",
    "# Create FilterBank classifier with best parameters\n",
    "clf = FilterBankRTSClassifier(\n",
    "    fs=fs,\n",
    "    order=filter_order,\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf# Trial 67 finished with value: 0.6263345734944465 and parameters: {'window_length': 250, 'stride': 250, 'tmin': 0, 'ch_FZ': 1, 'ch_C3': 0, 'ch_CZ': 1, 'ch_C4': 0, 'ch_PZ': 1, 'ch_PO7': 1, 'ch_OZ': 1, 'ch_PO8': 0, 'n_bands': 4, 'min_freq': 11, 'max_freq': 40, 'filter_order': 3, 'fs': 125, 'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 67 with value: 0.6263345734944465.\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "y_pred = clf.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()  # FloatTensor of shape (N, C, T)\n",
    "y_train = torch.from_numpy(y_train).long()  # LongTensor of shape (N, 2)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "X_val_t = torch.from_numpy(X_val).float()\n",
    "y_val_t = torch.from_numpy(y_val).long()\n",
    "\n",
    "val_dataset = TensorDataset(X_val_t, y_val_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9356cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGSimpleConv(\n",
    "    n_chans=5,\n",
    "    n_outputs=2,  # Left/right hand motor imagery\n",
    "    sfreq=250,  # Optimal resampling frequency for this model is 80hz\n",
    "    feature_maps=96,  # Within recommended range [64-144]\n",
    "    n_convs=2,  # For cross-subject: [2-4]\n",
    "    kernel_size=8,  # For cross-subject: [5-8]\n",
    "    resampling_freq=80,\n",
    ")\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=0.0001,\n",
    "    batch_size=64,\n",
    "    max_epochs=100,\n",
    "    train_split=predefined_split(val_dataset),\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=2,\n",
    "    callbacks=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52348595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGInceptionMI(\n",
    "    n_chans=5,  # Number of channels\n",
    "    n_outputs=2,  # Number of classes (adjust based on your task)\n",
    "    input_window_seconds=3.0,  # best is 3-second windows 1->4\n",
    "    sfreq=250,\n",
    "    n_filters=12,  # Optimized parameter\n",
    "    n_convs=5,\n",
    "    kernel_unit_s=0.1,\n",
    ")\n",
    "\n",
    "# Setup classifier with skorch wrapper\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=0.001,\n",
    "    batch_size=64,\n",
    "    max_epochs=100,\n",
    "    train_split=predefined_split(val_dataset), \n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=2,\n",
    "    callbacks=['accuracy'],\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "model = ATCNet(\n",
    "    n_chans=5,\n",
    "    n_outputs=2,  # Left/right hand motor imagery\n",
    "    input_window_seconds=3.0,\n",
    "    sfreq=250,\n",
    "    n_windows=5,\n",
    "    att_head_dim=8,\n",
    "    att_num_heads=2,\n",
    "    tcn_depth=2,\n",
    "    tcn_kernel_size=4,\n",
    "    tcn_n_filters=32,\n",
    ")\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=0.0005,  # Lower learning rate for attention models\n",
    "    batch_size=32,  # Smaller batch size for memory efficiency\n",
    "    max_epochs=100,\n",
    "    train_split=predefined_split(val_dataset),\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=2,\n",
    "    callbacks=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vincent": {
   "sessionId": "bb6251503a76299c2e1994d5_2025-06-21T14-24-00-772Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
