{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a563374",
   "metadata": {
    "cellUniqueIdByVincent": "b5c77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "2a563374",
    "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ahmad\\appdata\\roaming\\python\\python312\\site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.1.4)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.10.3)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.15.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\ahmad\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.5->mne) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (2.32.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "if not os.path.exists('./modules') and not os.path.exists('modules.zip'):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "if not os.path.exists('./modules') and os.path.exists('modules.zip'):\n",
    "    os.system('unzip modules.zip -d .')\n",
    "\n",
    "if not os.path.exists('./Models') and not os.path.exists('Models.zip'):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "if not os.path.exists('./Models') and os.path.exists('Models.zip'):\n",
    "    os.system('unzip Models.zip -d .')\n",
    "\n",
    "!pip3 install optuna\n",
    "!pip3 install mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from modules import Trainer\n",
    "from modules.competition_dataset_one_per_trial import EEGDataset\n",
    "from modules.utils import evaluate_model\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from Models.lfann_dann_gpt_generated import LFANN_DANN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5bf7b0",
   "metadata": {
    "cellUniqueIdByVincent": "e6823",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8c5bf7b0",
    "outputId": "e981327e-6451-4cf6-8020-c4fb791c5b99"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive/\")\n",
    "# try:\n",
    "#     print()\n",
    "#     os.symlink(\"/content/drive/MyDrive/ai_data/eeg_detection/data\", \"./data\")\n",
    "#     os.symlink(\"/content/drive/MyDrive/ai_data/eeg_detection/checkpoints\", \"./checkpoints\")\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "data_path = \"./data/mtcaic3\"\n",
    "model_path = \"./checkpoints/mi/models/the_honored_one.pth\"\n",
    "optuna_db_path = \"./checkpoints/mi/optuna/the_honored_one.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17b42a7",
   "metadata": {
    "cellUniqueIdByVincent": "285db",
    "id": "a17b42a7"
   },
   "outputs": [],
   "source": [
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call this function before creating datasets and models\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42089fb8",
   "metadata": {
    "cellUniqueIdByVincent": "77c22",
    "id": "42089fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np shape:  (2400, 3, 40, 1125)\n",
      "data shape: torch.Size([2400, 3, 40, 1125]), classes shape: torch.Size([2400, 2])\n",
      "np shape:  (50, 3, 40, 1125)\n",
      "data shape: torch.Size([50, 3, 40, 1125]), classes shape: torch.Size([50, 2])\n",
      "np shape:  (50, 3, 40, 1125)\n",
      "data shape: torch.Size([50, 3, 40, 1125]), classes shape: torch.Size([50, 2])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "eeg_channels = [\n",
    "    \"C3\", # 2296.15\n",
    "    \"PZ\", # 1744.43\n",
    "    \"C4\", # 1556.46\n",
    "    # \"OZ\" # 444.98\n",
    "    # \"PO7\" # 381.63\n",
    "    # \"PO8\" # 275.78\n",
    "    # \"CZ\" # 200.43\n",
    "    # \"FZ\" # 111.51\n",
    "]\n",
    "\n",
    "dataset_train = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    task=\"MI\",\n",
    "    split=\"train\",\n",
    "    tmin=0.5,  # skip first 0.5 s (125 samples)\n",
    "    win_len=int(4.5 * 250),  # 4.5 s window → 1125 samples\n",
    "    read_labels=True,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    task=\"MI\",\n",
    "    split=\"validation\",\n",
    "    tmin=0.5,\n",
    "    win_len=int(4.5 * 250),\n",
    "    read_labels=True,\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(dataset_val,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92337f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of modules.competition_dataset_one_per_trial failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ahmad\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\extensions\\autoreload.py\", line 280, in check\n",
      "    elif self.deduper_reloader.maybe_reload_module(m):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ahmad\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 533, in maybe_reload_module\n",
      "    new_source_code = f.read()\n",
      "                      ^^^^^^^^\n",
      "  File \"c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 6483: character maps to <undefined>\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 1125])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd5f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 40 1125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0040, -0.0810],\n",
       "         [ 0.0041, -0.0838],\n",
       "         [ 0.0008, -0.0759]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 2.1628e-01, -9.6212e-02,  1.7485e-01, -1.3373e-01,  1.8526e-01,\n",
       "           2.1715e-01,  1.8716e-01,  2.0344e-01,  2.4808e-01, -1.5374e-01,\n",
       "          -2.1584e-01, -2.5827e-01, -3.6120e-01, -1.2083e-01, -4.1747e-01,\n",
       "          -1.2597e-01, -3.7014e-01,  4.1168e-01,  8.7177e-02,  4.7319e-01,\n",
       "           2.5332e-01,  2.6611e-01, -1.4398e-01, -1.6633e-01, -2.9214e-01,\n",
       "          -3.3820e-01, -8.4273e-02,  1.9428e-01, -2.0986e-03, -2.0291e-02],\n",
       "         [ 2.1674e-01, -9.6597e-02,  1.7417e-01, -1.3452e-01,  1.8650e-01,\n",
       "           2.1595e-01,  1.8649e-01,  2.0159e-01,  2.4985e-01, -1.5413e-01,\n",
       "          -2.1684e-01, -2.5881e-01, -3.6280e-01, -1.2203e-01, -4.1908e-01,\n",
       "          -1.2603e-01, -3.7116e-01,  4.1253e-01,  8.7238e-02,  4.7475e-01,\n",
       "           2.5421e-01,  2.6541e-01, -1.4459e-01, -1.6665e-01, -2.9350e-01,\n",
       "          -3.3918e-01, -8.3659e-02,  1.9457e-01, -3.1612e-03, -2.0481e-02],\n",
       "         [ 2.1568e-01, -9.8003e-02,  1.7377e-01, -1.3753e-01,  1.8469e-01,\n",
       "           2.1641e-01,  1.8425e-01,  2.0080e-01,  2.4773e-01, -1.5603e-01,\n",
       "          -2.1292e-01, -2.5834e-01, -3.6304e-01, -1.2219e-01, -4.2270e-01,\n",
       "          -1.2787e-01, -3.7241e-01,  4.1304e-01,  8.7865e-02,  4.7419e-01,\n",
       "           2.5702e-01,  2.6775e-01, -1.4579e-01, -1.6779e-01, -2.8979e-01,\n",
       "          -3.4067e-01, -8.2042e-02,  1.9465e-01, -1.4131e-04, -2.0132e-02]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C, F, T = dataset_train[0][0].shape\n",
    "print(C, F, T)\n",
    "model = LFANN_DANN(C=C, F=F, T=T).to(device)\n",
    "inp = torch.randn(3, C, F, T).to(device)\n",
    "out = model(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71194cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_losses_label = []\n",
    "avg_losses_domain = []\n",
    "val_label_accuracies = []\n",
    "val_domain_accuracies = []\n",
    "train_label_accuracies = []\n",
    "train_domain_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b164b5",
   "metadata": {
    "cellUniqueIdByVincent": "c9b4e",
    "id": "12b164b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: avg_loss_label: 0.695, avg_loss_domain: 3.432, train_label_acc: 49.25%, train_domain_acc: 3.33%, label_evaluation: 56.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "5: avg_loss_label: 0.694, avg_loss_domain: 3.453, train_label_acc: 49.46%, train_domain_acc: 3.33%, label_evaluation: 60.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "10: avg_loss_label: 0.695, avg_loss_domain: 3.489, train_label_acc: 49.67%, train_domain_acc: 6.54%, label_evaluation: 60.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "15: avg_loss_label: 0.696, avg_loss_domain: 4.375, train_label_acc: 51.17%, train_domain_acc: 4.29%, label_evaluation: 60.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "20: avg_loss_label: 0.704, avg_loss_domain: 24.994, train_label_acc: 50.12%, train_domain_acc: 4.62%, label_evaluation: 48.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "25: avg_loss_label: 2.158, avg_loss_domain: 73.371, train_label_acc: 50.21%, train_domain_acc: 1.50%, label_evaluation: 48.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "30: avg_loss_label: 1.734, avg_loss_domain: 121.123, train_label_acc: 49.33%, train_domain_acc: 0.88%, label_evaluation: 52.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "35: avg_loss_label: 1.502, avg_loss_domain: 187.744, train_label_acc: 49.79%, train_domain_acc: 2.67%, label_evaluation: 44.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "40: avg_loss_label: 1.748, avg_loss_domain: 164.796, train_label_acc: 49.88%, train_domain_acc: 3.67%, label_evaluation: 48.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "45: avg_loss_label: 4.834, avg_loss_domain: 67.754, train_label_acc: 48.71%, train_domain_acc: 1.75%, label_evaluation: 52.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "50: avg_loss_label: 1.357, avg_loss_domain: 30.682, train_label_acc: 49.12%, train_domain_acc: 5.50%, label_evaluation: 52.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "55: avg_loss_label: 1.121, avg_loss_domain: 17.728, train_label_acc: 50.29%, train_domain_acc: 5.04%, label_evaluation: 56.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "60: avg_loss_label: 0.969, avg_loss_domain: 14.180, train_label_acc: 50.42%, train_domain_acc: 6.96%, label_evaluation: 52.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "65: avg_loss_label: 1.116, avg_loss_domain: 14.169, train_label_acc: 49.54%, train_domain_acc: 8.38%, label_evaluation: 56.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "70: avg_loss_label: 0.947, avg_loss_domain: 14.341, train_label_acc: 49.62%, train_domain_acc: 9.29%, label_evaluation: 44.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "75: avg_loss_label: 0.865, avg_loss_domain: 12.041, train_label_acc: 50.71%, train_domain_acc: 7.42%, label_evaluation: 44.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "80: avg_loss_label: 0.895, avg_loss_domain: 9.751, train_label_acc: 49.83%, train_domain_acc: 8.50%, label_evaluation: 56.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "85: avg_loss_label: 0.781, avg_loss_domain: 6.723, train_label_acc: 50.17%, train_domain_acc: 8.62%, label_evaluation: 40.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "90: avg_loss_label: 0.927, avg_loss_domain: 5.169, train_label_acc: 50.33%, train_domain_acc: 9.46%, label_evaluation: 44.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "95: avg_loss_label: 0.888, avg_loss_domain: 4.625, train_label_acc: 50.33%, train_domain_acc: 8.79%, label_evaluation: 48.00, domain_evaluation: 0.00, lr: 3e-05\n",
      "100: avg_loss_label: 0.827, avg_loss_domain: 4.193, train_label_acc: 50.04%, train_domain_acc: 8.58%, label_evaluation: 44.00, domain_evaluation: 0.00, lr: 3e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m loss.backward()\n\u001b[32m     44\u001b[39m opt.step()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m avg_loss_label += \u001b[43mloss_label\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m avg_loss_domain += loss_domain.item()\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Accuracy calculation\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "# except Exception:\n",
    "#     print(\"skipping model loading...\")\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    opt,\n",
    "    mode=\"min\",  # “min” if you want to reduce lr when the quantity monitored has stopped decreasing\n",
    "    factor=0.5,  # new_lr = lr * factor\n",
    "    patience=20,  # number of epochs with no improvement after which lr will be reduced\n",
    "    threshold=1e-4,  # threshold for measuring the new optimum, to only focus on significant changes\n",
    "    threshold_mode=\"rel\",  # `'rel'` means compare change relative to best value. Could use `'abs'`.\n",
    "    cooldown=0,  # epochs to wait before resuming normal operation after lr has been reduced\n",
    "    min_lr=1e-6,  # lower bound on the lr\n",
    ")\n",
    "\n",
    "epochs = 4000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss_label = 0\n",
    "    avg_loss_domain = 0\n",
    "    correct_label = 0\n",
    "    correct_domain = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).to(torch.int64) # shape: [Bx2], 0: label, 1: domain\n",
    "        y_labels = y[:, 0]\n",
    "        y_subj = y[:, 1]\n",
    "\n",
    "        y_pred_labels, y_pred_domain = model(x)\n",
    "\n",
    "        loss_label = criterion(y_pred_labels, y_labels)\n",
    "        loss_domain = criterion(y_pred_domain, y_subj)\n",
    "        loss = loss_label + loss_domain\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        avg_loss_label += loss_label.item()\n",
    "        avg_loss_domain += loss_domain.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, pred_labels = torch.max(y_pred_labels, 1)\n",
    "        _, pred_domains = torch.max(y_pred_domain, 1)\n",
    "        correct_label += (pred_labels == y_labels).sum().item()\n",
    "        correct_domain += (pred_domains == y_subj).sum().item()\n",
    "        total += y_labels.size(0)\n",
    "\n",
    "    avg_loss_label /= len(train_loader)\n",
    "    avg_loss_domain /= len(train_loader)\n",
    "    avg_losses_label.append(avg_loss_label)\n",
    "    avg_losses_domain.append(avg_loss_domain)\n",
    "    train_label_acc = 100.0 * correct_label / total\n",
    "    train_domain_acc = 100.0 * correct_domain / total\n",
    "    train_label_accuracies.append(train_label_acc)\n",
    "    train_domain_accuracies.append(train_domain_acc)\n",
    "    # scheduler.step(avg_loss_label)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        label_evaluation, domain_evaluation = evaluate_model(model, val_loader, device)\n",
    "        val_label_accuracies.append(label_evaluation)\n",
    "        val_domain_accuracies.append(domain_evaluation)\n",
    "        model.cpu()\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        model.to(device)\n",
    "        print(f\"{epoch}: avg_loss_label: {avg_loss_label:.3F}, avg_loss_domain: {avg_loss_domain:.3F}, train_label_acc: {train_label_acc:.2f}%, train_domain_acc: {train_domain_acc:.2f}%, label_evaluation: {(label_evaluation*100):.2f}, domain_evaluation: {(domain_evaluation*100):.2f}, lr: {opt.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec2ee1",
   "metadata": {
    "cellUniqueIdByVincent": "e8792",
    "id": "2dec2ee1"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    # This method is called by _objective during an Optuna trial\n",
    "    def prepare_trial_run(self):\n",
    "        assert isinstance(self.trial, optuna.Trial), \"Trial not set!\"\n",
    "\n",
    "        # 1. Define Hyperparameters for this trial\n",
    "        #    a. Data/Loader parameters\n",
    "        window_length = self.trial.suggest_categorical(\"window_length\", [128, 256, 640]) # e.g. 64*2, 64*4, 64*10\n",
    "        batch_size = self.trial.suggest_categorical(\"batch_size\", [32, 64])\n",
    "\n",
    "        #    b. Model architecture parameters\n",
    "        kernLength = self.trial.suggest_categorical(\"kernLength\", [64, 128, 256])\n",
    "        F1 = self.trial.suggest_categorical(\"F1\", [8, 16, 32])\n",
    "        D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
    "        F2 = self.trial.suggest_categorical(\"F2\", [16, 32, 64]) # F2 must be F1 * D\n",
    "        hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3])\n",
    "        dropout = self.trial.suggest_float(\"dropout\", 0.1, 0.6)\n",
    "        \n",
    "        #    c. Optimizer parameters\n",
    "        lr = self.trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "        # 2. Prepare the data using these parameters\n",
    "        super()._prepare_data(is_trial=True, batch_size=batch_size, window_length=window_length)\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0] # Get shape from underlying dataset\n",
    "\n",
    "        # 3. Build the model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes, # Use value from data\n",
    "            dropout=dropout,\n",
    "            kernLength=kernLength,\n",
    "            F1=F1,\n",
    "            D=D,\n",
    "            F2=F1 * D, # F2 is dependent on F1 and D\n",
    "            hidden_dim=hidden_dim,\n",
    "            layer_dim=layer_dim,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    # This method is called by train() for the final run\n",
    "    def prepare_final_run(self):\n",
    "        # 1. Get the best hyperparameters from the completed study\n",
    "        study = self._get_study()\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        # 2. Prepare data using the best params\n",
    "        super()._prepare_data(is_trial=False) # is_trial=False handles getting params from study\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0]\n",
    "\n",
    "        # 3. Build the final model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes,\n",
    "            out_dim=2,\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            kernLength=best_params[\"kernLength\"],\n",
    "            F1=best_params[\"F1\"],\n",
    "            D=best_params[\"D\"],\n",
    "            F2=best_params[\"F1\"] * best_params[\"D\"],\n",
    "            hidden_dim=best_params[\"hidden_dim\"],\n",
    "            layer_dim=best_params[\"layer_dim\"],\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Optional: Load pre-existing weights if you are resuming\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(self.model_path))\n",
    "            print(f\"Loaded existing model weights from {self.model_path}\")\n",
    "        except Exception:\n",
    "            print(f\"No existing model weights found at {self.model_path}. Training from scratch.\")\n",
    "        \n",
    "        lr = 0.00018182233882257615 # best_params[\"lr\"]\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',        # “min” if you want to reduce lr when the quantity monitored has stopped decreasing\n",
    "            factor=0.5,        # new_lr = lr * factor\n",
    "            patience=20,        # number of epochs with no improvement after which lr will be reduced\n",
    "            threshold=1e-4,    # threshold for measuring the new optimum, to only focus on significant changes\n",
    "            threshold_mode='rel', # `'rel'` means compare change relative to best value. Could use `'abs'`.\n",
    "            cooldown=0,        # epochs to wait before resuming normal operation after lr has been reduced\n",
    "            min_lr=1e-6,       # lower bound on the lr\n",
    "        )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        data_path=data_path,\n",
    "        optuna_db_path=optuna_db_path,\n",
    "        model_path=model_path,\n",
    "        train_epochs=500, # Final training epochs\n",
    "        tune_epochs=50,   # Epochs per trial\n",
    "        optuna_n_trials=50,\n",
    "        task=\"mi\",\n",
    "        eeg_channels=eeg_channels,\n",
    "        data_fraction=0.4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132bf51",
   "metadata": {
    "cellUniqueIdByVincent": "00f49",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "a132bf51",
    "outputId": "fce5db39-6f8c-4201-da84-09fc34a1779e"
   },
   "outputs": [],
   "source": [
    "delete_existing = False\n",
    "trainer.optimize(delete_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93294ea",
   "metadata": {
    "cellUniqueIdByVincent": "9a628",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "a93294ea",
    "outputId": "e77ed180-3a33-492a-c29e-15a57befbbae"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d4e73",
   "metadata": {
    "cellUniqueIdByVincent": "72394",
    "id": "1d8d4e73",
    "outputId": "879ad0ae-f397-49f7-e3ba-7d299bdcecf0"
   },
   "outputs": [],
   "source": [
    "trainer._prepare_training(False)\n",
    "trainer.model.eval()\n",
    "f\"test accuracy: {evaluate_model(trainer.model, trainer.eval_loader, device)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "bb6251503a76299c2e1994d5_2025-06-21T14-24-00-772Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
