{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563374",
   "metadata": {
    "cellUniqueIdByVincent": "b5c77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "2a563374",
    "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyadcode/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "if not os.path.exists('./modules') and not os.path.exists('modules.zip'):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "if not os.path.exists('./modules') and os.path.exists('modules.zip'):\n",
    "    os.system('unzip modules.zip -d .')\n",
    "\n",
    "if not os.path.exists('./Models') and not os.path.exists('Models.zip'):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "if not os.path.exists('./Models') and os.path.exists('Models.zip'):\n",
    "    os.system('unzip Models.zip -d .')\n",
    "\n",
    "!pip3 install optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from modules import Trainer\n",
    "from modules.competition_dataset_new import EEGDataset\n",
    "from modules.utils import evaluate_model\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset, random_split, DataLoader\n",
    "from Models import CCT\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5bf7b0",
   "metadata": {
    "cellUniqueIdByVincent": "e6823",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8c5bf7b0",
    "outputId": "e981327e-6451-4cf6-8020-c4fb791c5b99"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/ai_data/eeg_detection/data/mtcaic3'\n",
    "# model_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/models/ssvep.pth'\n",
    "# optuna_db_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/optuna/optuna_studies.db'\n",
    "data_path = './data/mtcaic3'\n",
    "model_path = './checkpoints/mi/models/the_honored_one.pth'\n",
    "optuna_db_path = './checkpoints/mi/optuna/the_honored_one.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17b42a7",
   "metadata": {
    "cellUniqueIdByVincent": "285db",
    "id": "a17b42a7"
   },
   "outputs": [],
   "source": [
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call this function before creating datasets and models\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42089fb8",
   "metadata": {
    "cellUniqueIdByVincent": "77c22",
    "id": "42089fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([240, 1, 8, 1125]), label shape: torch.Size([240])\n",
      "data shape: torch.Size([50, 1, 8, 1125]), label shape: torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset_train = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    task=\"MI\",\n",
    "    split=\"train\",\n",
    "    tmin=0.5,  # skip first 0.5 s (125 samples)\n",
    "    win_len=int(4.5 * 250),  # 4.5 s window → 1125 samples\n",
    "    read_labels=True,\n",
    "    data_fraction=0.1,\n",
    "    hardcoded_mean=True,\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    task=\"MI\",\n",
    "    split=\"validation\",\n",
    "    tmin=0.5,\n",
    "    win_len=int(4.5 * 250),\n",
    "    read_labels=True,\n",
    "    hardcoded_mean=False,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(dataset_val,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd5f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3957, -0.1457]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CCT(kernel_sizes=[(8, 1), (1, 24), (1, 24)], stride=(1, 1), padding=(0, 0), # first kernel size was 22 in paper\n",
    "            pooling_kernel_size=(3, 3), pooling_stride=(1, 1), pooling_padding=(0, 0),\n",
    "            n_conv_layers=3, n_input_channels=1,\n",
    "            in_planes=48, activation=None, # ReLU\n",
    "            max_pool=False, conv_bias=False,\n",
    "            dim=48, num_layers=3,\n",
    "            num_heads=3, num_classes=2, \n",
    "            attn_dropout=0.1, dropout=0.1, \n",
    "            mlp_size=48, positional_emb=\"learnable\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model(torch.randn(1, 1, 8, 1125).to(device))  # Test the model with a dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b164b5",
   "metadata": {
    "cellUniqueIdByVincent": "c9b4e",
    "id": "12b164b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping model loading...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m loss = criterion(y_pred, y)\n\u001b[32m     32\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m opt.step()\n\u001b[32m     35\u001b[39m avg_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "except Exception:\n",
    "    print(\"skipping model loading...\")\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "avg_losses = []\n",
    "val_accuracies = []\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    opt,\n",
    "    mode=\"min\",  # “min” if you want to reduce lr when the quantity monitored has stopped decreasing\n",
    "    factor=0.5,  # new_lr = lr * factor\n",
    "    patience=20,  # number of epochs with no improvement after which lr will be reduced\n",
    "    threshold=1e-4,  # threshold for measuring the new optimum, to only focus on significant changes\n",
    "    threshold_mode=\"rel\",  # `'rel'` means compare change relative to best value. Could use `'abs'`.\n",
    "    cooldown=0,  # epochs to wait before resuming normal operation after lr has been reduced\n",
    "    min_lr=1e-6,  # lower bound on the lr\n",
    ")\n",
    "\n",
    "epochs = 4000\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).to(torch.int64)\n",
    "        y_pred = model(x).to(device)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader)\n",
    "    avg_losses.append(avg_loss)\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        evaluation = evaluate_model(model, val_loader, device)\n",
    "        val_accuracies.append(evaluation)\n",
    "        model.cpu()\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        model.to(device)\n",
    "        print(f\"epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}, lr: {opt.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec2ee1",
   "metadata": {
    "cellUniqueIdByVincent": "e8792",
    "id": "2dec2ee1"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    # This method is called by _objective during an Optuna trial\n",
    "    def prepare_trial_run(self):\n",
    "        assert isinstance(self.trial, optuna.Trial), \"Trial not set!\"\n",
    "\n",
    "        # 1. Define Hyperparameters for this trial\n",
    "        #    a. Data/Loader parameters\n",
    "        window_length = self.trial.suggest_categorical(\"window_length\", [128, 256, 640]) # e.g. 64*2, 64*4, 64*10\n",
    "        batch_size = self.trial.suggest_categorical(\"batch_size\", [32, 64])\n",
    "\n",
    "        #    b. Model architecture parameters\n",
    "        kernLength = self.trial.suggest_categorical(\"kernLength\", [64, 128, 256])\n",
    "        F1 = self.trial.suggest_categorical(\"F1\", [8, 16, 32])\n",
    "        D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
    "        F2 = self.trial.suggest_categorical(\"F2\", [16, 32, 64]) # F2 must be F1 * D\n",
    "        hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3])\n",
    "        dropout = self.trial.suggest_float(\"dropout\", 0.1, 0.6)\n",
    "        \n",
    "        #    c. Optimizer parameters\n",
    "        lr = self.trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "        # 2. Prepare the data using these parameters\n",
    "        super()._prepare_data(is_trial=True, batch_size=batch_size, window_length=window_length)\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0] # Get shape from underlying dataset\n",
    "\n",
    "        # 3. Build the model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes, # Use value from data\n",
    "            dropout=dropout,\n",
    "            kernLength=kernLength,\n",
    "            F1=F1,\n",
    "            D=D,\n",
    "            F2=F1 * D, # F2 is dependent on F1 and D\n",
    "            hidden_dim=hidden_dim,\n",
    "            layer_dim=layer_dim,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    # This method is called by train() for the final run\n",
    "    def prepare_final_run(self):\n",
    "        # 1. Get the best hyperparameters from the completed study\n",
    "        study = self._get_study()\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        # 2. Prepare data using the best params\n",
    "        super()._prepare_data(is_trial=False) # is_trial=False handles getting params from study\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0]\n",
    "\n",
    "        # 3. Build the final model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes,\n",
    "            out_dim=2,\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            kernLength=best_params[\"kernLength\"],\n",
    "            F1=best_params[\"F1\"],\n",
    "            D=best_params[\"D\"],\n",
    "            F2=best_params[\"F1\"] * best_params[\"D\"],\n",
    "            hidden_dim=best_params[\"hidden_dim\"],\n",
    "            layer_dim=best_params[\"layer_dim\"],\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Optional: Load pre-existing weights if you are resuming\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(self.model_path))\n",
    "            print(f\"Loaded existing model weights from {self.model_path}\")\n",
    "        except Exception:\n",
    "            print(f\"No existing model weights found at {self.model_path}. Training from scratch.\")\n",
    "        \n",
    "        lr = 0.00018182233882257615 # best_params[\"lr\"]\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',        # “min” if you want to reduce lr when the quantity monitored has stopped decreasing\n",
    "            factor=0.5,        # new_lr = lr * factor\n",
    "            patience=20,        # number of epochs with no improvement after which lr will be reduced\n",
    "            threshold=1e-4,    # threshold for measuring the new optimum, to only focus on significant changes\n",
    "            threshold_mode='rel', # `'rel'` means compare change relative to best value. Could use `'abs'`.\n",
    "            cooldown=0,        # epochs to wait before resuming normal operation after lr has been reduced\n",
    "            min_lr=1e-6,       # lower bound on the lr\n",
    "        )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        data_path=data_path,\n",
    "        optuna_db_path=optuna_db_path,\n",
    "        model_path=model_path,\n",
    "        train_epochs=500, # Final training epochs\n",
    "        tune_epochs=50,   # Epochs per trial\n",
    "        optuna_n_trials=50,\n",
    "        task=\"mi\",\n",
    "        eeg_channels=eeg_channels,\n",
    "        data_fraction=0.4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132bf51",
   "metadata": {
    "cellUniqueIdByVincent": "00f49",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "a132bf51",
    "outputId": "fce5db39-6f8c-4201-da84-09fc34a1779e"
   },
   "outputs": [],
   "source": [
    "delete_existing = False\n",
    "trainer.optimize(delete_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93294ea",
   "metadata": {
    "cellUniqueIdByVincent": "9a628",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "a93294ea",
    "outputId": "e77ed180-3a33-492a-c29e-15a57befbbae"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d4e73",
   "metadata": {
    "cellUniqueIdByVincent": "72394",
    "id": "1d8d4e73",
    "outputId": "879ad0ae-f397-49f7-e3ba-7d299bdcecf0"
   },
   "outputs": [],
   "source": [
    "trainer._prepare_training(False)\n",
    "trainer.model.eval()\n",
    "f\"test accuracy: {evaluate_model(trainer.model, trainer.eval_loader, device)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vincent": {
   "sessionId": "bb6251503a76299c2e1994d5_2025-06-21T14-24-00-772Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
