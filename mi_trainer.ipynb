{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563374",
   "metadata": {
    "cellUniqueIdByVincent": "b5c77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "2a563374",
    "outputId": "2f5357e7-a3f2-46ab-a67e-a21a666bccbf"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from modules import Trainer\n",
    "from modules.competition_dataset import EEGDataset, LABELS\n",
    "from modules.utils import evaluate_model\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset, random_split, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bf7b0",
   "metadata": {
    "cellUniqueIdByVincent": "e6823",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8c5bf7b0",
    "outputId": "e981327e-6451-4cf6-8020-c4fb791c5b99"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/ai_data/eeg_detection/data/mtcaic3'\n",
    "# model_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/models/ssvep.pth'\n",
    "# optuna_db_path = '/content/drive/MyDrive/ai_data/eeg_detection/checkpoints/ssvep/optuna/optuna_studies.db'\n",
    "data_path = './data/mtcaic3'\n",
    "model_path = './checkpoints/mi/models/mi_lda_model.pth'\n",
    "lda_model_path = './checkpoints/mi/models/lda_mi.pkl'\n",
    "optuna_db_path = './checkpoints/mi/optuna/ssvep.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b42a7",
   "metadata": {
    "cellUniqueIdByVincent": "285db",
    "id": "a17b42a7"
   },
   "outputs": [],
   "source": [
    "# Add this at the beginning of your notebook, after imports\n",
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call this function before creating datasets and models\n",
    "set_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42089fb8",
   "metadata": {
    "cellUniqueIdByVincent": "77c22",
    "id": "42089fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: mi, split: train, domain: time, data_fraction: 0.3\n",
      "Using 30.0% of data: 720/720 samples\n",
      "skipped: 0/720\n",
      "data shape: (12662, 3, 256), mean shape: (1, 1, 1)\n",
      "task: mi, split: validation, domain: time, data_fraction: 1\n",
      "skipped: 0/50\n",
      "data shape: (857, 3, 256), mean shape: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "window_length = 128 * 2 # ensure divisble by 64 the kernel size\n",
    "stride = window_length // 3\n",
    "batch_size = 64\n",
    "eeg_channels = [\"C3\", \"PZ\", \"OZ\"]\n",
    "\n",
    "dataset_train = EEGDataset(\n",
    "    data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    domain=\"time\",\n",
    "    data_fraction=0.3,\n",
    "    hardcoded_mean=True,\n",
    "    task=\"mi\",\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    data_path=data_path,\n",
    "    window_length=window_length,\n",
    "    stride=stride,\n",
    "    split='validation',\n",
    "    read_labels=True,\n",
    "    hardcoded_mean=True,\n",
    "    data_fraction=1,\n",
    "    task=\"mi\",\n",
    "    eeg_channels=eeg_channels,\n",
    ")\n",
    "\n",
    "combined = ConcatDataset([dataset_train, dataset_val])\n",
    "train_len = int(len(combined) * 0.8)\n",
    "val_len = len(combined) - train_len\n",
    "train_ds, val_ds = random_split(combined, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbd5f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2063, -0.0770,  0.1550,  0.0283],\n",
       "        [ 0.1564,  0.0600,  0.1672, -0.0591],\n",
       "        [ 0.1094,  0.0767,  0.1235, -0.0390],\n",
       "        [ 0.2348,  0.0042,  0.1745,  0.0295],\n",
       "        [ 0.1234,  0.0625,  0.1286, -0.0291]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class DepthWiseConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, dim_mult=1, padding=0, bias=False):\n",
    "        super(DepthWiseConv2D, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels * dim_mult, padding=padding, kernel_size=kernel_size, groups=in_channels, bias=bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.depthwise(x)\n",
    "\n",
    "\n",
    "class SeperableConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=False):\n",
    "        super(SeperableConv2D, self).__init__()\n",
    "        self.depthwise = DepthWiseConv2D(in_channels, kernel_size, padding=padding)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class SSVEPClassifier(nn.Module):\n",
    "    # EEG Net Based\n",
    "    # todo look at this https://paperswithcode.com/paper/a-transformer-based-deep-neural-network-model\n",
    "    def __init__(self, n_electrodes=16, out_dim=4, dropout=0.25, kernLength=256, F1=96, D=1, F2=96, hidden_dim=100, layer_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # B x C x T\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernLength), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            #\n",
    "            DepthWiseConv2D(F1, (n_electrodes, 1), dim_mult=D, bias=False),\n",
    "            nn.BatchNorm2d(F1*D),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((1, 2)), # todo try making this max pool\n",
    "            nn.Dropout(dropout),\n",
    "            #\n",
    "            SeperableConv2D(F1 * D, F2, kernel_size=(1, 16), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.lstm_head = LSTMModel(F2, hidden_dim, layer_dim, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"expected input shape: BxCxT\"\"\"\n",
    "        x = x.unsqueeze(1)\n",
    "        y = self.block_1(x) # B x F1 x 1 x time_sub\n",
    "\n",
    "        y = y.squeeze(2) # B x F1 x time_sub\n",
    "        y = y.permute(0, 2, 1) # B x time_sub x F1\n",
    "        y = self.lstm_head(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "dummy_x = torch.randn(5, 3, 256).to(device)\n",
    "model = SSVEPClassifier(\n",
    "    n_electrodes=3,\n",
    "    dropout=0.18946921713370796,\n",
    "    kernLength=256,\n",
    "    F1 = 32,\n",
    "    D = 3,\n",
    "    F2 = 64,\n",
    "    hidden_dim=64,\n",
    "    layer_dim=1,\n",
    ").to(device)\n",
    "\n",
    "model(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12b164b5",
   "metadata": {
    "cellUniqueIdByVincent": "c9b4e",
    "id": "12b164b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping model loading...\n",
      "epoch: 0, avg_loss: 0.6742040737140813, val_evaluation: 0.6375739644970414\n",
      "epoch: 5, avg_loss: 0.6148358117899245, val_evaluation: 0.6771449704142012\n",
      "epoch: 10, avg_loss: 0.5902519104396098, val_evaluation: 0.6723372781065089\n",
      "epoch: 15, avg_loss: 0.564831160758374, val_evaluation: 0.6993343195266272\n",
      "epoch: 20, avg_loss: 0.5531797248583573, val_evaluation: 0.7267011834319527\n",
      "epoch: 25, avg_loss: 0.5394475758075714, val_evaluation: 0.7285502958579881\n",
      "epoch: 30, avg_loss: 0.5155241313065297, val_evaluation: 0.7403846153846154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m loss = criterion(y_pred, y)\n\u001b[32m     22\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m opt.step()\n\u001b[32m     25\u001b[39m avg_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/icmtc_venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "except Exception:\n",
    "    print(\"skipping model loading...\")\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0010898602411002927)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "avg_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 4000\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).to(torch.int64)\n",
    "        y_pred = model(x).to(device)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader)\n",
    "    avg_losses.append(avg_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        evaluation = evaluate_model(model, val_loader, device)\n",
    "        val_accuracies.append(evaluation)\n",
    "        model.cpu()\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        model.to(device)\n",
    "        print(f\"epoch: {epoch}, avg_loss: {avg_loss}, val_evaluation: {evaluation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec2ee1",
   "metadata": {
    "cellUniqueIdByVincent": "e8792",
    "id": "2dec2ee1"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    # This method is called by _objective during an Optuna trial\n",
    "    def prepare_trial_run(self):\n",
    "        assert isinstance(self.trial, optuna.Trial), \"Trial not set!\"\n",
    "\n",
    "        # 1. Define Hyperparameters for this trial\n",
    "        #    a. Data/Loader parameters\n",
    "        window_length = self.trial.suggest_categorical(\"window_length\", [128, 256, 640]) # e.g. 64*2, 64*4, 64*10\n",
    "        batch_size = self.trial.suggest_categorical(\"batch_size\", [32, 64])\n",
    "\n",
    "        #    b. Model architecture parameters\n",
    "        kernLength = self.trial.suggest_categorical(\"kernLength\", [64, 128, 256])\n",
    "        F1 = self.trial.suggest_categorical(\"F1\", [8, 16, 32])\n",
    "        D = self.trial.suggest_categorical(\"D\", [1, 2, 3])\n",
    "        F2 = self.trial.suggest_categorical(\"F2\", [16, 32, 64]) # F2 must be F1 * D\n",
    "        hidden_dim = self.trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        layer_dim = self.trial.suggest_categorical(\"layer_dim\", [1, 2, 3])\n",
    "        dropout = self.trial.suggest_float(\"dropout\", 0.1, 0.6)\n",
    "        \n",
    "        #    c. Optimizer parameters\n",
    "        lr = self.trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "        # 2. Prepare the data using these parameters\n",
    "        super()._prepare_data(is_trial=True, batch_size=batch_size, window_length=window_length)\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0] # Get shape from underlying dataset\n",
    "\n",
    "        # 3. Build the model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes, # Use value from data\n",
    "            dropout=dropout,\n",
    "            kernLength=kernLength,\n",
    "            F1=F1,\n",
    "            D=D,\n",
    "            F2=F1 * D, # F2 is dependent on F1 and D\n",
    "            hidden_dim=hidden_dim,\n",
    "            layer_dim=layer_dim,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    # This method is called by train() for the final run\n",
    "    def prepare_final_run(self):\n",
    "        # 1. Get the best hyperparameters from the completed study\n",
    "        study = self._get_study()\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        # 2. Prepare data using the best params\n",
    "        super()._prepare_data(is_trial=False) # is_trial=False handles getting params from study\n",
    "        \n",
    "        assert self.dataset is not None, \"Dataset was not created correctly\"\n",
    "        n_electrodes = self.dataset.datasets[0].data[0].shape[0]\n",
    "\n",
    "        # 3. Build the final model and optimizer\n",
    "        self.model = SSVEPClassifier(\n",
    "            n_electrodes=n_electrodes,\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            kernLength=best_params[\"kernLength\"],\n",
    "            F1=best_params[\"F1\"],\n",
    "            D=best_params[\"D\"],\n",
    "            F2=best_params[\"F1\"] * best_params[\"D\"],\n",
    "            hidden_dim=best_params[\"hidden_dim\"],\n",
    "            layer_dim=best_params[\"layer_dim\"],\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Optional: Load pre-existing weights if you are resuming\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(self.model_path))\n",
    "            print(f\"Loaded existing model weights from {self.model_path}\")\n",
    "        except Exception:\n",
    "            print(f\"No existing model weights found at {self.model_path}. Training from scratch.\")\n",
    "        \n",
    "        lr = 0.00018182233882257615 # best_params[\"lr\"]\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',        # “min” if you want to reduce lr when the quantity monitored has stopped decreasing\n",
    "            factor=0.5,        # new_lr = lr * factor\n",
    "            patience=20,        # number of epochs with no improvement after which lr will be reduced\n",
    "            threshold=1e-4,    # threshold for measuring the new optimum, to only focus on significant changes\n",
    "            threshold_mode='rel', # `'rel'` means compare change relative to best value. Could use `'abs'`.\n",
    "            cooldown=0,        # epochs to wait before resuming normal operation after lr has been reduced\n",
    "            min_lr=1e-6,       # lower bound on the lr\n",
    "        )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        data_path=data_path,\n",
    "        optuna_db_path=optuna_db_path,\n",
    "        model_path=model_path,\n",
    "        train_epochs=500, # Final training epochs\n",
    "        tune_epochs=50,   # Epochs per trial\n",
    "        optuna_n_trials=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132bf51",
   "metadata": {
    "cellUniqueIdByVincent": "00f49",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "a132bf51",
    "outputId": "fce5db39-6f8c-4201-da84-09fc34a1779e"
   },
   "outputs": [],
   "source": [
    "delete_existing = False\n",
    "trainer.optimize(delete_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93294ea",
   "metadata": {
    "cellUniqueIdByVincent": "9a628",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "a93294ea",
    "outputId": "e77ed180-3a33-492a-c29e-15a57befbbae"
   },
   "outputs": [],
   "source": [
    "# manual_write_study_params(trainer.study_name, trainer.storage)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d4e73",
   "metadata": {
    "cellUniqueIdByVincent": "72394",
    "id": "1d8d4e73",
    "outputId": "879ad0ae-f397-49f7-e3ba-7d299bdcecf0"
   },
   "outputs": [],
   "source": [
    "trainer._prepare_training(False)\n",
    "trainer.model.eval()\n",
    "f\"test accuracy: {evaluate_model(trainer.model, trainer.eval_loader, device)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmtc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vincent": {
   "sessionId": "bb6251503a76299c2e1994d5_2025-06-21T14-24-00-772Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
